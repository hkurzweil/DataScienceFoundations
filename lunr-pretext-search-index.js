var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "sec-what-is-data-science",
  "level": "1",
  "url": "sec-what-is-data-science.html",
  "type": "Section",
  "number": "",
  "title": "What is Data Science?",
  "body": " What is Data Science?   Defining Data Science  Data science is an interdisciplinary field that combines domain knowledge, programming skills, and statistical techniques to extract meaningful insights from data. At its core, data science is about using data to answer questions, solve problems, and make decisions.   The Data Science Venn Diagram   A Venn diagram showing data science as the intersection of domain expertise, mathematics\/statistics, and computer science.    Software Engineering: A Practitioner's Approach    The field of data science has evolved from statistics, computer science, and specific domain applications. While statisticians have been analyzing data for centuries, modern data science incorporates newer tools and techniques to handle larger, more complex datasets and to gain deeper insights into the data to solve real world problems.   Data Science Concepts   Which of the following best describes data science?      An interdisciplinary field that combines domain knowledge, programming skills, and statistical techniques to extract insights from data    Correct! Data science combines multiple disciplines to analyze and interpret data.      A branch of computer science focused exclusively on machine learning algorithms    While machine learning is part of data science, data science is broader and includes other disciplines.      A synonym for statistics that uses modern technology    Statistics is a component of data science, but data science also incorporates programming, domain expertise, and other skills.      The process of creating visual representations of large datasets    Data visualization is an important part of data science, but data science encompasses much more.       Exploring Data Science History: Snow's Cholera Map   Long before the term \"data science\" existed, people were using data to solve important problems. One of the most famous historical examples is Dr. John Snow's investigation of a cholera outbreak in London in 1854.  During a severe cholera outbreak in the Soho district of London, Dr. Snow collected data on the locations of cholera deaths and plotted them on a map. By carefully mapping each case, he noticed a pattern: the deaths clustered around a specific water pump on Broad Street. This spatial analysis led him to hypothesize that contaminated water, not \"bad air\" (the prevailing theory at the time), was responsible for spreading the disease.   John Snow's Original Cholera Map (1854)   John Snow's map showing cholera cases clustered around the Broad Street pump in London.    National Geographic    Snow's methods included:    Data collection: Recording the locations of cholera deaths    Spatial analysis: Plotting cases on a map to identify patterns    Hypothesis testing: Testing his theory by investigating the water source    Intervention: Recommending the removal of the pump handle, which helped end the outbreak    This early example of data-driven decision making saved lives and helped establish the field of epidemiology.     How is Snow's approach similar to modern data science methods? Identify at least two similarities.      What limitations did Snow face in his data collection and analysis? How might these have affected his conclusions?      If Snow had access to modern data science tools (like CODAP, GIS systems, or statistical software), how might his analysis have been enhanced or expanded?       Why Data Literacy Matters  Data literacy—the ability to read, work with, analyze, and communicate with data—has become an essential skill in the 21st century. Whether you're making personal decisions, participating in civic discussions, or pursuing a career, understanding data helps you:    Make informed decisions based on evidence rather than intuition alone    Critically evaluate claims that others make using data    Communicate your own findings effectively    Identify misleading presentations of data    Understand complex systems and patterns in the world      Consider a news article that claims \"Violent crime has surged by 30% this year.\" A data-literate person would ask:    Compared to what baseline? (Last year? Five years ago? The lowest point ever recorded?)    What specific crimes are included in \"violent crime\"?    What geographic area does this apply to?    Has the way crimes are reported or recorded changed?    Is a percentage the most appropriate measure, or would raw numbers provide important context?       Data Literacy in the News   In this activity, we'll practice data literacy by examining news articles.     Go to Google and navigate to the News tab. Type in Data about and enter in a topic you're interested in. Choose an article that looks interesting to you.      Identify at least three questions you would ask to better understand the data behind the claim.      If possible, find the original data source and determine if the article's interpretation seems accurate.       Data Literacy Skills   Match each data literacy skill with its appropriate example.     Critical evaluation of claims  Questioning a news headline about crime statistics by examining the source data    Making informed decisions  Choosing between job offers by comparing salary and benefits data    Identifying misleading presentations  Noticing that a graph's y-axis doesn't start at zero, exaggerating differences    Effective communication of findings  Creating a clear visualization that shows the key trends in your research    Understanding complex patterns  Recognizing seasonal variations in multiple years of sales data      Applications of Data Science  Data science methods are transforming virtually every field:    Healthcare   Predicting disease outbreaks  Personalizing treatment plans  Improving diagnostic accuracy  Optimizing hospital operations     Business   Customer segmentation  Demand forecasting  Process optimization  Fraud detection       Environmental Science   Climate modeling  Ecosystem monitoring  Pollution tracking  Resource management     Social Sciences   Analyzing social networks  Studying behavioral patterns  Evaluating program effectiveness  Understanding demographic trends      Data Science in Your Field of Interest   In this activity, you'll explore how data science is used in a field that interests you.     Select a field or industry that interests you.      Research and identify at least three specific ways data science is being applied in this field.      For one application, describe the data that might be collected, how it might be analyzed, and what insights it provides.      "
},
{
  "id": "fig-data-science-venn",
  "level": "2",
  "url": "sec-what-is-data-science.html#fig-data-science-venn",
  "type": "Figure",
  "number": "1",
  "title": "",
  "body": " The Data Science Venn Diagram   A Venn diagram showing data science as the intersection of domain expertise, mathematics\/statistics, and computer science.    Software Engineering: A Practitioner's Approach   "
},
{
  "id": "mc-data-science-concepts",
  "level": "2",
  "url": "sec-what-is-data-science.html#mc-data-science-concepts",
  "type": "Checkpoint",
  "number": "2",
  "title": "Data Science Concepts.",
  "body": " Data Science Concepts   Which of the following best describes data science?      An interdisciplinary field that combines domain knowledge, programming skills, and statistical techniques to extract insights from data    Correct! Data science combines multiple disciplines to analyze and interpret data.      A branch of computer science focused exclusively on machine learning algorithms    While machine learning is part of data science, data science is broader and includes other disciplines.      A synonym for statistics that uses modern technology    Statistics is a component of data science, but data science also incorporates programming, domain expertise, and other skills.      The process of creating visual representations of large datasets    Data visualization is an important part of data science, but data science encompasses much more.     "
},
{
  "id": "activity-data-science-history",
  "level": "2",
  "url": "sec-what-is-data-science.html#activity-data-science-history",
  "type": "Activity",
  "number": "1",
  "title": "Exploring Data Science History: Snow’s Cholera Map.",
  "body": " Exploring Data Science History: Snow's Cholera Map   Long before the term \"data science\" existed, people were using data to solve important problems. One of the most famous historical examples is Dr. John Snow's investigation of a cholera outbreak in London in 1854.  During a severe cholera outbreak in the Soho district of London, Dr. Snow collected data on the locations of cholera deaths and plotted them on a map. By carefully mapping each case, he noticed a pattern: the deaths clustered around a specific water pump on Broad Street. This spatial analysis led him to hypothesize that contaminated water, not \"bad air\" (the prevailing theory at the time), was responsible for spreading the disease.   John Snow's Original Cholera Map (1854)   John Snow's map showing cholera cases clustered around the Broad Street pump in London.    National Geographic    Snow's methods included:    Data collection: Recording the locations of cholera deaths    Spatial analysis: Plotting cases on a map to identify patterns    Hypothesis testing: Testing his theory by investigating the water source    Intervention: Recommending the removal of the pump handle, which helped end the outbreak    This early example of data-driven decision making saved lives and helped establish the field of epidemiology.     How is Snow's approach similar to modern data science methods? Identify at least two similarities.      What limitations did Snow face in his data collection and analysis? How might these have affected his conclusions?      If Snow had access to modern data science tools (like CODAP, GIS systems, or statistical software), how might his analysis have been enhanced or expanded?    "
},
{
  "id": "example-data-literacy-everyday",
  "level": "2",
  "url": "sec-what-is-data-science.html#example-data-literacy-everyday",
  "type": "Example",
  "number": "4",
  "title": "",
  "body": "  Consider a news article that claims \"Violent crime has surged by 30% this year.\" A data-literate person would ask:    Compared to what baseline? (Last year? Five years ago? The lowest point ever recorded?)    What specific crimes are included in \"violent crime\"?    What geographic area does this apply to?    Has the way crimes are reported or recorded changed?    Is a percentage the most appropriate measure, or would raw numbers provide important context?     "
},
{
  "id": "activity-data-literacy-news",
  "level": "2",
  "url": "sec-what-is-data-science.html#activity-data-literacy-news",
  "type": "Activity",
  "number": "2",
  "title": "Data Literacy in the News.",
  "body": " Data Literacy in the News   In this activity, we'll practice data literacy by examining news articles.     Go to Google and navigate to the News tab. Type in Data about and enter in a topic you're interested in. Choose an article that looks interesting to you.      Identify at least three questions you would ask to better understand the data behind the claim.      If possible, find the original data source and determine if the article's interpretation seems accurate.    "
},
{
  "id": "matching-data-literacy",
  "level": "2",
  "url": "sec-what-is-data-science.html#matching-data-literacy",
  "type": "Checkpoint",
  "number": "5",
  "title": "Data Literacy Skills.",
  "body": " Data Literacy Skills   Match each data literacy skill with its appropriate example.     Critical evaluation of claims  Questioning a news headline about crime statistics by examining the source data    Making informed decisions  Choosing between job offers by comparing salary and benefits data    Identifying misleading presentations  Noticing that a graph's y-axis doesn't start at zero, exaggerating differences    Effective communication of findings  Creating a clear visualization that shows the key trends in your research    Understanding complex patterns  Recognizing seasonal variations in multiple years of sales data    "
},
{
  "id": "subsec-applications-3-1-1",
  "level": "2",
  "url": "sec-what-is-data-science.html#subsec-applications-3-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Healthcare "
},
{
  "id": "subsec-applications-3-2-1",
  "level": "2",
  "url": "sec-what-is-data-science.html#subsec-applications-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Business "
},
{
  "id": "subsec-applications-4-1-1",
  "level": "2",
  "url": "sec-what-is-data-science.html#subsec-applications-4-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Environmental Science "
},
{
  "id": "subsec-applications-4-2-1",
  "level": "2",
  "url": "sec-what-is-data-science.html#subsec-applications-4-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Social Sciences "
},
{
  "id": "activity-field-exploration",
  "level": "2",
  "url": "sec-what-is-data-science.html#activity-field-exploration",
  "type": "Activity",
  "number": "3",
  "title": "Data Science in Your Field of Interest.",
  "body": " Data Science in Your Field of Interest   In this activity, you'll explore how data science is used in a field that interests you.     Select a field or industry that interests you.      Research and identify at least three specific ways data science is being applied in this field.      For one application, describe the data that might be collected, how it might be analyzed, and what insights it provides.    "
},
{
  "id": "sec-intro-to-codap",
  "level": "1",
  "url": "sec-intro-to-codap.html",
  "type": "Section",
  "number": "",
  "title": "Introduction to CODAP",
  "body": " Introduction to CODAP  CODAP (Common Online Data Analysis Platform) is a free, web-based data analysis tool designed specifically for educational purposes. It provides an intuitive interface for exploring data without requiring programming knowledge.   The CODAP Interface  Let's explore the basic components of the CODAP interface:   The CODAP Interface   Screenshot of the CODAP interface showing the built-in Mammal example.    Key components include:    Tables : Display data in rows and columns    Graphs : Create visual representations of data    Calculator : Perform calculations and create new attributes    Map : Plot geographic data    Text : Add explanatory notes to your document    You can access CODAP at codap.concord.org . No login is required to get started, though you can save files to your local computer or link it to your Google drive, if you have one.    Your First CODAP Exploration  Let's dive into CODAP with a simple dataset.   CODAP Basics   In this activity, we'll explore a simple dataset in CODAP to get familiar with the interface.     Open CODAP in your web browser by going to codap.concord.org .      Click on \"Examples\" in the main menu and select \"Mammals\" from the list.      Explore the table by:    Scrolling through the data    Sorting columns by clicking on column headers    Resizing columns by dragging the column borders        Create a graph by:    Clicking on \"Graph\" in the main toolbar    Dragging \"Body Weight\" from the table to the horizontal axis    Dragging \"Brain Weight\" from the table to the vertical axis        Explore the relationship between body weight and brain weight by examining the graph. What patterns do you notice?     This basic exploration gives you a sense of how CODAP makes it easy to view and visualize data. Throughout this course, we'll build on these skills to perform more sophisticated analyses.   "
},
{
  "id": "fig-codap-interface",
  "level": "2",
  "url": "sec-intro-to-codap.html#fig-codap-interface",
  "type": "Figure",
  "number": "6",
  "title": "",
  "body": " The CODAP Interface   Screenshot of the CODAP interface showing the built-in Mammal example.   "
},
{
  "id": "subsec-codap-interface-5-1-1",
  "level": "2",
  "url": "sec-intro-to-codap.html#subsec-codap-interface-5-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Tables "
},
{
  "id": "subsec-codap-interface-5-2-1",
  "level": "2",
  "url": "sec-intro-to-codap.html#subsec-codap-interface-5-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Graphs "
},
{
  "id": "subsec-codap-interface-5-3-1",
  "level": "2",
  "url": "sec-intro-to-codap.html#subsec-codap-interface-5-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Calculator "
},
{
  "id": "subsec-codap-interface-5-4-1",
  "level": "2",
  "url": "sec-intro-to-codap.html#subsec-codap-interface-5-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Map "
},
{
  "id": "subsec-codap-interface-5-5-1",
  "level": "2",
  "url": "sec-intro-to-codap.html#subsec-codap-interface-5-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Text "
},
{
  "id": "activity-codap-basics",
  "level": "2",
  "url": "sec-intro-to-codap.html#activity-codap-basics",
  "type": "Activity",
  "number": "4",
  "title": "CODAP Basics.",
  "body": " CODAP Basics   In this activity, we'll explore a simple dataset in CODAP to get familiar with the interface.     Open CODAP in your web browser by going to codap.concord.org .      Click on \"Examples\" in the main menu and select \"Mammals\" from the list.      Explore the table by:    Scrolling through the data    Sorting columns by clicking on column headers    Resizing columns by dragging the column borders        Create a graph by:    Clicking on \"Graph\" in the main toolbar    Dragging \"Body Weight\" from the table to the horizontal axis    Dragging \"Brain Weight\" from the table to the vertical axis        Explore the relationship between body weight and brain weight by examining the graph. What patterns do you notice?    "
},
{
  "id": "sec-project-launch",
  "level": "1",
  "url": "sec-project-launch.html",
  "type": "Section",
  "number": "",
  "title": "Project Launch: Community Health and Environment",
  "body": " Project Launch: Community Health and Environment   The Sample Project  Throughout this course, we'll work with a Community Health and Environment dataset to demonstrate data science concepts. Versions can be found on the CDC's website where you'll navigate to the most recent file, click Export in the top right-hand corner, and download it as a .csv file. This dataset contains information about:    Health indicators (asthma rates, heart disease prevalence)    Environmental factors (air quality, green space access)    Demographic information (income, education, location)    Using this dataset, we'll explore questions such as:    How do environmental factors relate to health outcomes?    Do these relationships vary across different demographic groups?    What interventions might improve community health based on our findings?     Sample Community Health Dataset   Screenshot showing a preview of the community health and environment dataset with columns for neighborhood, health indicators, and environmental factors.      Selecting Your Own Dataset  While I'll demonstrate concepts using the Community Health dataset, you'll select and work with your own dataset throughout this course. Your chosen dataset should:    Contain at least 100 records (rows) of data    Include at least 8 variables (columns)    Include a mix of categorical and numerical data    Be complex enough to support interesting questions    Be available for download so you can work with the file    Here are some potential topics for your project:    Sports   Team or player statistics  Game outcomes  Performance metrics     Entertainment   Music streaming trends  Movie or TV ratings  Social media metrics     Local Issues   Traffic patterns  Business performance  Educational outcomes       Health & Wellness   Fitness tracking data  Nutrition databases  Public health statistics  Sleep pattern analysis     Environment & Climate   Weather patterns  Air\/water quality  Energy consumption  Biodiversity metrics     Economics & Finance   Consumer spending patterns  Housing market trends  Stock market data  Small business statistics       Technology & Innovation   Mobile app usage statistics  Technology adoption rates  Social media metrics  Internet accessibility worldwide     Transportation   Public transit ridership data  Vehicle safety statistics  Bike sharing program usage  Commuting patterns     Education & Learning   Student performance metrics  Higher education statistics  Educational technology usage  Learning outcomes by teaching method      Dataset Exploration   In this activity, you'll explore potential datasets for your project.     Visit at least two of these data repositories:    Kaggle Datasets    Data.gov    Gapminder    Data.world        Identify three potential datasets that match our criteria and interest you.      For each dataset, record in a working file for this project:    The source and a brief description    The number of records and variables    At least two questions you might investigate with this dataset       To stay on time for this project, you should have selected your dataset and begun exploring it in CODAP by the end of this week.   "
},
{
  "id": "fig-sample-dataset",
  "level": "2",
  "url": "sec-project-launch.html#fig-sample-dataset",
  "type": "Figure",
  "number": "8",
  "title": "",
  "body": " Sample Community Health Dataset   Screenshot showing a preview of the community health and environment dataset with columns for neighborhood, health indicators, and environmental factors.   "
},
{
  "id": "subsec-student-projects-5-1-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-5-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Sports "
},
{
  "id": "subsec-student-projects-5-2-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-5-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Entertainment "
},
{
  "id": "subsec-student-projects-5-3-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-5-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Local Issues "
},
{
  "id": "subsec-student-projects-6-1-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-6-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Health & Wellness "
},
{
  "id": "subsec-student-projects-6-2-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-6-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Environment & Climate "
},
{
  "id": "subsec-student-projects-6-3-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-6-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Economics & Finance "
},
{
  "id": "subsec-student-projects-7-1-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-7-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Technology & Innovation "
},
{
  "id": "subsec-student-projects-7-2-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-7-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Transportation "
},
{
  "id": "subsec-student-projects-7-3-1",
  "level": "2",
  "url": "sec-project-launch.html#subsec-student-projects-7-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Education & Learning "
},
{
  "id": "activity-dataset-exploration",
  "level": "2",
  "url": "sec-project-launch.html#activity-dataset-exploration",
  "type": "Activity",
  "number": "5",
  "title": "Dataset Exploration.",
  "body": " Dataset Exploration   In this activity, you'll explore potential datasets for your project.     Visit at least two of these data repositories:    Kaggle Datasets    Data.gov    Gapminder    Data.world        Identify three potential datasets that match our criteria and interest you.      For each dataset, record in a working file for this project:    The source and a brief description    The number of records and variables    At least two questions you might investigate with this dataset      "
},
{
  "id": "sec-data-types",
  "level": "1",
  "url": "sec-data-types.html",
  "type": "Section",
  "number": "",
  "title": "Understanding Data Types",
  "body": " Understanding Data Types   Qualitative vs. Quantitative Data  One of the most fundamental distinctions in data is between qualitative and quantitative data:     Qualitative data (also called categorical data) represents characteristics that can be observed but not measured numerically. Qualitative data can be classified into categories.       Quantitative data represents information that can be measured numerically and can be used in calculations.      Consider the following variables from our Community Health dataset:    Qualitative : Neighborhood name, zip code, predominant housing type    Quantitative : Asthma rate (%), air quality index, median household income ($), number of parks       Identifying Data Types   In this activity, you'll practice identifying qualitative and quantitative data.     For the sample Community Health dataset, identify whether each variable is qualitative or quantitative:   Neighborhood  Population density  Predominant land use  Percent green space  Average temperature (°F)  Healthcare access rating       Now examine your chosen dataset and classify each variable as qualitative or quantitative.       Identifying Data Types   Which of the following is an example of quantitative data?      Hair color    Hair color is qualitative (categorical) data as it represents a characteristic that can be categorized but not measured numerically.      Zip code    Although zip codes contain numbers, they are actually qualitative data because they represent categories (geographic regions) rather than measurements.      Height in centimeters    Correct! Height in centimeters is quantitative data because it represents a numerical measurement that can be used in calculations.      Blood type    Blood type (A, B, AB, O) is qualitative data as it represents categories rather than numerical measurements.       Measurement Scales  Data can be further classified by measurement scale, which affects what operations and analyses make sense for that data.     Nominal data represents categories with no inherent order. The only valid operation is determining equality (same or different).       Ordinal data represents categories with a meaningful order or ranking, but the differences between values may not be consistent or meaningful.       Interval data has consistent differences between values, but lacks a meaningful zero point.       Ratio data has consistent differences between values and a meaningful zero point (zero represents the absence of the quantity).      Examples from our Community Health dataset:    Nominal : Neighborhood name, predominant land use (residential, commercial, industrial, mixed)    Ordinal : Healthcare access rating (poor, fair, good, excellent), air quality category (unhealthy, moderate, good)    Interval : Temperature (°F or °C) - the difference between 70°F and 80°F is the same as between 80°F and 90°F, but 0°F doesn't represent the absence of temperature    Ratio : Asthma rate (%), income ($), number of parks, population - zero means none, and the difference between values is consistent       Understanding measurement scales helps you determine appropriate:   Summary statistics (mean, median, mode)  Visualization methods (bar charts, histograms, scatter plots)  Analysis techniques (correlation, regression, categorical tests)     Classifying by Measurement Scale   In this activity, you'll practice identifying measurement scales.     For each variable below, identify its measurement scale (nominal, ordinal, interval, or ratio):   ZIP code  Education level (no high school, high school, bachelor's, graduate)  Annual rainfall (inches)  Birth month  Satisfaction rating (1-5 scale)  Distance from city center (miles)       Now examine your chosen dataset and classify each variable by measurement scale.       Measurement Scales   Match each variable with its appropriate measurement scale.     Temperature in degrees Fahrenheit  Interval    Brand preference (Favorite soda brand)  Nominal    Customer satisfaction rating (1-5 stars)  Ordinal    Height in centimeters  Ratio    Academic letter grades (A, B, C, D, F)  Ordinal    Weight in kilograms  Ratio      Other Data Classifications  Beyond the qualitative\/quantitative and measurement scale distinctions, there are other useful ways to classify data:     Discrete data can only take specific values (usually whole numbers), while continuous data can take any value within a range.      From our Community Health dataset:    Discrete : Number of parks, number of healthcare facilities, population count    Continuous : Air quality index, median income, percent green space, asthma rate         Structured data is organized in a predefined format (like a spreadsheet or database), while unstructured data doesn't conform to a predefined data model (text, images, audio).    In this course, we'll primarily work with structured data, but it's important to know that unstructured data constitutes the majority of data generated today.   Data Type Review   Which of the following statements about data types and classifications is correct?      All numerical data is quantitative and all text data is qualitative.    Not all numerical data is quantitative. For example, zip codes are numerical but are considered qualitative (nominal) data.      Nominal and ordinal scales are types of quantitative data.    Nominal and ordinal scales are actually types of qualitative (categorical) data.      Interval data has a true zero point, while ratio data does not.    This is reversed. Ratio data has a true zero point (representing the absence of the quantity), while interval data does not.      Discrete data can only take specific values, while continuous data can take any value within a range.    Correct! Discrete data is limited to specific values (usually whole numbers), while continuous data can take any value within a range, including fractional values.         Tidy data is a specific way of organizing data where:   Each variable forms a column  Each observation forms a row  Each type of observational unit forms a table      Untidy Data   The untidy data format has values that are spread across multiple columns.     Tidy Data   The tidy data format has variables as columns and observations as rows.    Tidy data makes analysis and visualization more straightforward, as most analysis tools (including CODAP) are designed to work with data in this format.   Identifying Tidy Data   In this activity, you'll practice identifying tidy and untidy data.     Examine the following datasets in CODAP:    Open a new CODAP document    Click on \"Example Documents\" in the main menu    Open both \"Mammals\" and \"Speed Trap\"        For each dataset, determine if it follows the principles of tidy data. If not, explain what would need to change to make it tidy.      Examine your chosen project dataset. Is it in tidy format? If not, what would need to change?      "
},
{
  "id": "def-qualitative-data",
  "level": "2",
  "url": "sec-data-types.html#def-qualitative-data",
  "type": "Definition",
  "number": "9",
  "title": "",
  "body": "   Qualitative data (also called categorical data) represents characteristics that can be observed but not measured numerically. Qualitative data can be classified into categories.   "
},
{
  "id": "def-quantitative-data",
  "level": "2",
  "url": "sec-data-types.html#def-quantitative-data",
  "type": "Definition",
  "number": "10",
  "title": "",
  "body": "   Quantitative data represents information that can be measured numerically and can be used in calculations.   "
},
{
  "id": "example-qual-quant",
  "level": "2",
  "url": "sec-data-types.html#example-qual-quant",
  "type": "Example",
  "number": "11",
  "title": "",
  "body": "  Consider the following variables from our Community Health dataset:    Qualitative : Neighborhood name, zip code, predominant housing type    Quantitative : Asthma rate (%), air quality index, median household income ($), number of parks     "
},
{
  "id": "activity-identify-data-types",
  "level": "2",
  "url": "sec-data-types.html#activity-identify-data-types",
  "type": "Activity",
  "number": "6",
  "title": "Identifying Data Types.",
  "body": " Identifying Data Types   In this activity, you'll practice identifying qualitative and quantitative data.     For the sample Community Health dataset, identify whether each variable is qualitative or quantitative:   Neighborhood  Population density  Predominant land use  Percent green space  Average temperature (°F)  Healthcare access rating       Now examine your chosen dataset and classify each variable as qualitative or quantitative.    "
},
{
  "id": "mc-data-types",
  "level": "2",
  "url": "sec-data-types.html#mc-data-types",
  "type": "Checkpoint",
  "number": "12",
  "title": "Identifying Data Types.",
  "body": " Identifying Data Types   Which of the following is an example of quantitative data?      Hair color    Hair color is qualitative (categorical) data as it represents a characteristic that can be categorized but not measured numerically.      Zip code    Although zip codes contain numbers, they are actually qualitative data because they represent categories (geographic regions) rather than measurements.      Height in centimeters    Correct! Height in centimeters is quantitative data because it represents a numerical measurement that can be used in calculations.      Blood type    Blood type (A, B, AB, O) is qualitative data as it represents categories rather than numerical measurements.     "
},
{
  "id": "def-nominal",
  "level": "2",
  "url": "sec-data-types.html#def-nominal",
  "type": "Definition",
  "number": "13",
  "title": "",
  "body": "   Nominal data represents categories with no inherent order. The only valid operation is determining equality (same or different).   "
},
{
  "id": "def-ordinal",
  "level": "2",
  "url": "sec-data-types.html#def-ordinal",
  "type": "Definition",
  "number": "14",
  "title": "",
  "body": "   Ordinal data represents categories with a meaningful order or ranking, but the differences between values may not be consistent or meaningful.   "
},
{
  "id": "def-interval",
  "level": "2",
  "url": "sec-data-types.html#def-interval",
  "type": "Definition",
  "number": "15",
  "title": "",
  "body": "   Interval data has consistent differences between values, but lacks a meaningful zero point.   "
},
{
  "id": "def-ratio",
  "level": "2",
  "url": "sec-data-types.html#def-ratio",
  "type": "Definition",
  "number": "16",
  "title": "",
  "body": "   Ratio data has consistent differences between values and a meaningful zero point (zero represents the absence of the quantity).   "
},
{
  "id": "example-measurement-scales",
  "level": "2",
  "url": "sec-data-types.html#example-measurement-scales",
  "type": "Example",
  "number": "17",
  "title": "",
  "body": "  Examples from our Community Health dataset:    Nominal : Neighborhood name, predominant land use (residential, commercial, industrial, mixed)    Ordinal : Healthcare access rating (poor, fair, good, excellent), air quality category (unhealthy, moderate, good)    Interval : Temperature (°F or °C) - the difference between 70°F and 80°F is the same as between 80°F and 90°F, but 0°F doesn't represent the absence of temperature    Ratio : Asthma rate (%), income ($), number of parks, population - zero means none, and the difference between values is consistent     "
},
{
  "id": "subsec-measurement-scales-8",
  "level": "2",
  "url": "sec-data-types.html#subsec-measurement-scales-8",
  "type": "Insight",
  "number": "18",
  "title": "",
  "body": " Understanding measurement scales helps you determine appropriate:   Summary statistics (mean, median, mode)  Visualization methods (bar charts, histograms, scatter plots)  Analysis techniques (correlation, regression, categorical tests)   "
},
{
  "id": "activity-measurement-scales",
  "level": "2",
  "url": "sec-data-types.html#activity-measurement-scales",
  "type": "Activity",
  "number": "7",
  "title": "Classifying by Measurement Scale.",
  "body": " Classifying by Measurement Scale   In this activity, you'll practice identifying measurement scales.     For each variable below, identify its measurement scale (nominal, ordinal, interval, or ratio):   ZIP code  Education level (no high school, high school, bachelor's, graduate)  Annual rainfall (inches)  Birth month  Satisfaction rating (1-5 scale)  Distance from city center (miles)       Now examine your chosen dataset and classify each variable by measurement scale.    "
},
{
  "id": "matching-measurement-scales",
  "level": "2",
  "url": "sec-data-types.html#matching-measurement-scales",
  "type": "Checkpoint",
  "number": "19",
  "title": "Measurement Scales.",
  "body": " Measurement Scales   Match each variable with its appropriate measurement scale.     Temperature in degrees Fahrenheit  Interval    Brand preference (Favorite soda brand)  Nominal    Customer satisfaction rating (1-5 stars)  Ordinal    Height in centimeters  Ratio    Academic letter grades (A, B, C, D, F)  Ordinal    Weight in kilograms  Ratio    "
},
{
  "id": "def-discrete-continuous",
  "level": "2",
  "url": "sec-data-types.html#def-discrete-continuous",
  "type": "Definition",
  "number": "20",
  "title": "",
  "body": "   Discrete data can only take specific values (usually whole numbers), while continuous data can take any value within a range.   "
},
{
  "id": "example-discrete-continuous",
  "level": "2",
  "url": "sec-data-types.html#example-discrete-continuous",
  "type": "Example",
  "number": "21",
  "title": "",
  "body": "  From our Community Health dataset:    Discrete : Number of parks, number of healthcare facilities, population count    Continuous : Air quality index, median income, percent green space, asthma rate     "
},
{
  "id": "def-structured-unstructured",
  "level": "2",
  "url": "sec-data-types.html#def-structured-unstructured",
  "type": "Definition",
  "number": "22",
  "title": "",
  "body": "   Structured data is organized in a predefined format (like a spreadsheet or database), while unstructured data doesn't conform to a predefined data model (text, images, audio).   "
},
{
  "id": "mc-data-type-review",
  "level": "2",
  "url": "sec-data-types.html#mc-data-type-review",
  "type": "Checkpoint",
  "number": "23",
  "title": "Data Type Review.",
  "body": " Data Type Review   Which of the following statements about data types and classifications is correct?      All numerical data is quantitative and all text data is qualitative.    Not all numerical data is quantitative. For example, zip codes are numerical but are considered qualitative (nominal) data.      Nominal and ordinal scales are types of quantitative data.    Nominal and ordinal scales are actually types of qualitative (categorical) data.      Interval data has a true zero point, while ratio data does not.    This is reversed. Ratio data has a true zero point (representing the absence of the quantity), while interval data does not.      Discrete data can only take specific values, while continuous data can take any value within a range.    Correct! Discrete data is limited to specific values (usually whole numbers), while continuous data can take any value within a range, including fractional values.     "
},
{
  "id": "def-tidy-data",
  "level": "2",
  "url": "sec-data-types.html#def-tidy-data",
  "type": "Definition",
  "number": "24",
  "title": "",
  "body": "   Tidy data is a specific way of organizing data where:   Each variable forms a column  Each observation forms a row  Each type of observational unit forms a table    "
},
{
  "id": "fig-untidy-data",
  "level": "2",
  "url": "sec-data-types.html#fig-untidy-data",
  "type": "Figure",
  "number": "25",
  "title": "",
  "body": " Untidy Data   The untidy data format has values that are spread across multiple columns.   "
},
{
  "id": "fig-tidy-data",
  "level": "2",
  "url": "sec-data-types.html#fig-tidy-data",
  "type": "Figure",
  "number": "26",
  "title": "",
  "body": " Tidy Data   The tidy data format has variables as columns and observations as rows.   "
},
{
  "id": "activity-tidy-data",
  "level": "2",
  "url": "sec-data-types.html#activity-tidy-data",
  "type": "Activity",
  "number": "8",
  "title": "Identifying Tidy Data.",
  "body": " Identifying Tidy Data   In this activity, you'll practice identifying tidy and untidy data.     Examine the following datasets in CODAP:    Open a new CODAP document    Click on \"Example Documents\" in the main menu    Open both \"Mammals\" and \"Speed Trap\"        For each dataset, determine if it follows the principles of tidy data. If not, explain what would need to change to make it tidy.      Examine your chosen project dataset. Is it in tidy format? If not, what would need to change?    "
},
{
  "id": "sec-ethics-spotlight-data-collection",
  "level": "1",
  "url": "sec-ethics-spotlight-data-collection.html",
  "type": "Section",
  "number": "",
  "title": "Ethics Spotlight: Ethical Data Collection",
  "body": " Ethics Spotlight: Ethical Data Collection  Before we conclude Unit 1, it's important to consider the ethical dimensions of data science. The data we collect and how we collect it has real impacts on people's lives.  Key ethical considerations in data collection include:    Consent : Were people informed about how their data would be used?    Privacy : Is sensitive information protected?    Representativeness : Does the data collection process exclude certain groups?    Transparency : Is the collection process clear and documented?    Minimization : Is only necessary data collected?      In our Community Health dataset, consider these ethical questions:    Are the neighborhoods defined in ways that might reinforce historical segregation?    Does the dataset include communities that are often underrepresented in research?    Is the aggregation level appropriate to protect individual privacy while still being useful?    Were community members involved in deciding what data to collect about their neighborhoods?       Data Ethics Discussion   In this activity, we'll discuss ethical considerations for our datasets.     For the Community Health dataset, identify at least two potential ethical concerns and how you might address them.      For your chosen project dataset, consider:    What was the original purpose of this data collection?    Who collected it and how?    Who might be missing from or underrepresented in this dataset?    Are there privacy concerns with this data?       "
},
{
  "id": "sec-ethics-spotlight-data-collection-4-1-1",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#sec-ethics-spotlight-data-collection-4-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Consent "
},
{
  "id": "sec-ethics-spotlight-data-collection-4-2-1",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#sec-ethics-spotlight-data-collection-4-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Privacy "
},
{
  "id": "sec-ethics-spotlight-data-collection-4-3-1",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#sec-ethics-spotlight-data-collection-4-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Representativeness "
},
{
  "id": "sec-ethics-spotlight-data-collection-4-4-1",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#sec-ethics-spotlight-data-collection-4-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Transparency "
},
{
  "id": "sec-ethics-spotlight-data-collection-4-5-1",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#sec-ethics-spotlight-data-collection-4-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Minimization "
},
{
  "id": "example-ethics-health",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#example-ethics-health",
  "type": "Example",
  "number": "28",
  "title": "",
  "body": "  In our Community Health dataset, consider these ethical questions:    Are the neighborhoods defined in ways that might reinforce historical segregation?    Does the dataset include communities that are often underrepresented in research?    Is the aggregation level appropriate to protect individual privacy while still being useful?    Were community members involved in deciding what data to collect about their neighborhoods?     "
},
{
  "id": "activity-ethics-discussion",
  "level": "2",
  "url": "sec-ethics-spotlight-data-collection.html#activity-ethics-discussion",
  "type": "Activity",
  "number": "9",
  "title": "Data Ethics Discussion.",
  "body": " Data Ethics Discussion   In this activity, we'll discuss ethical considerations for our datasets.     For the Community Health dataset, identify at least two potential ethical concerns and how you might address them.      For your chosen project dataset, consider:    What was the original purpose of this data collection?    Who collected it and how?    Who might be missing from or underrepresented in this dataset?    Are there privacy concerns with this data?      "
},
{
  "id": "sec-unit1-summary",
  "level": "1",
  "url": "sec-unit1-summary.html",
  "type": "Section",
  "number": "",
  "title": "Unit 1 Summary",
  "body": " Unit 1 Summary  In this unit, we've explored:    What data science is and why data literacy matters    Applications of data science across different domains    The basics of CODAP, our data analysis platform    The Community Health sample project and guidelines for your own project    Different data types and classification systems    Ethical considerations in data collection    In Unit 2, we'll dive deeper into the data investigation process, learning how to formulate meaningful questions and plan our analysis.   Unit 1 Reflection   Take some time to reflect on what you've learned in this unit:    What aspect of data science interests you most and why?    What surprised you about the different types of data and their classifications?    How might data science skills be valuable in your current or future career?    What questions do you have about your project dataset so far?      "
},
{
  "id": "exercise-unit1-reflection",
  "level": "2",
  "url": "sec-unit1-summary.html#exercise-unit1-reflection",
  "type": "Checkpoint",
  "number": "30",
  "title": "Unit 1 Reflection.",
  "body": " Unit 1 Reflection   Take some time to reflect on what you've learned in this unit:    What aspect of data science interests you most and why?    What surprised you about the different types of data and their classifications?    How might data science skills be valuable in your current or future career?    What questions do you have about your project dataset so far?     "
},
{
  "id": "sec-investigation-framework",
  "level": "1",
  "url": "sec-investigation-framework.html",
  "type": "Section",
  "number": "",
  "title": "The Data Investigation Framework",
  "body": " The Data Investigation Framework   Overview of the Framework  Hollylynne Lee and her colleagues at North Carolina State University have developed a comprehensive framework for data investigations in their paper Investigating Data Like a Scientist: Key Practices and Processes that helps structure the process of working with data. This framework, seen below, provides a roadmap that can guide us through the complexity of real-world data analysis.   The Data Investigation Cycle (based on Lee et al.)   Team at NCSU's graphic for the data investigation process framework.    HIRISE Project, NC State University    The framework consists of four interconnected phases:    Ask Questions  Formulate statistical questions that can be answered with data. These questions should anticipate variability and focus on distributions rather than individual cases.    Consider Data  Evaluate available data sources, collection methods, and variables. Consider what additional data might be needed and assess the quality and appropriateness of the data for answering your questions.    Analyze Data  Apply appropriate techniques to organize, summarize, and visualize the data. This includes cleaning the data, creating meaningful representations, and identifying patterns.    Interpret Results  Make claims based on the evidence from your analysis, acknowledge limitations, and consider implications. This often leads to new questions, continuing the cycle.    While the framework is presented as a cycle, real investigations rarely follows that circle perfectly. You might need to revisit earlier phases as you gain insights or encounter challenges. Iteration is essential in data analysis.   Data Investigation Phases   During which phase of the data investigation framework would you typically clean the dataset by handling missing values?      Ask Questions    The Ask Questions phase focuses on formulating statistical questions, not on cleaning data.      Consider Data    While you might identify data quality issues during the Consider Data phase, actual cleaning typically happens during analysis.      Analyze Data    Correct! Data cleaning is part of the Analyze Data phase, where you prepare and transform the data for meaningful analysis.      Interpret Results    The Interpret Results phase focuses on drawing conclusions from the analysis, not on cleaning the data.        The Framework in Practice  Let's see how this framework might apply to our Community Health and Environment project:   Community Health Investigation    Ask Questions : How does air quality relate to asthma rates across different neighborhoods? Do these relationships differ based on income levels?   Consider Data : Our dataset includes air quality measurements, asthma prevalence rates, and median household income for various neighborhoods. We need to consider how air quality was measured, whether measurements were taken consistently, and if there are confounding variables we should account for.   Analyze Data : We might create scatterplots of air quality versus asthma rates, calculate correlation coefficients, and group neighborhoods by income levels to compare patterns. We'd also need to handle any missing values or outliers.   Interpret Results : Based on our analysis, we might find that neighborhoods with poorer air quality tend to have higher asthma rates, and this relationship could be stronger in lower-income areas. We'd need to acknowledge limitations (correlation doesn't imply causation) and consider implications for public health policy.    The framework helps ensure that we approach data investigations systematically, considering crucial aspects at each stage. It also highlights the iterative nature of data analysis—insights from later phases often prompt us to refine our questions or seek additional data.   Applying the Framework   In this activity, you'll apply the data investigation framework to your chosen project dataset.     For your chosen dataset, brainstorm at least three potential statistical questions you could investigate.      For one of your questions, outline what you would do in each phase of the data investigation framework.      Identify at least one challenge you might face in each phase and how you might address it.      Framework Activities   Match each data science activity with the most appropriate phase of the data investigation framework.     Creating a histogram of income distribution  Analyze Data    Determining whether survey respondents are representative of the population  Consider Data    Wondering if exercise habits differ by age group  Ask Questions    Concluding that the data doesn't support the original hypothesis  Interpret Results    Deciding to collect additional measurements  Consider Data    Calculating the correlation between temperature and energy use  Analyze Data      "
},
{
  "id": "fig-lee-framework",
  "level": "2",
  "url": "sec-investigation-framework.html#fig-lee-framework",
  "type": "Figure",
  "number": "31",
  "title": "",
  "body": " The Data Investigation Cycle (based on Lee et al.)   Team at NCSU's graphic for the data investigation process framework.    HIRISE Project, NC State University   "
},
{
  "id": "mc-framework-phases",
  "level": "2",
  "url": "sec-investigation-framework.html#mc-framework-phases",
  "type": "Checkpoint",
  "number": "32",
  "title": "Data Investigation Phases.",
  "body": " Data Investigation Phases   During which phase of the data investigation framework would you typically clean the dataset by handling missing values?      Ask Questions    The Ask Questions phase focuses on formulating statistical questions, not on cleaning data.      Consider Data    While you might identify data quality issues during the Consider Data phase, actual cleaning typically happens during analysis.      Analyze Data    Correct! Data cleaning is part of the Analyze Data phase, where you prepare and transform the data for meaningful analysis.      Interpret Results    The Interpret Results phase focuses on drawing conclusions from the analysis, not on cleaning the data.     "
},
{
  "id": "example-framework-health",
  "level": "2",
  "url": "sec-investigation-framework.html#example-framework-health",
  "type": "Example",
  "number": "33",
  "title": "Community Health Investigation.",
  "body": " Community Health Investigation    Ask Questions : How does air quality relate to asthma rates across different neighborhoods? Do these relationships differ based on income levels?   Consider Data : Our dataset includes air quality measurements, asthma prevalence rates, and median household income for various neighborhoods. We need to consider how air quality was measured, whether measurements were taken consistently, and if there are confounding variables we should account for.   Analyze Data : We might create scatterplots of air quality versus asthma rates, calculate correlation coefficients, and group neighborhoods by income levels to compare patterns. We'd also need to handle any missing values or outliers.   Interpret Results : Based on our analysis, we might find that neighborhoods with poorer air quality tend to have higher asthma rates, and this relationship could be stronger in lower-income areas. We'd need to acknowledge limitations (correlation doesn't imply causation) and consider implications for public health policy.   "
},
{
  "id": "activity-apply-framework",
  "level": "2",
  "url": "sec-investigation-framework.html#activity-apply-framework",
  "type": "Activity",
  "number": "10",
  "title": "Applying the Framework.",
  "body": " Applying the Framework   In this activity, you'll apply the data investigation framework to your chosen project dataset.     For your chosen dataset, brainstorm at least three potential statistical questions you could investigate.      For one of your questions, outline what you would do in each phase of the data investigation framework.      Identify at least one challenge you might face in each phase and how you might address it.    "
},
{
  "id": "matching-framework-activities",
  "level": "2",
  "url": "sec-investigation-framework.html#matching-framework-activities",
  "type": "Checkpoint",
  "number": "34",
  "title": "Framework Activities.",
  "body": " Framework Activities   Match each data science activity with the most appropriate phase of the data investigation framework.     Creating a histogram of income distribution  Analyze Data    Determining whether survey respondents are representative of the population  Consider Data    Wondering if exercise habits differ by age group  Ask Questions    Concluding that the data doesn't support the original hypothesis  Interpret Results    Deciding to collect additional measurements  Consider Data    Calculating the correlation between temperature and energy use  Analyze Data    "
},
{
  "id": "sec-statistical-questions",
  "level": "1",
  "url": "sec-statistical-questions.html",
  "type": "Section",
  "number": "",
  "title": "Formulating Statistical Questions",
  "body": " Formulating Statistical Questions   What Makes a Question Statistical?  Not all questions are statistical questions. A statistical question is one that can be answered by collecting data and where we expect variability in that data.    A statistical question is a question that anticipates variability in the data related to it and can be answered by analyzing data. It usually addresses patterns, trends, or relationships in a group or population rather than specific individuals.     Statistical vs. Non-Statistical Questions   Non-statistical questions typically have a single, deterministic answer:    How tall is Jamal? (Asks about a specific individual)    What is the capital of France? (Has a definitive answer)    Did it rain yesterday? (Yes\/no factual question)    Statistical questions anticipate variability and focus on distributions:    How tall are 7th-grade students at Lincoln Middle School? (Expects variation in heights)    What is the relationship between a country's GDP and its literacy rate? (Examines patterns across countries)    How does rainfall vary by month in Seattle? (Looks at distribution over time)       Identifying Statistical Questions   Which of the following is a statistical question?      What is the temperature right now?    This is not a statistical question because it asks for a single measurement at a specific point in time, not a distribution or pattern.      How many siblings does Maria have?    This is not a statistical question because it asks about a specific individual and has a single answer.      How does commute time vary among employees at a company?    Correct! This is a statistical question because it anticipates variability (different commute times) and requires analyzing data from a group.      Is 15 minutes a long time to wait for a bus?    This is not a statistical question because it asks for a subjective judgment rather than something that can be answered directly with data.      Good statistical questions are the foundation of effective data investigations. They guide the entire process, from data collection to analysis and interpretation.    Crafting Effective Statistical Questions  Effective statistical questions have several key characteristics:    Clear and specific : Precisely defines what you want to know and what population you're studying    Answerable with data : Can be investigated through data collection and analysis    Anticipates variability : Expects a distribution of values rather than a single answer    Meaningful : Addresses something worth investigating and has potential implications    Neutral : Doesn't presuppose a particular answer or bias the investigation     Refining Statistical Questions   Consider how we might refine these initial questions to make them more effective:    Initial : Is air pollution bad for health?  Refined : What is the relationship between average annual air quality index (AQI) and asthma hospitalization rates across neighborhoods in our city over the past five years?    Initial : Do parks make neighborhoods healthier?  Refined : How does the percentage of green space in a neighborhood correlate with residents' self-reported physical activity levels, controlling for median income?    Initial : Which neighborhood has the worst environmental health?  Refined : How do neighborhoods compare across multiple environmental health indicators (air quality, water quality, access to green space, and proximity to pollution sources), and what patterns emerge when considering demographic factors?      Notice how the refined questions are more specific about what is being measured, the population being studied, and the relationships being investigated. They also avoid loaded terms like \"bad\" or \"worst\" that might bias the investigation.   Refining Your Questions   In this activity, you'll work on developing effective statistical questions for your project.     Review the statistical questions you brainstormed in the previous activity. Select one that you think has the most potential.      Refine your selected question using the characteristics of effective statistical questions. Make it clearer, more specific, and more answerable with data.      Share your refined question with a classmate and provide feedback on each other's questions.      Improving Statistical Questions   For each initial question below, select the most improved version that follows the principles of effective statistical questions.     Question 1: Initial question: Are students getting enough sleep?  Select the most improved version of this question:    a . Should students get more sleep?    b . What is the distribution of nightly sleep duration among high school students, and how does it compare to recommended amounts for adolescents?    c . Why don't students get enough sleep?    d . Who sleeps the most in the sophomore class?    Question 2: Initial question: Does income affect health?  Select the most improved version of this question:    a . Is it fair that rich people are healthier?    b . What is John's income and health status?    c . How do rates of chronic diseases vary across different income brackets in the United States, and has this relationship changed over the past decade?    d . Why do poor people have worse health outcomes?     Think about what makes a good statistical question: it should be specific, measurable, and free from assumptions or value judgments.             Question 1: The best improved version is: What is the distribution of nightly sleep duration among high school students, and how does it compare to recommended amounts for adolescents?  This question is specific about what is being measured (sleep duration), the population (high school students), and includes a comparison to a standard.  Question 2: The best improved version is: How do rates of chronic diseases vary across different income brackets in the United States, and has this relationship changed over the past decade?  This question is specific about the variables (chronic disease rates, income brackets), the population (United States), and adds a time dimension for additional insight.         "
},
{
  "id": "def-statistical-question",
  "level": "2",
  "url": "sec-statistical-questions.html#def-statistical-question",
  "type": "Definition",
  "number": "35",
  "title": "",
  "body": "  A statistical question is a question that anticipates variability in the data related to it and can be answered by analyzing data. It usually addresses patterns, trends, or relationships in a group or population rather than specific individuals.   "
},
{
  "id": "example-stat-vs-nonstat",
  "level": "2",
  "url": "sec-statistical-questions.html#example-stat-vs-nonstat",
  "type": "Example",
  "number": "36",
  "title": "Statistical vs. Non-Statistical Questions.",
  "body": " Statistical vs. Non-Statistical Questions   Non-statistical questions typically have a single, deterministic answer:    How tall is Jamal? (Asks about a specific individual)    What is the capital of France? (Has a definitive answer)    Did it rain yesterday? (Yes\/no factual question)    Statistical questions anticipate variability and focus on distributions:    How tall are 7th-grade students at Lincoln Middle School? (Expects variation in heights)    What is the relationship between a country's GDP and its literacy rate? (Examines patterns across countries)    How does rainfall vary by month in Seattle? (Looks at distribution over time)     "
},
{
  "id": "mc-identify-stat-questions",
  "level": "2",
  "url": "sec-statistical-questions.html#mc-identify-stat-questions",
  "type": "Checkpoint",
  "number": "37",
  "title": "Identifying Statistical Questions.",
  "body": " Identifying Statistical Questions   Which of the following is a statistical question?      What is the temperature right now?    This is not a statistical question because it asks for a single measurement at a specific point in time, not a distribution or pattern.      How many siblings does Maria have?    This is not a statistical question because it asks about a specific individual and has a single answer.      How does commute time vary among employees at a company?    Correct! This is a statistical question because it anticipates variability (different commute times) and requires analyzing data from a group.      Is 15 minutes a long time to wait for a bus?    This is not a statistical question because it asks for a subjective judgment rather than something that can be answered directly with data.     "
},
{
  "id": "subsec-crafting-questions-3-1-1",
  "level": "2",
  "url": "sec-statistical-questions.html#subsec-crafting-questions-3-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Clear and specific "
},
{
  "id": "subsec-crafting-questions-3-2-1",
  "level": "2",
  "url": "sec-statistical-questions.html#subsec-crafting-questions-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Answerable with data "
},
{
  "id": "subsec-crafting-questions-3-3-1",
  "level": "2",
  "url": "sec-statistical-questions.html#subsec-crafting-questions-3-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Anticipates variability "
},
{
  "id": "subsec-crafting-questions-3-4-1",
  "level": "2",
  "url": "sec-statistical-questions.html#subsec-crafting-questions-3-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Meaningful "
},
{
  "id": "subsec-crafting-questions-3-5-1",
  "level": "2",
  "url": "sec-statistical-questions.html#subsec-crafting-questions-3-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Neutral "
},
{
  "id": "example-refining-questions",
  "level": "2",
  "url": "sec-statistical-questions.html#example-refining-questions",
  "type": "Example",
  "number": "38",
  "title": "Refining Statistical Questions.",
  "body": " Refining Statistical Questions   Consider how we might refine these initial questions to make them more effective:    Initial : Is air pollution bad for health?  Refined : What is the relationship between average annual air quality index (AQI) and asthma hospitalization rates across neighborhoods in our city over the past five years?    Initial : Do parks make neighborhoods healthier?  Refined : How does the percentage of green space in a neighborhood correlate with residents' self-reported physical activity levels, controlling for median income?    Initial : Which neighborhood has the worst environmental health?  Refined : How do neighborhoods compare across multiple environmental health indicators (air quality, water quality, access to green space, and proximity to pollution sources), and what patterns emerge when considering demographic factors?     "
},
{
  "id": "activity-refine-questions",
  "level": "2",
  "url": "sec-statistical-questions.html#activity-refine-questions",
  "type": "Activity",
  "number": "11",
  "title": "Refining Your Questions.",
  "body": " Refining Your Questions   In this activity, you'll work on developing effective statistical questions for your project.     Review the statistical questions you brainstormed in the previous activity. Select one that you think has the most potential.      Refine your selected question using the characteristics of effective statistical questions. Make it clearer, more specific, and more answerable with data.      Share your refined question with a classmate and provide feedback on each other's questions.    "
},
{
  "id": "exercise-improve-questions",
  "level": "2",
  "url": "sec-statistical-questions.html#exercise-improve-questions",
  "type": "Checkpoint",
  "number": "39",
  "title": "Improving Statistical Questions.",
  "body": " Improving Statistical Questions   For each initial question below, select the most improved version that follows the principles of effective statistical questions.     Question 1: Initial question: Are students getting enough sleep?  Select the most improved version of this question:    a . Should students get more sleep?    b . What is the distribution of nightly sleep duration among high school students, and how does it compare to recommended amounts for adolescents?    c . Why don't students get enough sleep?    d . Who sleeps the most in the sophomore class?    Question 2: Initial question: Does income affect health?  Select the most improved version of this question:    a . Is it fair that rich people are healthier?    b . What is John's income and health status?    c . How do rates of chronic diseases vary across different income brackets in the United States, and has this relationship changed over the past decade?    d . Why do poor people have worse health outcomes?     Think about what makes a good statistical question: it should be specific, measurable, and free from assumptions or value judgments.             Question 1: The best improved version is: What is the distribution of nightly sleep duration among high school students, and how does it compare to recommended amounts for adolescents?  This question is specific about what is being measured (sleep duration), the population (high school students), and includes a comparison to a standard.  Question 2: The best improved version is: How do rates of chronic diseases vary across different income brackets in the United States, and has this relationship changed over the past decade?  This question is specific about the variables (chronic disease rates, income brackets), the population (United States), and adds a time dimension for additional insight.       "
},
{
  "id": "sec-planning-investigation",
  "level": "1",
  "url": "sec-planning-investigation.html",
  "type": "Section",
  "number": "",
  "title": "Planning an Investigation",
  "body": " Planning an Investigation   Elements of an Investigation Plan  A well-structured data investigation plan helps guide your analysis and ensures you consider all important aspects before diving into the data. Key elements of an investigation plan include:    Research Questions  The statistical questions you aim to answer, clearly stated and refined.    Data Requirements  The specific variables, measurements, and data sources needed to answer your questions.    Data Assessment  Evaluation of the available data's quality, completeness, and appropriateness for your questions.    Analysis Approach  The methods and techniques you plan to use for data cleaning, exploration, visualization, and statistical analysis.    Potential Challenges  Anticipated difficulties and limitations, along with strategies to address them.    Expected Outcomes  What you hope to learn and how you might apply the findings.     Organizing an Investigation Plan   Arrange the following steps in a logical order for planning a data investigation.     Formulate clear statistical questions based on your area of interest.     Begin analyzing the data immediately to save time.    Identify what specific variables and data you need to answer your questions.    Create visualizations before examining the data quality.     Assess whether the available data is suitable and of sufficient quality.    Determine appropriate methods for cleaning, visualizing, and analyzing the data.    Identify potential limitations and challenges in your investigation.    Skip directly to writing conclusions without analyzing the data.     Think about what information you need to know before you can determine your analysis methods.    A thoughtful investigation plan serves as a roadmap for your analysis, though you should be prepared to adapt it as you learn more about the data and discover unexpected patterns or challenges.    Sample Investigation Plan  Let's look at a sample investigation plan for our Community Health and Environment project:   Community Health Investigation Plan    Research Questions :   What is the relationship between air quality index (AQI) and asthma rates across neighborhoods?    How does access to green space correlate with obesity rates, controlling for neighborhood income?    Are there clusters of neighborhoods with similar environmental health profiles, and how do these clusters relate to demographic factors?      Data Requirements :   Neighborhood-level data on air quality measurements (annual average AQI)    Asthma prevalence rates by neighborhood    Green space access metrics (percentage of area, proximity to parks)    Obesity rates by neighborhood    Median household income by neighborhood    Additional environmental health indicators (water quality, proximity to pollution sources)    Demographic information (age distribution, racial\/ethnic composition)      Data Assessment :   Our dataset includes most required variables but lacks detailed green space metrics    Some neighborhoods have missing data for certain health indicators    Air quality measurements were taken at different times of year across neighborhoods    Need to verify that health data is age-adjusted for fair comparison      Analysis Approach :   Data cleaning: Handle missing values, check for outliers, standardize variables    Exploratory analysis: Create scatter plots, histograms, and maps to visualize distributions and relationships    Calculate correlation coefficients between environmental factors and health outcomes    Perform regression analysis to examine relationships while controlling for income    Use cluster analysis to identify neighborhoods with similar environmental health profiles      Potential Challenges :   Missing data might bias results if not handled appropriately    Correlation doesn't imply causation; many confounding variables might exist    Neighborhood boundaries might not align perfectly with environmental exposure patterns    Limited sample size (number of neighborhoods) might affect statistical power      Expected Outcomes :   Identification of environmental factors most strongly associated with health outcomes    Understanding of how socioeconomic factors interact with environmental exposures    Visualization of environmental health disparities across the city    Insights that could inform targeted public health interventions       This plan provides a comprehensive framework for the investigation, identifying key questions, necessary data, analytical approaches, and potential limitations. It serves as a guide but remains flexible enough to adapt as the investigation proceeds.   Developing Your Investigation Plan   In this activity, you'll develop an investigation plan for your own dataset.     Using the refined statistical questions from the previous activity, outline a complete investigation plan following the structure of the sample plan.      Assess your dataset critically. Does it contain all the variables you need? Are there quality issues you need to address?      Specify at least three analysis techniques you plan to use and why they're appropriate for your research questions.      Identifying Data Requirements   To investigate the question \"How does public transportation usage vary with income level across neighborhoods?\", which of the following variables would be LEAST essential?      Average number of public transportation trips per resident by neighborhood    This is a key measure of public transportation usage, which is central to the research question.      Median household income by neighborhood    Income level is explicitly mentioned in the research question, making this variable essential.      Average home value by neighborhood    Correct! While home value might correlate with income, it's not directly mentioned in the research question and is less essential than variables that directly measure transportation usage and income.      Availability of public transportation (e.g., bus stops per square mile) by neighborhood    This is important to consider because availability can influence usage, making it a potential confounding variable that should be accounted for.       "
},
{
  "id": "parsons-investigation-plan",
  "level": "2",
  "url": "sec-planning-investigation.html#parsons-investigation-plan",
  "type": "Checkpoint",
  "number": "40",
  "title": "Organizing an Investigation Plan.",
  "body": " Organizing an Investigation Plan   Arrange the following steps in a logical order for planning a data investigation.     Formulate clear statistical questions based on your area of interest.     Begin analyzing the data immediately to save time.    Identify what specific variables and data you need to answer your questions.    Create visualizations before examining the data quality.     Assess whether the available data is suitable and of sufficient quality.    Determine appropriate methods for cleaning, visualizing, and analyzing the data.    Identify potential limitations and challenges in your investigation.    Skip directly to writing conclusions without analyzing the data.     Think about what information you need to know before you can determine your analysis methods.   "
},
{
  "id": "example-health-plan",
  "level": "2",
  "url": "sec-planning-investigation.html#example-health-plan",
  "type": "Example",
  "number": "41",
  "title": "Community Health Investigation Plan.",
  "body": " Community Health Investigation Plan    Research Questions :   What is the relationship between air quality index (AQI) and asthma rates across neighborhoods?    How does access to green space correlate with obesity rates, controlling for neighborhood income?    Are there clusters of neighborhoods with similar environmental health profiles, and how do these clusters relate to demographic factors?      Data Requirements :   Neighborhood-level data on air quality measurements (annual average AQI)    Asthma prevalence rates by neighborhood    Green space access metrics (percentage of area, proximity to parks)    Obesity rates by neighborhood    Median household income by neighborhood    Additional environmental health indicators (water quality, proximity to pollution sources)    Demographic information (age distribution, racial\/ethnic composition)      Data Assessment :   Our dataset includes most required variables but lacks detailed green space metrics    Some neighborhoods have missing data for certain health indicators    Air quality measurements were taken at different times of year across neighborhoods    Need to verify that health data is age-adjusted for fair comparison      Analysis Approach :   Data cleaning: Handle missing values, check for outliers, standardize variables    Exploratory analysis: Create scatter plots, histograms, and maps to visualize distributions and relationships    Calculate correlation coefficients between environmental factors and health outcomes    Perform regression analysis to examine relationships while controlling for income    Use cluster analysis to identify neighborhoods with similar environmental health profiles      Potential Challenges :   Missing data might bias results if not handled appropriately    Correlation doesn't imply causation; many confounding variables might exist    Neighborhood boundaries might not align perfectly with environmental exposure patterns    Limited sample size (number of neighborhoods) might affect statistical power      Expected Outcomes :   Identification of environmental factors most strongly associated with health outcomes    Understanding of how socioeconomic factors interact with environmental exposures    Visualization of environmental health disparities across the city    Insights that could inform targeted public health interventions      "
},
{
  "id": "activity-develop-plan",
  "level": "2",
  "url": "sec-planning-investigation.html#activity-develop-plan",
  "type": "Activity",
  "number": "12",
  "title": "Developing Your Investigation Plan.",
  "body": " Developing Your Investigation Plan   In this activity, you'll develop an investigation plan for your own dataset.     Using the refined statistical questions from the previous activity, outline a complete investigation plan following the structure of the sample plan.      Assess your dataset critically. Does it contain all the variables you need? Are there quality issues you need to address?      Specify at least three analysis techniques you plan to use and why they're appropriate for your research questions.    "
},
{
  "id": "mc-data-requirements",
  "level": "2",
  "url": "sec-planning-investigation.html#mc-data-requirements",
  "type": "Checkpoint",
  "number": "42",
  "title": "Identifying Data Requirements.",
  "body": " Identifying Data Requirements   To investigate the question \"How does public transportation usage vary with income level across neighborhoods?\", which of the following variables would be LEAST essential?      Average number of public transportation trips per resident by neighborhood    This is a key measure of public transportation usage, which is central to the research question.      Median household income by neighborhood    Income level is explicitly mentioned in the research question, making this variable essential.      Average home value by neighborhood    Correct! While home value might correlate with income, it's not directly mentioned in the research question and is less essential than variables that directly measure transportation usage and income.      Availability of public transportation (e.g., bus stops per square mile) by neighborhood    This is important to consider because availability can influence usage, making it a potential confounding variable that should be accounted for.     "
},
{
  "id": "sec-statistical-thinking",
  "level": "1",
  "url": "sec-statistical-thinking.html",
  "type": "Section",
  "number": "",
  "title": "Statistical Thinking: Understanding Variability",
  "body": " Statistical Thinking: Understanding Variability   Key Concepts in Variability  Statistical thinking is a way of approaching problems that acknowledges and accounts for variability. Understanding variability is essential for interpreting data and making informed decisions.     Variability refers to the extent to which data points in a set differ from each other and from measures of central tendency. It is an inherent characteristic of data that arises from multiple sources.    Several key concepts help us understand and quantify variability:    Measures of Center  Statistics like mean, median, and mode that describe typical values in a distribution.    Measures of Spread  Statistics like range, interquartile range, variance, and standard deviation that quantify the amount of variability.    Distribution Shape  The pattern of variation in a dataset, which might be symmetric, skewed, uniform, bimodal, or follow a specific distribution like normal.    Sources of Variability  Factors that contribute to differences in observations, including natural variation, measurement error, and sampling methods.     Visualizing Variability in Distributions   Three histograms showing distributions with different variability: low, medium, and high. All have the same mean but different spread.     Understanding Variability   Which of the following statements about variability is TRUE?      High variability in a dataset always indicates a problem with data collection.    This is not true. High variability might be a natural characteristic of the phenomenon being studied, not necessarily an indication of problems with data collection.      The mean is always the best measure of central tendency regardless of variability.    This is not true. When data is highly skewed or contains outliers, the median may be a more appropriate measure of central tendency.      Two datasets with the same mean must have the same standard deviation.    This is not true. Datasets with the same mean can have vastly different spread or variability, resulting in different standard deviations.      Understanding variability is essential for making appropriate inferences from data.    Correct! Acknowledging and accounting for variability is a fundamental aspect of statistical thinking and is crucial for proper data interpretation.        Accounting for Variability in Data Analysis  When conducting data investigations, we need to consider variability at every stage:    When asking questions : Formulate questions that acknowledge and explore variability    When considering data : Evaluate how sampling methods might affect variability    When analyzing data : Use appropriate visualizations and statistics to represent variability    When interpreting results : Consider how variability affects the strength and reliability of conclusions     Variability in Community Health Data   In our Community Health dataset, we might observe that:    Asthma rates vary considerably across neighborhoods (spatial variability)    Air quality measurements fluctuate seasonally (temporal variability)    The relationship between green space and obesity is stronger in some demographic groups than others (variability in relationships)    Some health metrics have greater measurement uncertainty than others (variability due to measurement)    Acknowledging these sources of variability helps us avoid oversimplified conclusions and recognize the complexity of environmental health relationships.     Exploring Variability in Your Dataset   In this activity, you'll explore sources of variability in your chosen dataset.     Identify at least three variables in your dataset and use CODAP to create visualizations showing their distributions.      For each variable, describe the pattern of variability you observe. Is the distribution symmetric, skewed, uniform, bimodal, or something else?      Consider what might cause the variability you're seeing. Is it natural variation in the phenomenon, differences between groups, measurement issues, or something else?      Measures of Variability   Match each statistical measure with the aspect of variability it best represents.     Standard deviation  Average distance of values from the mean    Interquartile range (IQR)  Spread of the middle 50% of the data    Range  Difference between the maximum and minimum values    Variance  Average of squared deviations from the mean    Coefficient of variation  Standard deviation relative to the mean      "
},
{
  "id": "def-variability",
  "level": "2",
  "url": "sec-statistical-thinking.html#def-variability",
  "type": "Definition",
  "number": "43",
  "title": "",
  "body": "   Variability refers to the extent to which data points in a set differ from each other and from measures of central tendency. It is an inherent characteristic of data that arises from multiple sources.   "
},
{
  "id": "fig-variability-visualized",
  "level": "2",
  "url": "sec-statistical-thinking.html#fig-variability-visualized",
  "type": "Figure",
  "number": "44",
  "title": "",
  "body": " Visualizing Variability in Distributions   Three histograms showing distributions with different variability: low, medium, and high. All have the same mean but different spread.   "
},
{
  "id": "mc-variability-concepts",
  "level": "2",
  "url": "sec-statistical-thinking.html#mc-variability-concepts",
  "type": "Checkpoint",
  "number": "45",
  "title": "Understanding Variability.",
  "body": " Understanding Variability   Which of the following statements about variability is TRUE?      High variability in a dataset always indicates a problem with data collection.    This is not true. High variability might be a natural characteristic of the phenomenon being studied, not necessarily an indication of problems with data collection.      The mean is always the best measure of central tendency regardless of variability.    This is not true. When data is highly skewed or contains outliers, the median may be a more appropriate measure of central tendency.      Two datasets with the same mean must have the same standard deviation.    This is not true. Datasets with the same mean can have vastly different spread or variability, resulting in different standard deviations.      Understanding variability is essential for making appropriate inferences from data.    Correct! Acknowledging and accounting for variability is a fundamental aspect of statistical thinking and is crucial for proper data interpretation.     "
},
{
  "id": "subsec-variability-in-analysis-3-1-1",
  "level": "2",
  "url": "sec-statistical-thinking.html#subsec-variability-in-analysis-3-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "When asking questions "
},
{
  "id": "subsec-variability-in-analysis-3-2-1",
  "level": "2",
  "url": "sec-statistical-thinking.html#subsec-variability-in-analysis-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "When considering data "
},
{
  "id": "subsec-variability-in-analysis-3-3-1",
  "level": "2",
  "url": "sec-statistical-thinking.html#subsec-variability-in-analysis-3-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "When analyzing data "
},
{
  "id": "subsec-variability-in-analysis-3-4-1",
  "level": "2",
  "url": "sec-statistical-thinking.html#subsec-variability-in-analysis-3-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "When interpreting results "
},
{
  "id": "example-variability-health",
  "level": "2",
  "url": "sec-statistical-thinking.html#example-variability-health",
  "type": "Example",
  "number": "46",
  "title": "Variability in Community Health Data.",
  "body": " Variability in Community Health Data   In our Community Health dataset, we might observe that:    Asthma rates vary considerably across neighborhoods (spatial variability)    Air quality measurements fluctuate seasonally (temporal variability)    The relationship between green space and obesity is stronger in some demographic groups than others (variability in relationships)    Some health metrics have greater measurement uncertainty than others (variability due to measurement)    Acknowledging these sources of variability helps us avoid oversimplified conclusions and recognize the complexity of environmental health relationships.   "
},
{
  "id": "activity-explore-variability",
  "level": "2",
  "url": "sec-statistical-thinking.html#activity-explore-variability",
  "type": "Activity",
  "number": "13",
  "title": "Exploring Variability in Your Dataset.",
  "body": " Exploring Variability in Your Dataset   In this activity, you'll explore sources of variability in your chosen dataset.     Identify at least three variables in your dataset and use CODAP to create visualizations showing their distributions.      For each variable, describe the pattern of variability you observe. Is the distribution symmetric, skewed, uniform, bimodal, or something else?      Consider what might cause the variability you're seeing. Is it natural variation in the phenomenon, differences between groups, measurement issues, or something else?    "
},
{
  "id": "matching-variability-measures",
  "level": "2",
  "url": "sec-statistical-thinking.html#matching-variability-measures",
  "type": "Checkpoint",
  "number": "47",
  "title": "Measures of Variability.",
  "body": " Measures of Variability   Match each statistical measure with the aspect of variability it best represents.     Standard deviation  Average distance of values from the mean    Interquartile range (IQR)  Spread of the middle 50% of the data    Range  Difference between the maximum and minimum values    Variance  Average of squared deviations from the mean    Coefficient of variation  Standard deviation relative to the mean    "
},
{
  "id": "sec-ethics-spotlight-sampling",
  "level": "1",
  "url": "sec-ethics-spotlight-sampling.html",
  "type": "Section",
  "number": "",
  "title": "Ethics Spotlight: Representation in Data",
  "body": " Ethics Spotlight: Representation in Data  As we plan our data investigations, it's crucial to consider who is represented in our data and who might be missing or underrepresented.  Key ethical considerations regarding representation include:    Selection bias : Does our data systematically exclude certain groups?    Sampling fairness : Does our sample adequately represent diverse populations?    Historical exclusion : Are we working with data that reflects historical patterns of exclusion?    Appropriate categorization : Do our categories respect how people identify themselves?    Contextual interpretation : Are we considering social and historical context when interpreting group differences?     Representation in Community Health Data   In our Community Health dataset, we might need to consider:    Whether health surveys reached residents who don't speak English    If environmental monitoring stations are distributed equitably across neighborhoods    Whether certain communities have historically been excluded from public health research    If the neighborhood boundaries used in our analysis reflect meaningful community divisions    How to interpret health disparities without reinforcing harmful stereotypes       Data Representation Scenarios   For each scenario, identify the primary ethical concern related to representation in data.     Scenario 1: A city collects feedback about public services through an online survey that requires a smartphone and internet access.  What is the primary ethical concern in this scenario?    a . Selection bias    b . Privacy violation    c . Inappropriate categorization    d . Excessive data collection    Scenario 2: A medical research study examines health outcomes using patient data from university hospitals in affluent neighborhoods.  What is the primary ethical concern in this scenario?    a . Inappropriate categorization    b . Sampling fairness    c . Data security    d . Transparency     Consider who might be included or excluded from each data collection approach, and how that might affect the conclusions drawn from the data.             Scenario 1: The primary ethical concern is Selection bias.  This method systematically excludes residents without smartphones or internet access, creating selection bias that likely underrepresents lower-income or elderly populations.  Scenario 2: The primary ethical concern is Sampling fairness.  The sample is biased toward patients who have access to university hospitals in affluent areas, potentially missing health patterns in underserved communities.         Evaluating Representation in Your Dataset   In this activity, you'll critically examine representation issues in your chosen dataset.     Identify at least three ways in which your dataset might not fully represent the population you're interested in studying.      Consider how these representation issues might affect the conclusions you can draw from your analysis.      Propose at least two strategies for acknowledging or addressing these representation issues in your investigation.     "
},
{
  "id": "sec-ethics-spotlight-sampling-4-1-1",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#sec-ethics-spotlight-sampling-4-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Selection bias "
},
{
  "id": "sec-ethics-spotlight-sampling-4-2-1",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#sec-ethics-spotlight-sampling-4-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Sampling fairness "
},
{
  "id": "sec-ethics-spotlight-sampling-4-3-1",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#sec-ethics-spotlight-sampling-4-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Historical exclusion "
},
{
  "id": "sec-ethics-spotlight-sampling-4-4-1",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#sec-ethics-spotlight-sampling-4-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Appropriate categorization "
},
{
  "id": "sec-ethics-spotlight-sampling-4-5-1",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#sec-ethics-spotlight-sampling-4-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Contextual interpretation "
},
{
  "id": "example-ethics-representation",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#example-ethics-representation",
  "type": "Example",
  "number": "48",
  "title": "Representation in Community Health Data.",
  "body": " Representation in Community Health Data   In our Community Health dataset, we might need to consider:    Whether health surveys reached residents who don't speak English    If environmental monitoring stations are distributed equitably across neighborhoods    Whether certain communities have historically been excluded from public health research    If the neighborhood boundaries used in our analysis reflect meaningful community divisions    How to interpret health disparities without reinforcing harmful stereotypes     "
},
{
  "id": "exercise-ethics-scenarios",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#exercise-ethics-scenarios",
  "type": "Checkpoint",
  "number": "49",
  "title": "Data Representation Scenarios.",
  "body": " Data Representation Scenarios   For each scenario, identify the primary ethical concern related to representation in data.     Scenario 1: A city collects feedback about public services through an online survey that requires a smartphone and internet access.  What is the primary ethical concern in this scenario?    a . Selection bias    b . Privacy violation    c . Inappropriate categorization    d . Excessive data collection    Scenario 2: A medical research study examines health outcomes using patient data from university hospitals in affluent neighborhoods.  What is the primary ethical concern in this scenario?    a . Inappropriate categorization    b . Sampling fairness    c . Data security    d . Transparency     Consider who might be included or excluded from each data collection approach, and how that might affect the conclusions drawn from the data.             Scenario 1: The primary ethical concern is Selection bias.  This method systematically excludes residents without smartphones or internet access, creating selection bias that likely underrepresents lower-income or elderly populations.  Scenario 2: The primary ethical concern is Sampling fairness.  The sample is biased toward patients who have access to university hospitals in affluent areas, potentially missing health patterns in underserved communities.       "
},
{
  "id": "activity-ethics-representation",
  "level": "2",
  "url": "sec-ethics-spotlight-sampling.html#activity-ethics-representation",
  "type": "Activity",
  "number": "14",
  "title": "Evaluating Representation in Your Dataset.",
  "body": " Evaluating Representation in Your Dataset   In this activity, you'll critically examine representation issues in your chosen dataset.     Identify at least three ways in which your dataset might not fully represent the population you're interested in studying.      Consider how these representation issues might affect the conclusions you can draw from your analysis.      Propose at least two strategies for acknowledging or addressing these representation issues in your investigation.    "
},
{
  "id": "sec-unit2-summary",
  "level": "1",
  "url": "sec-unit2-summary.html",
  "type": "Section",
  "number": "",
  "title": "Unit 2 Summary",
  "body": " Unit 2 Summary  In this unit, we've explored:    The data investigation framework developed by Hollylynne Lee and colleagues, which provides a structured approach to data analysis    How to formulate effective statistical questions that anticipate variability and can be answered with data    The components of a comprehensive investigation plan, including research questions, data requirements, analysis approaches, and potential challenges    Fundamental concepts of statistical thinking, particularly the importance of understanding and accounting for variability    Ethical considerations regarding representation in data and how they affect the conclusions we can draw    By the end of this unit, you should have a clear investigation plan for your project dataset, including well-formulated statistical questions and a strategy for analysis. This plan will guide your work in the upcoming units as we dive deeper into data moves and visualization techniques.   Unit 2 Reflection   Take some time to reflect on what you've learned in this unit:    How has the data investigation framework changed your approach to analyzing data?    What was most challenging about formulating effective statistical questions?    How does understanding variability influence the way you think about data?    What aspects of your investigation plan are you most confident about, and which might need refinement as you proceed?       Unit 2 Review   Which of the following BEST describes the main purpose of the data investigation framework?      To provide a rigid, linear sequence of steps that must be followed in every data analysis    The framework is not meant to be rigid or strictly linear. Real investigations often involve cycling back through earlier phases as new insights emerge.      To replace critical thinking with standardized procedures for data analysis    The framework is designed to enhance critical thinking, not replace it. It provides a structure while still requiring judgment and creativity.      To provide a structured approach that ensures all important aspects of data investigation are considered    Correct! The framework serves as a guide to help ensure that important elements like question formulation, data quality assessment, appropriate analysis, and careful interpretation are all addressed.      To automate the process of analyzing data so that minimal human intervention is required    The framework does not automate analysis; it provides a conceptual structure for human investigators to follow while still requiring substantial judgment and expertise.      "
},
{
  "id": "exercise-unit2-reflection",
  "level": "2",
  "url": "sec-unit2-summary.html#exercise-unit2-reflection",
  "type": "Checkpoint",
  "number": "50",
  "title": "Unit 2 Reflection.",
  "body": " Unit 2 Reflection   Take some time to reflect on what you've learned in this unit:    How has the data investigation framework changed your approach to analyzing data?    What was most challenging about formulating effective statistical questions?    How does understanding variability influence the way you think about data?    What aspects of your investigation plan are you most confident about, and which might need refinement as you proceed?     "
},
{
  "id": "mc-unit2-review",
  "level": "2",
  "url": "sec-unit2-summary.html#mc-unit2-review",
  "type": "Checkpoint",
  "number": "51",
  "title": "Unit 2 Review.",
  "body": " Unit 2 Review   Which of the following BEST describes the main purpose of the data investigation framework?      To provide a rigid, linear sequence of steps that must be followed in every data analysis    The framework is not meant to be rigid or strictly linear. Real investigations often involve cycling back through earlier phases as new insights emerge.      To replace critical thinking with standardized procedures for data analysis    The framework is designed to enhance critical thinking, not replace it. It provides a structure while still requiring judgment and creativity.      To provide a structured approach that ensures all important aspects of data investigation are considered    Correct! The framework serves as a guide to help ensure that important elements like question formulation, data quality assessment, appropriate analysis, and careful interpretation are all addressed.      To automate the process of analyzing data so that minimal human intervention is required    The framework does not automate analysis; it provides a conceptual structure for human investigators to follow while still requiring substantial judgment and expertise.     "
},
{
  "id": "sec-data-cleaning",
  "level": "1",
  "url": "sec-data-cleaning.html",
  "type": "Section",
  "number": "",
  "title": "Data Cleaning and Organization",
  "body": " Data Cleaning and Organization   Why Data Cleaning Matters  Data cleaning is often the most time-consuming part of data science work—and for good reason. The quality of your cleaning directly affects the validity of your results.   \"Garbage in, garbage out\" is a fundamental principle in data science. No amount of sophisticated analysis can compensate for poor-quality data.   Common data quality issues include:    Missing values : Data points that weren't recorded or were lost    Inconsistent formats : The same information recorded in different ways (e.g., \"NY\" vs. \"New York\")    Duplicate records : The same observation recorded multiple times    Outliers : Extreme values that may represent errors or unusual cases    Structural issues : Data not organized according to tidy data principles    Coding errors : Incorrect values due to human or system errors     Identifying Data Quality Issues   Which of the following would NOT typically be considered a data quality issue requiring cleaning?      A temperature column contains some values recorded in Celsius and others in Fahrenheit.    This is a data quality issue. Inconsistent units need to be standardized before analysis.      Several cells in a spreadsheet contain \"#N\/A\" or \"NULL\" values.    Missing values represented as \"#N\/A\" or \"NULL\" are data quality issues that need to be addressed.      A dataset shows that air pollution levels are higher in urban areas compared to rural areas.    Correct! This is an actual finding from the data rather than a quality issue. It represents a pattern or relationship that might emerge after proper cleaning and analysis.      Dates are stored in different formats such as \"01\/05\/2023\", \"Jan 5, 2023\", and \"2023-01-05\".    Inconsistent date formats are a data quality issue that needs to be standardized.      Data cleaning is both a science and an art. While there are standard approaches for handling common issues, every dataset presents unique challenges that require careful judgment.    Handling Missing Values  Missing values are perhaps the most common data quality issue. Before deciding how to handle them, it's important to understand why the data might be missing:    Missing Completely at Random (MCAR)  The missing values occur purely by chance, with no relationship to any variables in the dataset.    Missing at Random (MAR)  The probability of missing values depends on observed data but not on the missing values themselves.    Missing Not at Random (MNAR)  The missing values are related to the values themselves (e.g., people with high incomes might be less likely to report their income).    There are several common approaches to handling missing values:    Complete Case Analysis (Listwise Deletion)  Remove all rows with any missing values. Simple but can substantially reduce your dataset and introduce bias.    Single Imputation  Replace missing values with a calculated value like the mean, median, or mode. Straightforward but doesn't account for uncertainty.    Multiple Imputation  Generate multiple plausible values for each missing value, reflecting uncertainty. More complex but statistically sounder.    Indicator Variables  Create a new variable that flags where values were missing, then use imputation. Preserves information about missingness patterns.     Patterns of Missing Values   A visualization showing different patterns of missing values in a dataset: scattered randomly, entire columns missing, or specific combinations of variables missing together.    The appropriate approach depends on:    The pattern and mechanism of missingness    The proportion of missing values    The importance of the variable to your analysis    The size of your dataset     Missing Values in Community Health Data   In our Community Health dataset, we might encounter these missing value situations:    A few neighborhoods have missing air quality index values because monitoring stations were temporarily offline (likely MCAR).    Asthma rates are more likely to be missing in lower-income neighborhoods due to less comprehensive health reporting systems (MAR).    Obesity rates might be missing in neighborhoods where they are particularly high due to stigma-related underreporting (MNAR).    Different approaches might be appropriate for each situation:    For the missing air quality values, we might interpolate values from nearby stations.    For missing asthma rates, we might use multiple imputation based on other health and socioeconomic variables.    For the obesity data, we should acknowledge the potential bias and perhaps use an indicator variable approach to flag where data was missing.       Steps for Handling Missing Values   Arrange the following steps in a logical order for handling missing values in a dataset.     Identify variables with missing values and calculate the proportion of missingness.     Immediately delete all rows with any missing values.    Examine patterns of missingness to understand potential mechanisms (MCAR, MAR, MNAR).    Replace all missing values with zero.     Consider the impact of missingness on your specific research questions.    Select appropriate techniques for handling missing values based on the pattern, mechanism, and research goals.    Implement the chosen techniques and document your approach.    Ignore missing values since they don't affect analysis results.     Before deciding how to handle missing values, you need to understand the extent and pattern of missingness in your data.     Missing Values in CODAP   In this activity, you'll practice working with missing values in CODAP.     Open the Community Health dataset in CODAP (or your own project dataset).      Identify variables with missing values. CODAP typically shows these as empty cells. Count how many missing values exist for each variable.      Create a calculated attribute using the formula if(isNaN(originalAttribute), replacementValue, originalAttribute) to replace missing values in a numerical column with the mean or median of that column.      Create visualizations comparing the distribution of a variable before and after imputing missing values. How does the imputation affect the distribution?       Dealing with Outliers  Outliers are extreme values that differ significantly from other observations in the dataset. Not all outliers are errors—some represent genuine extreme cases that are important to understand.    An outlier is an observation that falls far outside the typical range of values in a dataset, often defined statistically as values more than 1.5 interquartile ranges below the first quartile or above the third quartile.    When encountering outliers, consider these questions:    Is the outlier a genuine observation or a data entry error?    If it's genuine, does it represent an important case that should be included in analysis?    How much influence does the outlier have on your statistics and visualizations?    What is the most appropriate way to handle this outlier given your research questions?    Common approaches to handling outliers include:    Retain  Keep outliers in the dataset, especially if they represent valid and important observations.    Remove  Delete outliers if they are clearly errors or if they unduly influence your analysis.    Transform  Apply mathematical transformations (like logarithmic) to reduce the influence of extreme values.    Cap  Set a maximum threshold and replace values exceeding it (winsorizing).    Analyze Separately  Conduct analyses both with and without outliers to understand their influence.     Outliers in Community Health Data   In our Community Health dataset, we might encounter several types of outliers:    A neighborhood shows an air quality index ten times higher than any other neighborhood, which investigation reveals was due to a data entry error (decimal point misplaced). This should be corrected.    One neighborhood has an unusually high asthma rate that is verified as accurate and corresponds to its proximity to a major industrial facility. This outlier should be retained as it represents an important case.    Income distribution across neighborhoods is highly skewed, with a few very wealthy areas. A log transformation might be appropriate for some analyses to better visualize relationships.      This figure shows a box and whisker plot with outliers.   Detecting Outliers with Box Plots   A box plot showing the distribution of values with outliers marked as individual points beyond the whiskers.     Outlier Handling Approaches   Which approach to handling outliers would be MOST appropriate in this situation: You're analyzing neighborhood crime rates, and one neighborhood has a rate five times higher than the next highest. Upon investigation, you confirm this is accurate data for a neighborhood with unique circumstances.      Remove the neighborhood from your dataset to prevent it from skewing your statistical results.    This would not be appropriate since the outlier represents a genuine and potentially important case. Removing it would eliminate valuable information about an actual neighborhood.      Replace the crime rate value with the mean of all other neighborhoods.    Replacing a confirmed accurate value with the mean would discard valid information and misrepresent the actual situation in that neighborhood.      Retain the outlier but conduct analyses both with and without it to understand its influence on your results.    Correct! This approach preserves the valid data point while allowing you to assess its impact on your overall results. This provides a more complete understanding of neighborhood crime patterns.      Cap the value at three times the next highest rate to reduce its influence.    Capping a confirmed accurate value would artificially alter real data. Since the extreme value is valid, artificially reducing it would misrepresent the actual situation.       Outlier Detection in CODAP   In this activity, you'll practice identifying and examining outliers in CODAP.     Open your dataset in CODAP and create box plots for at least three numerical variables.      Identify potential outliers in each variable (points outside the whiskers of the box plot).      For each identified outlier, examine the complete record (row) to see if you can determine why it might be unusual. Is it likely an error or a genuine extreme case?      Create scatter plots showing relationships between variables, and identify any points that appear to be outliers in these relationships (even if they're not outliers in individual variables).       Renaming and Restructuring Data  Beyond fixing errors, data cleaning often involves restructuring the dataset to make it more suitable for analysis. This might include:    Renaming variables for clarity and consistency    Recoding values to standardize categories (e.g., \"M\" and \"Male\" to a single code)    Creating new variables based on existing ones    Reshaping data between wide and long formats    Merging datasets to combine information from different sources    A particularly important restructuring is ensuring your data follows the principles of tidy data:    Each variable forms a column    Each observation forms a row    Each type of observational unit forms a table     Restructuring Community Health Data   For our Community Health dataset, we might need to:    Rename variables from cryptic codes like \"AQI_AVG\" to clearer names like \"Average_Air_Quality_Index\"    Standardize inconsistent neighborhood classifications (e.g., \"Downtown\", \"Central Business District\", \"CBD\" all referring to the same area)    Create a new variable categorizing air quality as \"Good\", \"Moderate\", or \"Poor\" based on numerical AQI values    Convert data from a wide format (different health metrics in separate columns) to a long format (a single \"Health_Metric\" column with a \"Value\" column) for certain analyses       Data Restructuring Operations   Match each data restructuring operation with its most appropriate use case.     Converting from wide to long format  Preparing data where one observation is measured across multiple time points for time-series visualization    Recoding categorical values  Standardizing inconsistent entries like \"F\", \"female\", and \"fem\" to a single value    Creating calculated variables  Deriving Body Mass Index (BMI) from height and weight measurements    Merging datasets  Combining neighborhood health data with separate census demographic data using a common ID    Renaming variables  Changing cryptic column names like \"var001\" to descriptive names like \"annual_income\"      Restructuring Data in CODAP   In this activity, you'll practice renaming and restructuring data in CODAP.     In your dataset, identify at least three variables that could benefit from clearer, more descriptive names. Rename these attributes in CODAP by right-clicking on the column header.      Find a numerical variable that would be useful to categorize. Use CODAP's calculator to create a new attribute that categorizes values (e.g., creating \"Income_Level\" with values like \"Low\", \"Medium\", and \"High\" based on numeric income).      Create at least one calculated attribute that performs a mathematical operation on existing variables (e.g., a ratio, percentage, or unit conversion).      "
},
{
  "id": "subsec-importance-cleaning-5-1-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-importance-cleaning-5-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Missing values "
},
{
  "id": "subsec-importance-cleaning-5-2-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-importance-cleaning-5-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Inconsistent formats "
},
{
  "id": "subsec-importance-cleaning-5-3-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-importance-cleaning-5-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Duplicate records "
},
{
  "id": "subsec-importance-cleaning-5-4-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-importance-cleaning-5-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Outliers "
},
{
  "id": "subsec-importance-cleaning-5-5-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-importance-cleaning-5-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Structural issues "
},
{
  "id": "subsec-importance-cleaning-5-6-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-importance-cleaning-5-6-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Coding errors "
},
{
  "id": "mc-data-quality-issues",
  "level": "2",
  "url": "sec-data-cleaning.html#mc-data-quality-issues",
  "type": "Checkpoint",
  "number": "52",
  "title": "Identifying Data Quality Issues.",
  "body": " Identifying Data Quality Issues   Which of the following would NOT typically be considered a data quality issue requiring cleaning?      A temperature column contains some values recorded in Celsius and others in Fahrenheit.    This is a data quality issue. Inconsistent units need to be standardized before analysis.      Several cells in a spreadsheet contain \"#N\/A\" or \"NULL\" values.    Missing values represented as \"#N\/A\" or \"NULL\" are data quality issues that need to be addressed.      A dataset shows that air pollution levels are higher in urban areas compared to rural areas.    Correct! This is an actual finding from the data rather than a quality issue. It represents a pattern or relationship that might emerge after proper cleaning and analysis.      Dates are stored in different formats such as \"01\/05\/2023\", \"Jan 5, 2023\", and \"2023-01-05\".    Inconsistent date formats are a data quality issue that needs to be standardized.     "
},
{
  "id": "fig-missing-values",
  "level": "2",
  "url": "sec-data-cleaning.html#fig-missing-values",
  "type": "Figure",
  "number": "53",
  "title": "",
  "body": " Patterns of Missing Values   A visualization showing different patterns of missing values in a dataset: scattered randomly, entire columns missing, or specific combinations of variables missing together.   "
},
{
  "id": "example-missing-health",
  "level": "2",
  "url": "sec-data-cleaning.html#example-missing-health",
  "type": "Example",
  "number": "54",
  "title": "Missing Values in Community Health Data.",
  "body": " Missing Values in Community Health Data   In our Community Health dataset, we might encounter these missing value situations:    A few neighborhoods have missing air quality index values because monitoring stations were temporarily offline (likely MCAR).    Asthma rates are more likely to be missing in lower-income neighborhoods due to less comprehensive health reporting systems (MAR).    Obesity rates might be missing in neighborhoods where they are particularly high due to stigma-related underreporting (MNAR).    Different approaches might be appropriate for each situation:    For the missing air quality values, we might interpolate values from nearby stations.    For missing asthma rates, we might use multiple imputation based on other health and socioeconomic variables.    For the obesity data, we should acknowledge the potential bias and perhaps use an indicator variable approach to flag where data was missing.     "
},
{
  "id": "parsons-missing-values",
  "level": "2",
  "url": "sec-data-cleaning.html#parsons-missing-values",
  "type": "Checkpoint",
  "number": "55",
  "title": "Steps for Handling Missing Values.",
  "body": " Steps for Handling Missing Values   Arrange the following steps in a logical order for handling missing values in a dataset.     Identify variables with missing values and calculate the proportion of missingness.     Immediately delete all rows with any missing values.    Examine patterns of missingness to understand potential mechanisms (MCAR, MAR, MNAR).    Replace all missing values with zero.     Consider the impact of missingness on your specific research questions.    Select appropriate techniques for handling missing values based on the pattern, mechanism, and research goals.    Implement the chosen techniques and document your approach.    Ignore missing values since they don't affect analysis results.     Before deciding how to handle missing values, you need to understand the extent and pattern of missingness in your data.   "
},
{
  "id": "activity-missing-values",
  "level": "2",
  "url": "sec-data-cleaning.html#activity-missing-values",
  "type": "Activity",
  "number": "15",
  "title": "Missing Values in CODAP.",
  "body": " Missing Values in CODAP   In this activity, you'll practice working with missing values in CODAP.     Open the Community Health dataset in CODAP (or your own project dataset).      Identify variables with missing values. CODAP typically shows these as empty cells. Count how many missing values exist for each variable.      Create a calculated attribute using the formula if(isNaN(originalAttribute), replacementValue, originalAttribute) to replace missing values in a numerical column with the mean or median of that column.      Create visualizations comparing the distribution of a variable before and after imputing missing values. How does the imputation affect the distribution?    "
},
{
  "id": "def-outlier",
  "level": "2",
  "url": "sec-data-cleaning.html#def-outlier",
  "type": "Definition",
  "number": "56",
  "title": "",
  "body": "  An outlier is an observation that falls far outside the typical range of values in a dataset, often defined statistically as values more than 1.5 interquartile ranges below the first quartile or above the third quartile.   "
},
{
  "id": "example-outliers-health",
  "level": "2",
  "url": "sec-data-cleaning.html#example-outliers-health",
  "type": "Example",
  "number": "57",
  "title": "Outliers in Community Health Data.",
  "body": " Outliers in Community Health Data   In our Community Health dataset, we might encounter several types of outliers:    A neighborhood shows an air quality index ten times higher than any other neighborhood, which investigation reveals was due to a data entry error (decimal point misplaced). This should be corrected.    One neighborhood has an unusually high asthma rate that is verified as accurate and corresponds to its proximity to a major industrial facility. This outlier should be retained as it represents an important case.    Income distribution across neighborhoods is highly skewed, with a few very wealthy areas. A log transformation might be appropriate for some analyses to better visualize relationships.     "
},
{
  "id": "fig-outlier-detection",
  "level": "2",
  "url": "sec-data-cleaning.html#fig-outlier-detection",
  "type": "Figure",
  "number": "58",
  "title": "",
  "body": " Detecting Outliers with Box Plots   A box plot showing the distribution of values with outliers marked as individual points beyond the whiskers.   "
},
{
  "id": "mc-outlier-handling",
  "level": "2",
  "url": "sec-data-cleaning.html#mc-outlier-handling",
  "type": "Checkpoint",
  "number": "59",
  "title": "Outlier Handling Approaches.",
  "body": " Outlier Handling Approaches   Which approach to handling outliers would be MOST appropriate in this situation: You're analyzing neighborhood crime rates, and one neighborhood has a rate five times higher than the next highest. Upon investigation, you confirm this is accurate data for a neighborhood with unique circumstances.      Remove the neighborhood from your dataset to prevent it from skewing your statistical results.    This would not be appropriate since the outlier represents a genuine and potentially important case. Removing it would eliminate valuable information about an actual neighborhood.      Replace the crime rate value with the mean of all other neighborhoods.    Replacing a confirmed accurate value with the mean would discard valid information and misrepresent the actual situation in that neighborhood.      Retain the outlier but conduct analyses both with and without it to understand its influence on your results.    Correct! This approach preserves the valid data point while allowing you to assess its impact on your overall results. This provides a more complete understanding of neighborhood crime patterns.      Cap the value at three times the next highest rate to reduce its influence.    Capping a confirmed accurate value would artificially alter real data. Since the extreme value is valid, artificially reducing it would misrepresent the actual situation.     "
},
{
  "id": "activity-outlier-detection",
  "level": "2",
  "url": "sec-data-cleaning.html#activity-outlier-detection",
  "type": "Activity",
  "number": "16",
  "title": "Outlier Detection in CODAP.",
  "body": " Outlier Detection in CODAP   In this activity, you'll practice identifying and examining outliers in CODAP.     Open your dataset in CODAP and create box plots for at least three numerical variables.      Identify potential outliers in each variable (points outside the whiskers of the box plot).      For each identified outlier, examine the complete record (row) to see if you can determine why it might be unusual. Is it likely an error or a genuine extreme case?      Create scatter plots showing relationships between variables, and identify any points that appear to be outliers in these relationships (even if they're not outliers in individual variables).    "
},
{
  "id": "subsec-restructuring-3-1-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-restructuring-3-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Renaming variables "
},
{
  "id": "subsec-restructuring-3-2-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-restructuring-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Recoding values "
},
{
  "id": "subsec-restructuring-3-3-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-restructuring-3-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Creating new variables "
},
{
  "id": "subsec-restructuring-3-4-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-restructuring-3-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Reshaping data "
},
{
  "id": "subsec-restructuring-3-5-1",
  "level": "2",
  "url": "sec-data-cleaning.html#subsec-restructuring-3-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Merging datasets "
},
{
  "id": "example-restructuring-health",
  "level": "2",
  "url": "sec-data-cleaning.html#example-restructuring-health",
  "type": "Example",
  "number": "60",
  "title": "Restructuring Community Health Data.",
  "body": " Restructuring Community Health Data   For our Community Health dataset, we might need to:    Rename variables from cryptic codes like \"AQI_AVG\" to clearer names like \"Average_Air_Quality_Index\"    Standardize inconsistent neighborhood classifications (e.g., \"Downtown\", \"Central Business District\", \"CBD\" all referring to the same area)    Create a new variable categorizing air quality as \"Good\", \"Moderate\", or \"Poor\" based on numerical AQI values    Convert data from a wide format (different health metrics in separate columns) to a long format (a single \"Health_Metric\" column with a \"Value\" column) for certain analyses     "
},
{
  "id": "matching-restructuring",
  "level": "2",
  "url": "sec-data-cleaning.html#matching-restructuring",
  "type": "Checkpoint",
  "number": "61",
  "title": "Data Restructuring Operations.",
  "body": " Data Restructuring Operations   Match each data restructuring operation with its most appropriate use case.     Converting from wide to long format  Preparing data where one observation is measured across multiple time points for time-series visualization    Recoding categorical values  Standardizing inconsistent entries like \"F\", \"female\", and \"fem\" to a single value    Creating calculated variables  Deriving Body Mass Index (BMI) from height and weight measurements    Merging datasets  Combining neighborhood health data with separate census demographic data using a common ID    Renaming variables  Changing cryptic column names like \"var001\" to descriptive names like \"annual_income\"    "
},
{
  "id": "activity-data-restructuring",
  "level": "2",
  "url": "sec-data-cleaning.html#activity-data-restructuring",
  "type": "Activity",
  "number": "17",
  "title": "Restructuring Data in CODAP.",
  "body": " Restructuring Data in CODAP   In this activity, you'll practice renaming and restructuring data in CODAP.     In your dataset, identify at least three variables that could benefit from clearer, more descriptive names. Rename these attributes in CODAP by right-clicking on the column header.      Find a numerical variable that would be useful to categorize. Use CODAP's calculator to create a new attribute that categorizes values (e.g., creating \"Income_Level\" with values like \"Low\", \"Medium\", and \"High\" based on numeric income).      Create at least one calculated attribute that performs a mathematical operation on existing variables (e.g., a ratio, percentage, or unit conversion).    "
},
{
  "id": "sec-filtering-subsetting",
  "level": "1",
  "url": "sec-filtering-subsetting.html",
  "type": "Section",
  "number": "",
  "title": "Filtering and Subsetting",
  "body": " Filtering and Subsetting   The Purpose of Filtering  Rarely do we analyze an entire dataset at once. More often, we focus on specific subsets of the data that are relevant to particular questions. Filtering and subsetting allow us to:    Focus on specific groups or conditions of interest    Compare different subsets to identify patterns and differences    Remove irrelevant data that might obscure important relationships    Create more manageable subsets for specialized analyses    Test relationships under different conditions    Effective filtering requires clear criteria and an understanding of how the filtering might affect your analysis.   Filtering in Community Health Analysis   In our Community Health dataset, we might apply these filters:    Focus only on neighborhoods with complete data across all health metrics    Compare high-income versus low-income neighborhoods (using median household income)    Examine only neighborhoods with poor air quality to understand health patterns in most affected areas    Create separate analyses for different regions of the city (north, south, east, west)    Filter out neighborhoods undergoing major redevelopment that might skew environmental measurements       Purposes of Filtering   Which of the following is NOT a valid reason to filter or subset data?      To compare outcomes between different demographic groups    This is a valid reason for filtering—creating subsets based on demographic variables can reveal important differences between groups.      To focus analysis on the most recent time period in a longitudinal dataset    This is a valid reason for filtering—focusing on the most recent data can provide insights into current conditions.      To remove data points that contradict your hypothesis    Correct! This is NOT a valid reason for filtering. Removing data merely because it contradicts your hypothesis introduces bias and violates principles of scientific integrity.      To create a more manageable dataset for complex computational methods    This is a valid reason for filtering—some analyses may require smaller datasets due to computational constraints, as long as the subsetting is done in a principled way.        Filtering Methods in CODAP  CODAP provides several ways to filter data:    Selection from Visualizations  Clicking on points in a graph or cells in a table selects those cases. You can then hide unselected cases or create a new collection with only selected cases.    Filter Using Formulas  Create a filter using a formula like income > 50000 to show only cases meeting that condition.    Creating Subsets  Create a new dataset containing only filtered data, preserving the original dataset.    Hierarchical Organization  Organize data into hierarchical collections, allowing analysis at different levels (e.g., cities → neighborhoods → households).    When filtering data, it's important to:    Document your filtering criteria clearly    Consider how the filter might affect the representativeness of your data    Be aware of how sample size reduction might impact statistical analyses    Check whether your filtered data still addresses your research questions     Filtering Data in CODAP   In this activity, you'll practice filtering data in CODAP using different methods.     Open your dataset in CODAP and create a scatter plot using two numerical variables.      Use selection to highlight a cluster of points, then create a new collection containing only these selected cases.      Create a filter using the formula editor to show only cases meeting specific criteria (e.g., values above a threshold or matching a category).      Compare summary statistics of your original dataset and filtered subset. How do measures like mean, median, and standard deviation change when you apply your filter?      Translating Filter Statements   For each of the following filtering objectives, select the CODAP filter formula that would accomplish it.     Question 1: Show only neighborhoods with both above-average income and above-average green space.  Select the correct CODAP filter formula:    a . Income > AverageIncome OR GreenSpace > AverageGreenSpace    b . Income > AverageIncome AND GreenSpace > AverageGreenSpace    c . Income = AverageIncome AND GreenSpace = AverageGreenSpace    d . Income > AverageIncome    Question 2: Show neighborhoods that are either in the North region or have low pollution levels.  Select the correct CODAP filter formula:    a . Region = 'North' AND PollutionLevel = 'Low'    b . NOT(Region = 'North') OR NOT(PollutionLevel = 'Low')    c . Region = 'North' OR PollutionLevel = 'Low'    d . Region != 'North' AND PollutionLevel != 'Low'     Remember the difference between AND and OR operators:    AND requires both conditions to be true    OR requires at least one condition to be true    Also pay attention to comparison operators (=, >, !=) and make sure they match what the question is asking for.             Question 1: The correct formula is Income > AverageIncome AND GreenSpace > AverageGreenSpace  This formula uses AND to require that both conditions (above-average income and above-average green space) must be true for a neighborhood to be included in the filter.  Question 2: The correct formula is Region = 'North' OR PollutionLevel = 'Low'  This formula uses OR to include neighborhoods that meet either condition: being in the North region OR having low pollution levels.          Creating Meaningful Subsets  Beyond simple filtering, creating meaningful subsets often involves more complex criteria and a deeper understanding of your data. Effective subsetting strategies include:    Comparative Subsets  Create groups for comparison based on key variables (e.g., high vs. low exposure groups, different demographic categories).    Threshold-Based Subsets  Define groups based on meaningful thresholds like regulatory standards or clinical definitions.    Time-Based Subsets  Create groups based on time periods to study changes or compare before\/after scenarios.    Cluster-Based Subsets  Use patterns in the data itself to identify natural groupings.    Random Sampling  Create representative subsets through random sampling, particularly for very large datasets.     Meaningful Subsets in Community Health   For our Community Health dataset, meaningful subsets might include:    Income quantiles : Dividing neighborhoods into income quintiles (bottom 20%, 20-40%, etc.) to examine how health patterns vary across socioeconomic spectrum    Environmental risk categories : Grouping neighborhoods as \"high-risk\" or \"low-risk\" based on combined environmental factors    Geographic regions : Creating subsets based on meaningful geographic divisions like urban core, inner suburbs, outer suburbs    Health outcome groups : Identifying neighborhoods with multiple poor health outcomes versus those with generally good outcomes    Green space access : Comparing neighborhoods with high, medium, and low access to green spaces       Creating Meaningful Subsets   In this activity, you'll create and analyze meaningful subsets of your data.     Identify a key numerical variable in your dataset. Create a new categorical attribute that divides this variable into meaningful groups (e.g., low\/medium\/high, or quantiles).      Create visualizations comparing these groups across other variables. Look for patterns or differences between the groups.      Devise at least two different ways to create subsets from your data that might reveal interesting patterns. Implement these in CODAP and explore the results.      Write a brief summary of what you learned by examining different subsets of your data. Were there patterns that only became apparent when looking at specific subsets?      Subset Creation Approaches   A researcher is studying the relationship between exercise habits and health outcomes. Which subsetting approach would be MOST useful for comparing the effects of different exercise levels?      Random sampling to create smaller, more manageable datasets    While random sampling can be useful for creating manageable datasets from large ones, it doesn't specifically help with comparing different exercise levels.      Time-based subsetting to examine seasonal variations in exercise    While seasonal variations might be interesting, this approach doesn't directly address comparing different exercise levels and their health effects.      Threshold-based groups dividing participants into categories based on weekly exercise minutes (e.g., sedentary, moderately active, highly active)    Correct! Creating categorical groups based on meaningful exercise thresholds provides a clear way to compare health outcomes across different exercise levels.      Geographic subsetting to compare exercise habits across different regions    While regional comparisons might reveal interesting patterns in exercise habits, this approach focuses on geographic differences rather than directly comparing exercise levels and their health effects.       "
},
{
  "id": "example-filtering-health",
  "level": "2",
  "url": "sec-filtering-subsetting.html#example-filtering-health",
  "type": "Example",
  "number": "62",
  "title": "Filtering in Community Health Analysis.",
  "body": " Filtering in Community Health Analysis   In our Community Health dataset, we might apply these filters:    Focus only on neighborhoods with complete data across all health metrics    Compare high-income versus low-income neighborhoods (using median household income)    Examine only neighborhoods with poor air quality to understand health patterns in most affected areas    Create separate analyses for different regions of the city (north, south, east, west)    Filter out neighborhoods undergoing major redevelopment that might skew environmental measurements     "
},
{
  "id": "mc-filtering-purpose",
  "level": "2",
  "url": "sec-filtering-subsetting.html#mc-filtering-purpose",
  "type": "Checkpoint",
  "number": "63",
  "title": "Purposes of Filtering.",
  "body": " Purposes of Filtering   Which of the following is NOT a valid reason to filter or subset data?      To compare outcomes between different demographic groups    This is a valid reason for filtering—creating subsets based on demographic variables can reveal important differences between groups.      To focus analysis on the most recent time period in a longitudinal dataset    This is a valid reason for filtering—focusing on the most recent data can provide insights into current conditions.      To remove data points that contradict your hypothesis    Correct! This is NOT a valid reason for filtering. Removing data merely because it contradicts your hypothesis introduces bias and violates principles of scientific integrity.      To create a more manageable dataset for complex computational methods    This is a valid reason for filtering—some analyses may require smaller datasets due to computational constraints, as long as the subsetting is done in a principled way.     "
},
{
  "id": "activity-codap-filtering",
  "level": "2",
  "url": "sec-filtering-subsetting.html#activity-codap-filtering",
  "type": "Activity",
  "number": "18",
  "title": "Filtering Data in CODAP.",
  "body": " Filtering Data in CODAP   In this activity, you'll practice filtering data in CODAP using different methods.     Open your dataset in CODAP and create a scatter plot using two numerical variables.      Use selection to highlight a cluster of points, then create a new collection containing only these selected cases.      Create a filter using the formula editor to show only cases meeting specific criteria (e.g., values above a threshold or matching a category).      Compare summary statistics of your original dataset and filtered subset. How do measures like mean, median, and standard deviation change when you apply your filter?    "
},
{
  "id": "exercise-filtering-statements",
  "level": "2",
  "url": "sec-filtering-subsetting.html#exercise-filtering-statements",
  "type": "Checkpoint",
  "number": "64",
  "title": "Translating Filter Statements.",
  "body": " Translating Filter Statements   For each of the following filtering objectives, select the CODAP filter formula that would accomplish it.     Question 1: Show only neighborhoods with both above-average income and above-average green space.  Select the correct CODAP filter formula:    a . Income > AverageIncome OR GreenSpace > AverageGreenSpace    b . Income > AverageIncome AND GreenSpace > AverageGreenSpace    c . Income = AverageIncome AND GreenSpace = AverageGreenSpace    d . Income > AverageIncome    Question 2: Show neighborhoods that are either in the North region or have low pollution levels.  Select the correct CODAP filter formula:    a . Region = 'North' AND PollutionLevel = 'Low'    b . NOT(Region = 'North') OR NOT(PollutionLevel = 'Low')    c . Region = 'North' OR PollutionLevel = 'Low'    d . Region != 'North' AND PollutionLevel != 'Low'     Remember the difference between AND and OR operators:    AND requires both conditions to be true    OR requires at least one condition to be true    Also pay attention to comparison operators (=, >, !=) and make sure they match what the question is asking for.             Question 1: The correct formula is Income > AverageIncome AND GreenSpace > AverageGreenSpace  This formula uses AND to require that both conditions (above-average income and above-average green space) must be true for a neighborhood to be included in the filter.  Question 2: The correct formula is Region = 'North' OR PollutionLevel = 'Low'  This formula uses OR to include neighborhoods that meet either condition: being in the North region OR having low pollution levels.       "
},
{
  "id": "example-subsets-health",
  "level": "2",
  "url": "sec-filtering-subsetting.html#example-subsets-health",
  "type": "Example",
  "number": "65",
  "title": "Meaningful Subsets in Community Health.",
  "body": " Meaningful Subsets in Community Health   For our Community Health dataset, meaningful subsets might include:    Income quantiles : Dividing neighborhoods into income quintiles (bottom 20%, 20-40%, etc.) to examine how health patterns vary across socioeconomic spectrum    Environmental risk categories : Grouping neighborhoods as \"high-risk\" or \"low-risk\" based on combined environmental factors    Geographic regions : Creating subsets based on meaningful geographic divisions like urban core, inner suburbs, outer suburbs    Health outcome groups : Identifying neighborhoods with multiple poor health outcomes versus those with generally good outcomes    Green space access : Comparing neighborhoods with high, medium, and low access to green spaces     "
},
{
  "id": "activity-create-subsets",
  "level": "2",
  "url": "sec-filtering-subsetting.html#activity-create-subsets",
  "type": "Activity",
  "number": "19",
  "title": "Creating Meaningful Subsets.",
  "body": " Creating Meaningful Subsets   In this activity, you'll create and analyze meaningful subsets of your data.     Identify a key numerical variable in your dataset. Create a new categorical attribute that divides this variable into meaningful groups (e.g., low\/medium\/high, or quantiles).      Create visualizations comparing these groups across other variables. Look for patterns or differences between the groups.      Devise at least two different ways to create subsets from your data that might reveal interesting patterns. Implement these in CODAP and explore the results.      Write a brief summary of what you learned by examining different subsets of your data. Were there patterns that only became apparent when looking at specific subsets?    "
},
{
  "id": "mc-subset-creation",
  "level": "2",
  "url": "sec-filtering-subsetting.html#mc-subset-creation",
  "type": "Checkpoint",
  "number": "66",
  "title": "Subset Creation Approaches.",
  "body": " Subset Creation Approaches   A researcher is studying the relationship between exercise habits and health outcomes. Which subsetting approach would be MOST useful for comparing the effects of different exercise levels?      Random sampling to create smaller, more manageable datasets    While random sampling can be useful for creating manageable datasets from large ones, it doesn't specifically help with comparing different exercise levels.      Time-based subsetting to examine seasonal variations in exercise    While seasonal variations might be interesting, this approach doesn't directly address comparing different exercise levels and their health effects.      Threshold-based groups dividing participants into categories based on weekly exercise minutes (e.g., sedentary, moderately active, highly active)    Correct! Creating categorical groups based on meaningful exercise thresholds provides a clear way to compare health outcomes across different exercise levels.      Geographic subsetting to compare exercise habits across different regions    While regional comparisons might reveal interesting patterns in exercise habits, this approach focuses on geographic differences rather than directly comparing exercise levels and their health effects.     "
},
{
  "id": "sec-ethics-spotlight-selection",
  "level": "1",
  "url": "sec-ethics-spotlight-selection.html",
  "type": "Section",
  "number": "",
  "title": "Ethics Spotlight: Selection Bias",
  "body": " Ethics Spotlight: Selection Bias  When filtering and subsetting data, we must be careful not to introduce selection bias—a distortion in our results due to the way we select cases for analysis.     Selection bias occurs when the data selected for analysis is not representative of the population about which conclusions are to be drawn, leading to systematic error in the findings.    Common forms of selection bias include:    Sampling Bias  The sample selected for study doesn't represent the population of interest.    Self-Selection Bias  Participants choose whether to participate, potentially introducing systematic differences between participants and non-participants.    Survival Bias  Analysis focuses only on cases that \"survived\" some process, ignoring those that didn't.    Exclusion Bias  Systematic exclusion of certain groups or cases due to methodological choices.    Confirmation Bias  Tendency to filter data in ways that confirm preexisting beliefs or hypotheses.     Selection Bias in Community Health Research   In our Community Health project, selection bias might occur if:    We exclude neighborhoods with missing data, which happen to be primarily lower-income areas    Health survey data includes only responses from residents who volunteered to participate    Air quality measurements are taken only during weekdays, missing weekend patterns    We focus our analysis only on neighborhoods with good outcomes to identify \"best practices\"    We filter data to include only cases that support our initial hypothesis about environmental factors    Each of these filtering or selection decisions could lead to conclusions that don't accurately represent the true relationships in the complete population.    To minimize selection bias when filtering data:    Document all filtering criteria and justify them based on substantive rather than convenient reasons    Consider how excluded cases differ from included ones    Perform sensitivity analysis by comparing results with different filtering criteria    Be transparent about the limitations of your filtered dataset    Actively look for potential sources of bias in your selection process     Identifying Selection Bias   Which scenario represents the clearest example of selection bias?      A researcher randomly selects 100 participants from a complete list of 1,000 eligible individuals.    This describes proper random sampling rather than selection bias, as every eligible individual had an equal chance of being selected.      After collecting data, a researcher finds that one variable has a non-normal distribution.    A non-normal distribution is not necessarily an indication of bias; many variables naturally have skewed or other non-normal distributions.      A study finds weak but statistically significant correlations between variables.    Finding weak correlations is not an indication of selection bias; it simply describes the strength of relationships in the data.      A survey about internet usage is conducted exclusively through online questionnaires.    Correct! This is a clear example of selection bias. By conducting the survey only online, the study systematically excludes people with limited or no internet access, who likely have different internet usage patterns than those who regularly use the internet.       Identifying Potential Selection Bias   In this activity, you'll examine potential selection bias in your own data analysis.     Review the filtering and subsetting operations you've performed on your dataset. For each filter, identify who or what is being excluded.      Consider how these exclusions might affect your conclusions. Are you systematically excluding certain types of cases?      Identify at least one potential source of selection bias in your data collection process (before you even received the dataset).      Propose strategies for addressing or minimizing the selection bias you've identified.     "
},
{
  "id": "def-selection-bias",
  "level": "2",
  "url": "sec-ethics-spotlight-selection.html#def-selection-bias",
  "type": "Definition",
  "number": "67",
  "title": "",
  "body": "   Selection bias occurs when the data selected for analysis is not representative of the population about which conclusions are to be drawn, leading to systematic error in the findings.   "
},
{
  "id": "example-selection-bias-health",
  "level": "2",
  "url": "sec-ethics-spotlight-selection.html#example-selection-bias-health",
  "type": "Example",
  "number": "68",
  "title": "Selection Bias in Community Health Research.",
  "body": " Selection Bias in Community Health Research   In our Community Health project, selection bias might occur if:    We exclude neighborhoods with missing data, which happen to be primarily lower-income areas    Health survey data includes only responses from residents who volunteered to participate    Air quality measurements are taken only during weekdays, missing weekend patterns    We focus our analysis only on neighborhoods with good outcomes to identify \"best practices\"    We filter data to include only cases that support our initial hypothesis about environmental factors    Each of these filtering or selection decisions could lead to conclusions that don't accurately represent the true relationships in the complete population.   "
},
{
  "id": "mc-selection-bias",
  "level": "2",
  "url": "sec-ethics-spotlight-selection.html#mc-selection-bias",
  "type": "Checkpoint",
  "number": "69",
  "title": "Identifying Selection Bias.",
  "body": " Identifying Selection Bias   Which scenario represents the clearest example of selection bias?      A researcher randomly selects 100 participants from a complete list of 1,000 eligible individuals.    This describes proper random sampling rather than selection bias, as every eligible individual had an equal chance of being selected.      After collecting data, a researcher finds that one variable has a non-normal distribution.    A non-normal distribution is not necessarily an indication of bias; many variables naturally have skewed or other non-normal distributions.      A study finds weak but statistically significant correlations between variables.    Finding weak correlations is not an indication of selection bias; it simply describes the strength of relationships in the data.      A survey about internet usage is conducted exclusively through online questionnaires.    Correct! This is a clear example of selection bias. By conducting the survey only online, the study systematically excludes people with limited or no internet access, who likely have different internet usage patterns than those who regularly use the internet.     "
},
{
  "id": "activity-selection-bias",
  "level": "2",
  "url": "sec-ethics-spotlight-selection.html#activity-selection-bias",
  "type": "Activity",
  "number": "20",
  "title": "Identifying Potential Selection Bias.",
  "body": " Identifying Potential Selection Bias   In this activity, you'll examine potential selection bias in your own data analysis.     Review the filtering and subsetting operations you've performed on your dataset. For each filter, identify who or what is being excluded.      Consider how these exclusions might affect your conclusions. Are you systematically excluding certain types of cases?      Identify at least one potential source of selection bias in your data collection process (before you even received the dataset).      Propose strategies for addressing or minimizing the selection bias you've identified.    "
},
{
  "id": "sec-summarizing-calculating",
  "level": "1",
  "url": "sec-summarizing-calculating.html",
  "type": "Section",
  "number": "",
  "title": "Summarizing, Calculating, and Grouping",
  "body": " Summarizing, Calculating, and Grouping   Essential Summary Statistics  Summary statistics condense complex datasets into manageable metrics that capture key aspects of the data. Common summary statistics include:    Measures of Central Tendency    Mean : The arithmetic average (sum divided by count)  Median : The middle value when data is ordered  Mode : The most frequently occurring value      Measures of Spread    Range : The difference between maximum and minimum values  Variance : The average squared deviation from the mean  Standard Deviation : The square root of variance  Interquartile Range (IQR) : The range of the middle 50% of values      Measures of Position    Percentiles : Values below which a given percentage of observations fall  Quartiles : Values that divide data into quarters  Z-scores : How many standard deviations a value is from the mean      Measures of Relationship    Correlation : The strength and direction of linear relationships  Covariance : How two variables vary together  Contingency tables : Counts of co-occurrences for categorical variables       Summary Statistics for Different Distributions   Three different distributions showing how the same mean and standard deviation can represent very different data patterns.    When choosing summary statistics, consider:    The type and scale of your data (categorical, ordinal, interval, ratio)    The shape of your distribution (symmetrical, skewed, multimodal)    The presence of outliers or extreme values    The specific aspects of the data you want to highlight     Choosing Appropriate Summary Statistics   For a highly skewed distribution of housing prices in a city, which measure of central tendency would be MOST appropriate to report?      Mean (average) price    The mean is highly influenced by extreme values and can be misleading for skewed distributions. In housing prices, a few very expensive properties can pull the mean upward, making it unrepresentative of typical prices.      Median price    Correct! The median is the most appropriate measure for skewed distributions like housing prices because it's not influenced by extreme values. It represents the middle value, giving a better sense of the \"typical\" home price.      Modal price (most common price)    While the mode can be useful for categorical data, it's generally less informative for continuous variables like housing prices, which may not have many exact repeated values.      Midrange (average of minimum and maximum prices)    The midrange is highly influenced by outliers and would be particularly problematic for a skewed distribution of housing prices, where the maximum value could be dramatically higher than most values.       Calculating Summary Statistics in CODAP   In this activity, you'll calculate and interpret summary statistics for your dataset.     Select at least three numerical variables from your dataset. For each variable, use CODAP to calculate:    Mean, median, and mode    Standard deviation and interquartile range    Minimum, maximum, and range        Create visualizations (histograms or box plots) for each variable and examine how the summary statistics relate to the distribution shape.      For each variable, determine which measure of central tendency (mean, median, or mode) best represents the \"typical\" value and explain why.      Calculate correlation coefficients between pairs of numerical variables. Identify the strongest positive and negative correlations in your dataset.       Creating Derived Variables  Often, the variables we need for analysis aren't directly present in our original dataset. Creating derived variables allows us to transform existing data into more meaningful measures.  Common types of derived variables include:    Mathematical Transformations    Logarithmic transformations to handle skewed data  Standardization (z-scores) to compare different scales  Unit conversions (e.g., meters to feet, Celsius to Fahrenheit)      Combinations of Variables    Ratios and proportions (e.g., debt-to-income ratio)  Indices combining multiple measures (e.g., air quality index)  Weighted averages (e.g., GPA calculation)      Categorical Derivations    Binning numerical variables into categories (e.g., age groups)  Creating binary indicators (e.g., high-risk vs. low-risk)  Recoding categorical variables (e.g., combining similar categories)      Temporal Derivations    Calculating time differences (e.g., days between events)  Creating growth rates (e.g., annual percentage change)  Extracting components from dates (e.g., month, day of week)       Derived Variables in Community Health   For our Community Health dataset, useful derived variables might include:    Environmental Quality Index : A weighted average combining air quality, water quality, and green space measures    Health Disparity Ratio : The ratio of health outcomes in highest-income versus lowest-income neighborhoods    Risk Categories : Classifying neighborhoods as \"high,\" \"medium,\" or \"low\" risk based on multiple environmental factors    Green Space per Capita : Total green space area divided by population    Walkability Score : Combining measures of sidewalk coverage, street connectivity, and proximity to amenities      Creating effective derived variables requires:    Clear definition of what you're trying to measure    Thoughtful selection of component variables    Appropriate mathematical operations    Verification that the derived variable behaves as expected    Documentation of how the variable was created     Matching Derived Variables   Match each derived variable with the most appropriate formula or method for creating it.     Body Mass Index (BMI)  weight (kg) \/ [height (m)]²    Age category  if(age < 18, \"Child\", if(age < 65, \"Adult\", \"Senior\"))    Percentage change  ((new_value - old_value) \/ old_value) * 100    Standardized score  (value - mean) \/ standard_deviation    High-risk indicator  if(risk_score > threshold, 1, 0)      Creating Derived Variables in CODAP   In this activity, you'll create and analyze derived variables in your dataset.     Create at least three derived variables in your dataset, including:    A mathematical transformation of an existing variable (e.g., log, square root, or standardization)    A ratio or relationship between two variables    A categorical variable derived from a numerical variable (e.g., binning into groups)        Create visualizations showing the relationships between your original variables and the derived variables.      Explore how your derived variables relate to other variables in the dataset. Do they reveal patterns that weren't obvious with the original variables?       Grouping and Aggregation Techniques  Grouping and aggregation allow us to summarize data at different levels and examine patterns across categories. These techniques help us answer questions about how metrics vary between groups.  Common grouping and aggregation operations include:    Group By  Dividing data into subsets based on categories (e.g., by region, income level, or time period).    Aggregate Functions  Calculating summary statistics for each group:  Count: Number of observations  Sum: Total of values  Average: Mean value  Min\/Max: Smallest\/largest values  Standard Deviation: Measure of spread      Pivot Tables  Reorganizing data to show aggregated values across multiple dimensions.    Hierarchical Grouping  Nesting groups within groups (e.g., neighborhoods within districts within cities).     Grouping in Community Health Analysis   In our Community Health dataset, we might use grouping and aggregation to:    Calculate average asthma rates by income quartile to examine socioeconomic health disparities    Compare environmental quality metrics across different regions of the city    Examine how multiple health indicators vary across neighborhoods with different levels of green space access    Create a pivot table showing average health metrics by both region and income level simultaneously    Calculate the standard deviation of air quality within each region to understand environmental variability       Purpose of Grouping and Aggregation   What is the PRIMARY purpose of grouping and aggregation in data analysis?      To remove outliers from a dataset    While aggregation may reduce the impact of outliers in summary statistics, this is not the primary purpose of grouping and aggregation.      To understand patterns and variations across categories or subsets    Correct! The primary purpose of grouping and aggregation is to reveal how metrics and patterns vary across different categories or subsets, allowing for meaningful comparisons.      To reduce the size of large datasets    While aggregation does create a more compact summary, this is a side effect rather than the primary purpose of grouping and aggregation.      To correct errors in the original data    Grouping and aggregation do not correct errors in the original data; in fact, they might obscure some errors by combining them with correct values.       Grouping and Aggregation in CODAP   In this activity, you'll practice grouping and aggregating data in CODAP.     Identify at least two categorical variables in your dataset that would be meaningful to group by.      For each grouping variable, create a summary table in CODAP that shows aggregated measures (mean, count, etc.) of at least two numerical variables for each group.      Create visualizations comparing these groups. Use bar charts or box plots to show how the numerical variables differ across categories.      Try creating a two-way grouping by two different categorical variables. Examine how this more detailed breakdown reveals patterns that might not be apparent in single-variable groupings.      "
},
{
  "id": "subsec-summary-statistics-3-1-2",
  "level": "2",
  "url": "sec-summarizing-calculating.html#subsec-summary-statistics-3-1-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Mean Median Mode "
},
{
  "id": "subsec-summary-statistics-3-2-2",
  "level": "2",
  "url": "sec-summarizing-calculating.html#subsec-summary-statistics-3-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Range Variance Standard Deviation Interquartile Range (IQR) "
},
{
  "id": "subsec-summary-statistics-3-3-2",
  "level": "2",
  "url": "sec-summarizing-calculating.html#subsec-summary-statistics-3-3-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Percentiles Quartiles Z-scores "
},
{
  "id": "subsec-summary-statistics-3-4-2",
  "level": "2",
  "url": "sec-summarizing-calculating.html#subsec-summary-statistics-3-4-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Correlation Covariance Contingency tables "
},
{
  "id": "fig-summary-stats-distributions",
  "level": "2",
  "url": "sec-summarizing-calculating.html#fig-summary-stats-distributions",
  "type": "Figure",
  "number": "70",
  "title": "",
  "body": " Summary Statistics for Different Distributions   Three different distributions showing how the same mean and standard deviation can represent very different data patterns.   "
},
{
  "id": "mc-summary-stats",
  "level": "2",
  "url": "sec-summarizing-calculating.html#mc-summary-stats",
  "type": "Checkpoint",
  "number": "71",
  "title": "Choosing Appropriate Summary Statistics.",
  "body": " Choosing Appropriate Summary Statistics   For a highly skewed distribution of housing prices in a city, which measure of central tendency would be MOST appropriate to report?      Mean (average) price    The mean is highly influenced by extreme values and can be misleading for skewed distributions. In housing prices, a few very expensive properties can pull the mean upward, making it unrepresentative of typical prices.      Median price    Correct! The median is the most appropriate measure for skewed distributions like housing prices because it's not influenced by extreme values. It represents the middle value, giving a better sense of the \"typical\" home price.      Modal price (most common price)    While the mode can be useful for categorical data, it's generally less informative for continuous variables like housing prices, which may not have many exact repeated values.      Midrange (average of minimum and maximum prices)    The midrange is highly influenced by outliers and would be particularly problematic for a skewed distribution of housing prices, where the maximum value could be dramatically higher than most values.     "
},
{
  "id": "activity-summary-stats",
  "level": "2",
  "url": "sec-summarizing-calculating.html#activity-summary-stats",
  "type": "Activity",
  "number": "21",
  "title": "Calculating Summary Statistics in CODAP.",
  "body": " Calculating Summary Statistics in CODAP   In this activity, you'll calculate and interpret summary statistics for your dataset.     Select at least three numerical variables from your dataset. For each variable, use CODAP to calculate:    Mean, median, and mode    Standard deviation and interquartile range    Minimum, maximum, and range        Create visualizations (histograms or box plots) for each variable and examine how the summary statistics relate to the distribution shape.      For each variable, determine which measure of central tendency (mean, median, or mode) best represents the \"typical\" value and explain why.      Calculate correlation coefficients between pairs of numerical variables. Identify the strongest positive and negative correlations in your dataset.    "
},
{
  "id": "example-derived-health",
  "level": "2",
  "url": "sec-summarizing-calculating.html#example-derived-health",
  "type": "Example",
  "number": "72",
  "title": "Derived Variables in Community Health.",
  "body": " Derived Variables in Community Health   For our Community Health dataset, useful derived variables might include:    Environmental Quality Index : A weighted average combining air quality, water quality, and green space measures    Health Disparity Ratio : The ratio of health outcomes in highest-income versus lowest-income neighborhoods    Risk Categories : Classifying neighborhoods as \"high,\" \"medium,\" or \"low\" risk based on multiple environmental factors    Green Space per Capita : Total green space area divided by population    Walkability Score : Combining measures of sidewalk coverage, street connectivity, and proximity to amenities     "
},
{
  "id": "matching-derived-variables",
  "level": "2",
  "url": "sec-summarizing-calculating.html#matching-derived-variables",
  "type": "Checkpoint",
  "number": "73",
  "title": "Matching Derived Variables.",
  "body": " Matching Derived Variables   Match each derived variable with the most appropriate formula or method for creating it.     Body Mass Index (BMI)  weight (kg) \/ [height (m)]²    Age category  if(age < 18, \"Child\", if(age < 65, \"Adult\", \"Senior\"))    Percentage change  ((new_value - old_value) \/ old_value) * 100    Standardized score  (value - mean) \/ standard_deviation    High-risk indicator  if(risk_score > threshold, 1, 0)    "
},
{
  "id": "activity-derived-variables",
  "level": "2",
  "url": "sec-summarizing-calculating.html#activity-derived-variables",
  "type": "Activity",
  "number": "22",
  "title": "Creating Derived Variables in CODAP.",
  "body": " Creating Derived Variables in CODAP   In this activity, you'll create and analyze derived variables in your dataset.     Create at least three derived variables in your dataset, including:    A mathematical transformation of an existing variable (e.g., log, square root, or standardization)    A ratio or relationship between two variables    A categorical variable derived from a numerical variable (e.g., binning into groups)        Create visualizations showing the relationships between your original variables and the derived variables.      Explore how your derived variables relate to other variables in the dataset. Do they reveal patterns that weren't obvious with the original variables?    "
},
{
  "id": "example-grouping-health",
  "level": "2",
  "url": "sec-summarizing-calculating.html#example-grouping-health",
  "type": "Example",
  "number": "74",
  "title": "Grouping in Community Health Analysis.",
  "body": " Grouping in Community Health Analysis   In our Community Health dataset, we might use grouping and aggregation to:    Calculate average asthma rates by income quartile to examine socioeconomic health disparities    Compare environmental quality metrics across different regions of the city    Examine how multiple health indicators vary across neighborhoods with different levels of green space access    Create a pivot table showing average health metrics by both region and income level simultaneously    Calculate the standard deviation of air quality within each region to understand environmental variability     "
},
{
  "id": "mc-grouping-purpose",
  "level": "2",
  "url": "sec-summarizing-calculating.html#mc-grouping-purpose",
  "type": "Checkpoint",
  "number": "75",
  "title": "Purpose of Grouping and Aggregation.",
  "body": " Purpose of Grouping and Aggregation   What is the PRIMARY purpose of grouping and aggregation in data analysis?      To remove outliers from a dataset    While aggregation may reduce the impact of outliers in summary statistics, this is not the primary purpose of grouping and aggregation.      To understand patterns and variations across categories or subsets    Correct! The primary purpose of grouping and aggregation is to reveal how metrics and patterns vary across different categories or subsets, allowing for meaningful comparisons.      To reduce the size of large datasets    While aggregation does create a more compact summary, this is a side effect rather than the primary purpose of grouping and aggregation.      To correct errors in the original data    Grouping and aggregation do not correct errors in the original data; in fact, they might obscure some errors by combining them with correct values.     "
},
{
  "id": "activity-grouping",
  "level": "2",
  "url": "sec-summarizing-calculating.html#activity-grouping",
  "type": "Activity",
  "number": "23",
  "title": "Grouping and Aggregation in CODAP.",
  "body": " Grouping and Aggregation in CODAP   In this activity, you'll practice grouping and aggregating data in CODAP.     Identify at least two categorical variables in your dataset that would be meaningful to group by.      For each grouping variable, create a summary table in CODAP that shows aggregated measures (mean, count, etc.) of at least two numerical variables for each group.      Create visualizations comparing these groups. Use bar charts or box plots to show how the numerical variables differ across categories.      Try creating a two-way grouping by two different categorical variables. Examine how this more detailed breakdown reveals patterns that might not be apparent in single-variable groupings.    "
},
{
  "id": "sec-statistical-thinking-comparing",
  "level": "1",
  "url": "sec-statistical-thinking-comparing.html",
  "type": "Section",
  "number": "",
  "title": "Statistical Thinking: Comparing Groups",
  "body": " Statistical Thinking: Comparing Groups   Variation Within and Between Groups  When comparing groups, it's important to consider both the variation within each group and the variation between groups. This helps us determine whether observed differences are meaningful or might simply be due to random variation.     Within-group variation refers to how much values differ from each other within the same group or category.       Between-group variation refers to how much the typical values (e.g., means) differ across different groups or categories.     Within- and Between-Group Variation   Two scenarios: one showing large between-group differences with small within-group variation, and another showing small between-group differences with large within-group variation.    The relationship between within-group and between-group variation affects our ability to draw meaningful conclusions:    When between-group variation is large relative to within-group variation, group differences are more likely to be meaningful.    When within-group variation is large relative to between-group variation, apparent group differences might just reflect random variation.     Variation in Community Health Data   When comparing asthma rates across income levels in our Community Health dataset:    Within-group variation : The range of asthma rates among neighborhoods within the same income category (e.g., high-income neighborhoods might have asthma rates ranging from 5% to 12%).    Between-group variation : The difference in average asthma rates between income categories (e.g., high-income neighborhoods averaging 8% versus low-income neighborhoods averaging 15%).    If within-group variation is small (neighborhoods within the same income category have similar asthma rates) and between-group variation is large (different income categories have noticeably different average asthma rates), we might reasonably conclude that income level is associated with asthma prevalence.     Comparing Group Variations   Based on the box plots below, which statement is most accurate?  Within- and Between-Group Variation   Two scenarios: one showing large between-group differences with small within-group variation, and another showing small between-group differences with large within-group variation.   Method A has scores ranging from 60-80 with median 70, Method B has scores ranging from 65-85 with median 75, and Method C has scores ranging from 40-95 with median 72.      Method C is clearly the most effective teaching approach.    This is not supported by the data. While Method C has some high scores, it also has the lowest scores and the widest range, indicating inconsistent results.      There are no meaningful differences between the teaching methods.    This overlooks the notable differences in both median scores and score distributions among the methods.      Method B has the highest median score, but the differences between methods are modest.    This accurately notes Method B's higher median but doesn't address the important difference in variability.      Method B shows a higher median with relatively low variability, while Method C shows inconsistent results with high variability.    Correct! This statement accurately describes both the differences in central tendency (median scores) and the critical difference in within-group variation, with Method C showing much higher variability in outcomes than Methods A and B.        Making Meaningful Comparisons  To make meaningful comparisons between groups, consider these key principles:    Compare Like with Like  Ensure that groups are comparable in terms of relevant characteristics other than the one you're studying.    Consider Sample Size  Larger groups generally provide more reliable estimates than smaller groups.    Examine Both Summary Statistics and Distributions  Don't rely solely on averages; consider the full distribution of values within each group.    Visualize Comparisons  Use appropriate visualizations (box plots, bar charts with error bars, etc.) to show both central tendency and variation.    Test for Statistical Significance  When appropriate, use statistical tests to assess whether differences are likely due to chance.    Consider Practical Significance  Even statistically significant differences might not be practically meaningful if they're very small.     Meaningful Comparisons in Community Health   To meaningfully compare asthma rates between high-income and low-income neighborhoods in our dataset, we might:    Control for other factors by comparing neighborhoods with similar population density, age distribution, and geographic location    Ensure we have enough neighborhoods in each income category for reliable comparison    Examine not just average asthma rates but also the range and distribution within each income group    Create box plots showing asthma rates by income category, clearly displaying both central tendency and variation    Conduct a statistical test (e.g., t-test) to assess whether the difference in means is statistically significant    Consider whether the observed difference in asthma rates (e.g., 7 percentage points) is large enough to be medically and socially significant       Comparing Groups in Your Dataset   In this activity, you'll practice making meaningful comparisons between groups in your dataset.     Identify a categorical variable in your dataset that creates meaningful groups for comparison. This could be a variable that was in the original dataset or a derived categorical variable you created.      Select at least two numerical variables to compare across these groups.      Create appropriate visualizations (box plots, bar charts with measures of variation, etc.) to compare the groups.      Write a brief analysis of the comparisons, addressing:    What differences do you observe between groups?    How much variation exists within each group?    Are the differences large enough to be meaningful in the context of your research questions?    What factors might explain the differences you observed?        Group Comparison Pitfalls   For each scenario, identify the primary issue that could lead to misleading conclusions when comparing groups.     Scenario 1: A researcher compares the performance of students who chose to participate in an optional after-school program with those who did not.  What is the primary issue in this scenario?    a . Inadequate sample size    b . Self-selection bias    c . Comparing unlike time periods    d . Using inappropriate statistical tests    Scenario 2: An analyst reports that neighborhoods with more parks have lower crime rates, suggesting that parks reduce crime.  What is the primary issue in this scenario?    a . Insufficient visualization of the data    b . High within-group variation    c . Confusing correlation with causation    d . Outlier influence     Think about what assumptions or inferences are being made in each scenario, and whether they are supported by the data collection method or analysis.             Scenario 1: The primary issue is self-selection bias.  Students who choose to participate in optional programs may already be more motivated or higher-performing than those who don t. This self-selection bias means the groups differ in ways beyond just program participation.  Scenario 2: The primary issue is confusing correlation with causation.  The analyst observes a correlation (neighborhoods with more parks have lower crime) but suggests causation (parks reduce crime). Other factors like neighborhood wealth, housing density, or policing could explain both the presence of parks and lower crime rates.         "
},
{
  "id": "def-within-group-variation",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#def-within-group-variation",
  "type": "Definition",
  "number": "76",
  "title": "",
  "body": "   Within-group variation refers to how much values differ from each other within the same group or category.   "
},
{
  "id": "def-between-group-variation",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#def-between-group-variation",
  "type": "Definition",
  "number": "77",
  "title": "",
  "body": "   Between-group variation refers to how much the typical values (e.g., means) differ across different groups or categories.   "
},
{
  "id": "fig-within-between-variation",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#fig-within-between-variation",
  "type": "Figure",
  "number": "78",
  "title": "",
  "body": " Within- and Between-Group Variation   Two scenarios: one showing large between-group differences with small within-group variation, and another showing small between-group differences with large within-group variation.   "
},
{
  "id": "example-variation-health",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#example-variation-health",
  "type": "Example",
  "number": "79",
  "title": "Variation in Community Health Data.",
  "body": " Variation in Community Health Data   When comparing asthma rates across income levels in our Community Health dataset:    Within-group variation : The range of asthma rates among neighborhoods within the same income category (e.g., high-income neighborhoods might have asthma rates ranging from 5% to 12%).    Between-group variation : The difference in average asthma rates between income categories (e.g., high-income neighborhoods averaging 8% versus low-income neighborhoods averaging 15%).    If within-group variation is small (neighborhoods within the same income category have similar asthma rates) and between-group variation is large (different income categories have noticeably different average asthma rates), we might reasonably conclude that income level is associated with asthma prevalence.   "
},
{
  "id": "mc-variation-comparison",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#mc-variation-comparison",
  "type": "Checkpoint",
  "number": "80",
  "title": "Comparing Group Variations.",
  "body": " Comparing Group Variations   Based on the box plots below, which statement is most accurate?  Within- and Between-Group Variation   Two scenarios: one showing large between-group differences with small within-group variation, and another showing small between-group differences with large within-group variation.   Method A has scores ranging from 60-80 with median 70, Method B has scores ranging from 65-85 with median 75, and Method C has scores ranging from 40-95 with median 72.      Method C is clearly the most effective teaching approach.    This is not supported by the data. While Method C has some high scores, it also has the lowest scores and the widest range, indicating inconsistent results.      There are no meaningful differences between the teaching methods.    This overlooks the notable differences in both median scores and score distributions among the methods.      Method B has the highest median score, but the differences between methods are modest.    This accurately notes Method B's higher median but doesn't address the important difference in variability.      Method B shows a higher median with relatively low variability, while Method C shows inconsistent results with high variability.    Correct! This statement accurately describes both the differences in central tendency (median scores) and the critical difference in within-group variation, with Method C showing much higher variability in outcomes than Methods A and B.     "
},
{
  "id": "example-comparison-health",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#example-comparison-health",
  "type": "Example",
  "number": "81",
  "title": "Meaningful Comparisons in Community Health.",
  "body": " Meaningful Comparisons in Community Health   To meaningfully compare asthma rates between high-income and low-income neighborhoods in our dataset, we might:    Control for other factors by comparing neighborhoods with similar population density, age distribution, and geographic location    Ensure we have enough neighborhoods in each income category for reliable comparison    Examine not just average asthma rates but also the range and distribution within each income group    Create box plots showing asthma rates by income category, clearly displaying both central tendency and variation    Conduct a statistical test (e.g., t-test) to assess whether the difference in means is statistically significant    Consider whether the observed difference in asthma rates (e.g., 7 percentage points) is large enough to be medically and socially significant     "
},
{
  "id": "activity-group-comparison",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#activity-group-comparison",
  "type": "Activity",
  "number": "24",
  "title": "Comparing Groups in Your Dataset.",
  "body": " Comparing Groups in Your Dataset   In this activity, you'll practice making meaningful comparisons between groups in your dataset.     Identify a categorical variable in your dataset that creates meaningful groups for comparison. This could be a variable that was in the original dataset or a derived categorical variable you created.      Select at least two numerical variables to compare across these groups.      Create appropriate visualizations (box plots, bar charts with measures of variation, etc.) to compare the groups.      Write a brief analysis of the comparisons, addressing:    What differences do you observe between groups?    How much variation exists within each group?    Are the differences large enough to be meaningful in the context of your research questions?    What factors might explain the differences you observed?      "
},
{
  "id": "exercise-comparison-pitfalls",
  "level": "2",
  "url": "sec-statistical-thinking-comparing.html#exercise-comparison-pitfalls",
  "type": "Checkpoint",
  "number": "82",
  "title": "Group Comparison Pitfalls.",
  "body": " Group Comparison Pitfalls   For each scenario, identify the primary issue that could lead to misleading conclusions when comparing groups.     Scenario 1: A researcher compares the performance of students who chose to participate in an optional after-school program with those who did not.  What is the primary issue in this scenario?    a . Inadequate sample size    b . Self-selection bias    c . Comparing unlike time periods    d . Using inappropriate statistical tests    Scenario 2: An analyst reports that neighborhoods with more parks have lower crime rates, suggesting that parks reduce crime.  What is the primary issue in this scenario?    a . Insufficient visualization of the data    b . High within-group variation    c . Confusing correlation with causation    d . Outlier influence     Think about what assumptions or inferences are being made in each scenario, and whether they are supported by the data collection method or analysis.             Scenario 1: The primary issue is self-selection bias.  Students who choose to participate in optional programs may already be more motivated or higher-performing than those who don t. This self-selection bias means the groups differ in ways beyond just program participation.  Scenario 2: The primary issue is confusing correlation with causation.  The analyst observes a correlation (neighborhoods with more parks have lower crime) but suggests causation (parks reduce crime). Other factors like neighborhood wealth, housing density, or policing could explain both the presence of parks and lower crime rates.       "
},
{
  "id": "sec-unit3-summary",
  "level": "1",
  "url": "sec-unit3-summary.html",
  "type": "Section",
  "number": "",
  "title": "Unit 3 Summary",
  "body": " Unit 3 Summary  In this unit, we've explored essential data moves that transform raw data into meaningful insights:    Data Cleaning and Organization : We learned how to handle missing values, deal with outliers, and restructure data to prepare it for analysis.    Filtering and Subsetting : We explored techniques for creating focused subsets of data to answer specific questions and make meaningful comparisons.    Summarizing and Calculating : We examined summary statistics that capture key aspects of our data and learned to create derived variables that reveal new insights.    Grouping and Comparing : We developed skills for aggregating data by categories and making meaningful comparisons between groups.    We also explored important ethical considerations regarding selection bias and developed our statistical thinking about variation within and between groups.  By the end of this unit, you should have applied these data moves to both our Community Health dataset and your own chosen dataset. These skills provide the foundation for the more advanced visualization and communication techniques we'll explore in the next unit.   Unit 3 Reflection   Take some time to reflect on what you've learned in this unit:    Which data move did you find most challenging to implement, and why?    What surprised you about your dataset when you applied these data moves?    How have these data moves helped you address your investigation questions?    What new questions have emerged as you've worked with your data?       Unit 3 Review   Which sequence of data moves best represents a typical data analysis workflow?      Grouping → Cleaning → Filtering → Creating visualizations    This sequence is problematic because grouping data before cleaning it could lead to incorrect aggregations based on errors or missing values.      Cleaning → Creating derived variables → Filtering → Grouping and comparing    Correct! This sequence represents a logical workflow: first clean the data to address quality issues, then create any needed derived variables, then filter to focus on relevant subsets, and finally group and compare to identify patterns.      Filtering → Cleaning → Summarizing → Creating derived variables    Filtering before cleaning could result in removing data that might be valuable once cleaned, potentially introducing bias.      Creating derived variables → Summarizing → Cleaning → Grouping    Creating derived variables before cleaning could propagate errors into new variables, and summarizing before cleaning could lead to misleading statistics.      "
},
{
  "id": "sec-unit3-summary-3-1-1",
  "level": "2",
  "url": "sec-unit3-summary.html#sec-unit3-summary-3-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Data Cleaning and Organization "
},
{
  "id": "sec-unit3-summary-3-2-1",
  "level": "2",
  "url": "sec-unit3-summary.html#sec-unit3-summary-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Filtering and Subsetting "
},
{
  "id": "sec-unit3-summary-3-3-1",
  "level": "2",
  "url": "sec-unit3-summary.html#sec-unit3-summary-3-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Summarizing and Calculating "
},
{
  "id": "sec-unit3-summary-3-4-1",
  "level": "2",
  "url": "sec-unit3-summary.html#sec-unit3-summary-3-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Grouping and Comparing "
},
{
  "id": "exercise-unit3-reflection",
  "level": "2",
  "url": "sec-unit3-summary.html#exercise-unit3-reflection",
  "type": "Checkpoint",
  "number": "83",
  "title": "Unit 3 Reflection.",
  "body": " Unit 3 Reflection   Take some time to reflect on what you've learned in this unit:    Which data move did you find most challenging to implement, and why?    What surprised you about your dataset when you applied these data moves?    How have these data moves helped you address your investigation questions?    What new questions have emerged as you've worked with your data?     "
},
{
  "id": "mc-unit3-review",
  "level": "2",
  "url": "sec-unit3-summary.html#mc-unit3-review",
  "type": "Checkpoint",
  "number": "84",
  "title": "Unit 3 Review.",
  "body": " Unit 3 Review   Which sequence of data moves best represents a typical data analysis workflow?      Grouping → Cleaning → Filtering → Creating visualizations    This sequence is problematic because grouping data before cleaning it could lead to incorrect aggregations based on errors or missing values.      Cleaning → Creating derived variables → Filtering → Grouping and comparing    Correct! This sequence represents a logical workflow: first clean the data to address quality issues, then create any needed derived variables, then filter to focus on relevant subsets, and finally group and compare to identify patterns.      Filtering → Cleaning → Summarizing → Creating derived variables    Filtering before cleaning could result in removing data that might be valuable once cleaned, potentially introducing bias.      Creating derived variables → Summarizing → Cleaning → Grouping    Creating derived variables before cleaning could propagate errors into new variables, and summarizing before cleaning could lead to misleading statistics.     "
},
{
  "id": "sec-visualization-fundamentals",
  "level": "1",
  "url": "sec-visualization-fundamentals.html",
  "type": "Section",
  "number": "",
  "title": "Visualization Fundamentals",
  "body": " Visualization Fundamentals   The Power of Data Visualization  Data visualization serves several crucial functions in the data science process:    Exploration  Visualizations help us discover patterns, relationships, and outliers that might not be apparent in raw data or summary statistics.    Analysis  Visual representations allow us to compare groups, identify trends, and test hypotheses about our data.    Communication  Well-designed visualizations make complex findings accessible to others, supporting decision-making and action.    Engagement  Visual elements capture attention and make data more engaging and memorable than text or numbers alone.    The power of visualization is illustrated by Anscombe's Quartet , a set of four datasets with nearly identical statistical properties but dramatically different visual patterns:   Anscombe's Quartet   Four scatter plots showing datasets with identical summary statistics but very different patterns: a linear relationship, a curved relationship, a linear relationship with an outlier, and a vertical line with an outlier.    Each of the four datasets in Anscombe's Quartet has the same mean, variance, correlation, and linear regression line. If we relied only on these summary statistics, we'd miss the crucial differences between these datasets. Visualization reveals what statistics alone can hide.   Visualization Purpose   Which of the following is NOT a primary purpose of data visualization?      To discover patterns and relationships in data    This is a primary purpose of data visualization - helping analysts discover patterns, trends, and relationships that might not be apparent in raw data.      To communicate insights to diverse audiences    This is a primary purpose of data visualization - making complex findings accessible and understandable to various stakeholders.      To increase the volume of data that can be presented    Correct! While visualizations can represent large datasets, the primary goal is not to maximize the volume of data presented. In fact, effective visualization often involves carefully selecting what data to present to avoid overwhelming the viewer.      To identify outliers and unusual patterns    This is a primary purpose of data visualization - making outliers and anomalies in the data immediately visible for further investigation.        Choosing the Right Visualization  Different types of data and questions call for different visualization approaches. Selecting the right chart type is essential for effectively representing your data.  Here are some common visualization types and their appropriate uses:    Bar Charts\/Column Charts  Best for comparing values across discrete categories.  Vertical bars (columns): Good for comparing values across categories  Horizontal bars: Useful when category names are long or there are many categories  Grouped bars: For comparing multiple measurements across categories  Stacked bars: For showing composition within categories      Line Charts  Best for showing trends over time or continuous variables.  Single line: Shows trend in one variable  Multiple lines: Compares trends across groups  Area charts: Emphasize magnitude along with trend      Scatter Plots  Best for examining relationships between two numerical variables.  Simple scatter: Shows correlation between two variables  Bubble charts: Add a third dimension through point size  Scatter with groups: Compare relationships across categories      Pie Charts  Best for showing parts of a whole (composition) when there are few categories.  Use only when the sum is meaningful and categories are few (preferably 5 or fewer)  Consider alternatives like stacked bars for more effective comparison      Histograms  Best for showing the distribution of a single numerical variable.  Shows frequency of values falling within specific ranges (bins)  Reveals shape of distribution (normal, skewed, bimodal, etc.)      Box Plots  Best for showing distribution summary and comparing distributions.  Shows median, quartiles, range, and outliers  Excellent for comparing distributions across groups      Heat Maps  Best for showing patterns across two categorical dimensions.  Uses color intensity to represent a third variable  Good for large datasets with complex patterns      Maps  Best for showing spatial patterns and geographic distributions.  Choropleth maps: Color regions based on data values  Dot maps: Show individual locations or events       Common Chart Types from Medium.com .   Examples of various chart types including bar chart, line chart, scatter plot, pie chart, histogram, box plot, heat map, and map.    When choosing a visualization type, consider:    What question are you trying to answer?    What types of variables are you working with (categorical, numerical, time-based)?    What relationship or pattern are you trying to show (comparison, composition, distribution, relationship)?    Who is your audience and what is their level of data literacy?     Matching Chart Types to Questions   Match each data visualization question with the most appropriate chart type.     How has unemployment rate changed over the past 10 years?  Line chart    What is the relationship between study time and test scores?  Scatter plot    How do average incomes compare across different education levels?  Bar chart    What is the distribution of home prices in a neighborhood?  Histogram    How do temperature distributions vary across seasons?  Box plot    How is the city budget allocated across departments?  Pie chart      Chart Selection for Your Dataset   In this activity, you'll identify appropriate visualization types for different aspects of your dataset.     Write down at least three specific questions you want to answer with visualizations of your dataset.      For each question, identify:    The variables involved (including their types: categorical, numerical, time-based)    The most appropriate visualization type to answer the question    Why this visualization type is the best choice for your specific question        Share your choices with a classmate and provide feedback on each other's selections.       Principles of Effective Visualization  Creating effective visualizations requires more than just selecting the right chart type. Well-designed visualizations follow these key principles:    Show the Data  The primary purpose of a visualization is to clearly present the data. Avoid unnecessary decorations or \"chart junk\" that distracts from the data.    Reduce Cognitive Load  Make it as easy as possible for viewers to extract insights. Minimize the mental effort required to interpret the visualization.    Focus Attention  Use visual elements like color, size, and position to direct attention to the most important aspects of the data.    Provide Context  Include reference points, comparisons, or baselines that help viewers understand the significance of the data.    Be Truthful  Represent the data accurately without distortion. Ensure that visual encodings are proportional to the data values.    Specific design principles include:    Clear labeling : Include descriptive titles, axis labels, and legends    Thoughtful color use : Choose accessible color schemes and use color consistently and purposefully    Appropriate scales : Use scales that accurately represent the data, generally starting at zero for bar charts    Data-ink ratio : Maximize the ratio of \"ink\" used to display data versus decorative elements    Simplicity : Include only what's necessary, removing redundant or distracting elements    Consistency : Use consistent formats, scales, and styles across related visualizations    The Economist wrote a great article called, Mistakes, We've Drawn a Few that I would highly recommend reading to see several ways visuals are created that are misleading and better practices to follow when creating visuals from your data. Below you can see one of the graphs from that article, where the bad graph attempts to create a perfect correlation between dog weights and neck size by creating the y-axes disproportionally.   Good vs. Problematic Visualization   Two versions of the same chart: one with clear labeling, appropriate scale, and thoughtful design; the other with misleading scale, excessive decoration, and unclear labeling.     Visualizing Community Health Data   For our Community Health dataset, effective visualizations might include:    A scatter plot showing the relationship between air quality index and asthma rates across neighborhoods, with points colored by income level to reveal potential socioeconomic patterns    A grouped bar chart comparing multiple health metrics (asthma, obesity, heart disease) across different regions of the city, allowing for direct comparison of health outcomes    A choropleth map showing the spatial distribution of environmental risk factors across the city, revealing geographic patterns and potential hotspots    Box plots comparing the distribution of health outcomes across neighborhoods with different levels of green space access, showing both central tendency and variation    A connected scatter plot showing how the relationship between environmental factors and health outcomes has changed over time       Steps for Creating Effective Visualizations   Arrange the following steps in a logical order for creating an effective data visualization.     Clarify the specific question or insight you want the visualization to address.     Add as many decorative elements as possible to make the visualization attractive.    Select the appropriate chart type based on your data and question.    Use the most complex visualization possible to impress your audience.     Prepare and transform your data as needed for the visualization.    Create a first draft of the visualization with the essential elements.    Add clear titles, labels, and other contextual information.    Refine the design by removing clutter and emphasizing key insights.    Manipulate the scales to make patterns look more dramatic.     Think about how you would first plan what you want to show before deciding how to show it.     Visualization Critique   In this activity, you'll analyze and critique existing visualizations using the principles we've discussed.     Find three different data visualizations from news articles, reports, or websites. Try to include at least one visualization that you think is particularly effective and one that could be improved.      For each visualization, evaluate:    Is the chart type appropriate for the data and question?    How well does it follow the principles of effective visualization?    What works well about this visualization?    How could it be improved?        For the visualization that needs improvement, sketch or describe how you would redesign it to be more effective.       Creating Visualizations in CODAP  CODAP offers a variety of tools for creating interactive visualizations. Let's explore how to use these tools effectively.  Key visualization features in CODAP include:    Graph tool : Create scatter plots, line plots, and dot plots by dragging attributes to axes    Plot type menu : Change between dot plots, box plots, histograms, and other display types    Axis options : Adjust scales, binning, and other axis properties    Grouping : Split data into categories using the ruler tool    Legend attributes : Add color, size, or shape encoding by dragging attributes to the legend area    Connecting lines : Show connections between related points    Map tool : Display geographic data on interactive maps     CODAP Visualization Tools   Screenshot showing CODAP's interface for creating and customizing visualizations, with labeled tools for graphs, plot types, axis options, and other features.    Steps for creating effective visualizations in CODAP:    Open the Graph or Map tool from the main toolbar    Drag attributes from your dataset to the axes or legend area    Select the appropriate plot type from the menu    Adjust axis scales, binning, and other properties as needed    Add additional attributes to the legend to encode with color, size, or shape    Use the ruler tool to create groupings or reference lines    Add text objects with titles, labels, or explanatory notes    Arrange multiple visualizations to create a dashboard     Creating Visualizations in CODAP   In this activity, you'll practice creating various types of visualizations in CODAP using your dataset.     Create at least one of each of the following visualization types using your dataset:    Scatter plot showing the relationship between two numerical variables    Bar chart or dot plot comparing values across categories    Histogram showing the distribution of a numerical variable    Box plot comparing distributions across groups        For each visualization:    Add appropriate titles and labels    Adjust scales and binning as needed    Use color or other visual encodings to add an additional dimension    Write a brief interpretation of what the visualization reveals        Arrange your visualizations to create a simple dashboard with at least three different charts that together tell a story about your data.      CODAP Visualization Features   Which CODAP feature would be MOST appropriate for examining how a relationship between two numerical variables differs across categories?      Changing from a dot plot to a histogram    Changing to a histogram would show the distribution of a single variable, not the relationship between two variables across categories.      Adding connecting lines between points    Connecting lines are typically used to show sequences or paths between related points, not to distinguish between categories.      Dragging a categorical attribute to the legend area to color points by category    Correct! By dragging a categorical attribute to the legend area, points in the scatter plot will be colored according to their category, allowing you to visually distinguish how the relationship differs across categories.      Using the ruler tool to add reference lines    While reference lines can be helpful markers, they don't specifically help examine how relationships differ across categories.       "
},
{
  "id": "fig-anscombe",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#fig-anscombe",
  "type": "Figure",
  "number": "85",
  "title": "",
  "body": " Anscombe's Quartet   Four scatter plots showing datasets with identical summary statistics but very different patterns: a linear relationship, a curved relationship, a linear relationship with an outlier, and a vertical line with an outlier.   "
},
{
  "id": "mc-viz-purpose",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#mc-viz-purpose",
  "type": "Checkpoint",
  "number": "86",
  "title": "Visualization Purpose.",
  "body": " Visualization Purpose   Which of the following is NOT a primary purpose of data visualization?      To discover patterns and relationships in data    This is a primary purpose of data visualization - helping analysts discover patterns, trends, and relationships that might not be apparent in raw data.      To communicate insights to diverse audiences    This is a primary purpose of data visualization - making complex findings accessible and understandable to various stakeholders.      To increase the volume of data that can be presented    Correct! While visualizations can represent large datasets, the primary goal is not to maximize the volume of data presented. In fact, effective visualization often involves carefully selecting what data to present to avoid overwhelming the viewer.      To identify outliers and unusual patterns    This is a primary purpose of data visualization - making outliers and anomalies in the data immediately visible for further investigation.     "
},
{
  "id": "fig-chart-types",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#fig-chart-types",
  "type": "Figure",
  "number": "87",
  "title": "",
  "body": " Common Chart Types from Medium.com .   Examples of various chart types including bar chart, line chart, scatter plot, pie chart, histogram, box plot, heat map, and map.   "
},
{
  "id": "matching-chart-selection",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#matching-chart-selection",
  "type": "Checkpoint",
  "number": "88",
  "title": "Matching Chart Types to Questions.",
  "body": " Matching Chart Types to Questions   Match each data visualization question with the most appropriate chart type.     How has unemployment rate changed over the past 10 years?  Line chart    What is the relationship between study time and test scores?  Scatter plot    How do average incomes compare across different education levels?  Bar chart    What is the distribution of home prices in a neighborhood?  Histogram    How do temperature distributions vary across seasons?  Box plot    How is the city budget allocated across departments?  Pie chart    "
},
{
  "id": "activity-chart-selection",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#activity-chart-selection",
  "type": "Activity",
  "number": "25",
  "title": "Chart Selection for Your Dataset.",
  "body": " Chart Selection for Your Dataset   In this activity, you'll identify appropriate visualization types for different aspects of your dataset.     Write down at least three specific questions you want to answer with visualizations of your dataset.      For each question, identify:    The variables involved (including their types: categorical, numerical, time-based)    The most appropriate visualization type to answer the question    Why this visualization type is the best choice for your specific question        Share your choices with a classmate and provide feedback on each other's selections.    "
},
{
  "id": "subsec-visualization-principles-5-1-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-visualization-principles-5-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Clear labeling "
},
{
  "id": "subsec-visualization-principles-5-2-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-visualization-principles-5-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Thoughtful color use "
},
{
  "id": "subsec-visualization-principles-5-3-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-visualization-principles-5-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Appropriate scales "
},
{
  "id": "subsec-visualization-principles-5-4-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-visualization-principles-5-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Data-ink ratio "
},
{
  "id": "subsec-visualization-principles-5-5-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-visualization-principles-5-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Simplicity "
},
{
  "id": "subsec-visualization-principles-5-6-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-visualization-principles-5-6-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Consistency "
},
{
  "id": "fig-good-bad-viz",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#fig-good-bad-viz",
  "type": "Figure",
  "number": "89",
  "title": "",
  "body": " Good vs. Problematic Visualization   Two versions of the same chart: one with clear labeling, appropriate scale, and thoughtful design; the other with misleading scale, excessive decoration, and unclear labeling.   "
},
{
  "id": "example-viz-health",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#example-viz-health",
  "type": "Example",
  "number": "90",
  "title": "Visualizing Community Health Data.",
  "body": " Visualizing Community Health Data   For our Community Health dataset, effective visualizations might include:    A scatter plot showing the relationship between air quality index and asthma rates across neighborhoods, with points colored by income level to reveal potential socioeconomic patterns    A grouped bar chart comparing multiple health metrics (asthma, obesity, heart disease) across different regions of the city, allowing for direct comparison of health outcomes    A choropleth map showing the spatial distribution of environmental risk factors across the city, revealing geographic patterns and potential hotspots    Box plots comparing the distribution of health outcomes across neighborhoods with different levels of green space access, showing both central tendency and variation    A connected scatter plot showing how the relationship between environmental factors and health outcomes has changed over time     "
},
{
  "id": "parsons-viz-design",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#parsons-viz-design",
  "type": "Checkpoint",
  "number": "91",
  "title": "Steps for Creating Effective Visualizations.",
  "body": " Steps for Creating Effective Visualizations   Arrange the following steps in a logical order for creating an effective data visualization.     Clarify the specific question or insight you want the visualization to address.     Add as many decorative elements as possible to make the visualization attractive.    Select the appropriate chart type based on your data and question.    Use the most complex visualization possible to impress your audience.     Prepare and transform your data as needed for the visualization.    Create a first draft of the visualization with the essential elements.    Add clear titles, labels, and other contextual information.    Refine the design by removing clutter and emphasizing key insights.    Manipulate the scales to make patterns look more dramatic.     Think about how you would first plan what you want to show before deciding how to show it.   "
},
{
  "id": "activity-visualization-critique",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#activity-visualization-critique",
  "type": "Activity",
  "number": "26",
  "title": "Visualization Critique.",
  "body": " Visualization Critique   In this activity, you'll analyze and critique existing visualizations using the principles we've discussed.     Find three different data visualizations from news articles, reports, or websites. Try to include at least one visualization that you think is particularly effective and one that could be improved.      For each visualization, evaluate:    Is the chart type appropriate for the data and question?    How well does it follow the principles of effective visualization?    What works well about this visualization?    How could it be improved?        For the visualization that needs improvement, sketch or describe how you would redesign it to be more effective.    "
},
{
  "id": "subsec-codap-viz-4-1-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Graph tool "
},
{
  "id": "subsec-codap-viz-4-2-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Plot type menu "
},
{
  "id": "subsec-codap-viz-4-3-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Axis options "
},
{
  "id": "subsec-codap-viz-4-4-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Grouping "
},
{
  "id": "subsec-codap-viz-4-5-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Legend attributes "
},
{
  "id": "subsec-codap-viz-4-6-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-6-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Connecting lines "
},
{
  "id": "subsec-codap-viz-4-7-1",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#subsec-codap-viz-4-7-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Map tool "
},
{
  "id": "fig-codap-viz-tools",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#fig-codap-viz-tools",
  "type": "Figure",
  "number": "92",
  "title": "",
  "body": " CODAP Visualization Tools   Screenshot showing CODAP's interface for creating and customizing visualizations, with labeled tools for graphs, plot types, axis options, and other features.   "
},
{
  "id": "activity-codap-viz",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#activity-codap-viz",
  "type": "Activity",
  "number": "27",
  "title": "Creating Visualizations in CODAP.",
  "body": " Creating Visualizations in CODAP   In this activity, you'll practice creating various types of visualizations in CODAP using your dataset.     Create at least one of each of the following visualization types using your dataset:    Scatter plot showing the relationship between two numerical variables    Bar chart or dot plot comparing values across categories    Histogram showing the distribution of a numerical variable    Box plot comparing distributions across groups        For each visualization:    Add appropriate titles and labels    Adjust scales and binning as needed    Use color or other visual encodings to add an additional dimension    Write a brief interpretation of what the visualization reveals        Arrange your visualizations to create a simple dashboard with at least three different charts that together tell a story about your data.    "
},
{
  "id": "mc-codap-features",
  "level": "2",
  "url": "sec-visualization-fundamentals.html#mc-codap-features",
  "type": "Checkpoint",
  "number": "93",
  "title": "CODAP Visualization Features.",
  "body": " CODAP Visualization Features   Which CODAP feature would be MOST appropriate for examining how a relationship between two numerical variables differs across categories?      Changing from a dot plot to a histogram    Changing to a histogram would show the distribution of a single variable, not the relationship between two variables across categories.      Adding connecting lines between points    Connecting lines are typically used to show sequences or paths between related points, not to distinguish between categories.      Dragging a categorical attribute to the legend area to color points by category    Correct! By dragging a categorical attribute to the legend area, points in the scatter plot will be colored according to their category, allowing you to visually distinguish how the relationship differs across categories.      Using the ruler tool to add reference lines    While reference lines can be helpful markers, they don't specifically help examine how relationships differ across categories.     "
},
{
  "id": "sec-ethics-misleading",
  "level": "1",
  "url": "sec-ethics-misleading.html",
  "type": "Section",
  "number": "",
  "title": "Ethics Spotlight: Avoiding Misleading Visualizations",
  "body": " Ethics Spotlight: Avoiding Misleading Visualizations  Visualizations can powerfully communicate data insights, but they can also mislead viewers if not created responsibly. Understanding common ways visualizations can mislead helps us create more ethical data presentations.  Common misleading visualization practices include:    Truncated Axes  Starting bar charts or line charts at values other than zero can exaggerate differences. While non-zero baselines can be appropriate for line charts showing trends, they should be clearly indicated.    Manipulated Aspect Ratios  Changing the height-to-width ratio of a chart can make trends appear steeper or flatter than they actually are.    Cherry-Picking Data  Selectively including or excluding data points to support a particular narrative rather than showing the complete picture.    Problematic Color Scales  Using colors that imply judgment (e.g., red\/green) for neutral data, or using color scales that perceptually distort the data.    3D Charts for 2D Data  Using 3D effects for 2D data can distort proportions and make accurate comparisons difficult.    Inappropriate Chart Types  Using chart types that are not suited to the data or question, leading to misinterpretation.    Missing Context  Failing to provide necessary context, such as sample sizes, time periods, or relevant comparisons.    To create ethical visualizations:    Present data completely and accurately    Choose appropriate scales and chart types    Provide necessary context and uncertainty information    Use color and design elements thoughtfully    Consider diverse audience perspectives    Be transparent about data sources and processing     Ethical Considerations in Community Health Visualization   When visualizing our Community Health data, ethical considerations might include:    Ensuring bar charts comparing health outcomes across neighborhoods start at zero to avoid exaggerating differences    Including confidence intervals or other uncertainty indicators when showing health metrics based on small sample sizes    Using culturally sensitive color schemes when mapping data by neighborhood to avoid reinforcing stereotypes    Providing context about historical factors that might explain environmental disparities rather than just showing current differences    Being careful about implying causation when visualizing correlations between environmental factors and health outcomes    Including complete data rather than cherry-picking neighborhoods or time periods that support a particular narrative       Identifying Misleading Visualizations   For each visualization description, identify the primary way it might mislead viewers.     Scenario 1: A bar chart comparing company profits starts the y-axis at $50 million instead of zero, making a $5 million difference between competitors look very large.  What is the primary way this visualization might mislead viewers?    a . Truncated axis    b . Cherry-picking data    c . 3D effects    d . Inappropriate chart type    Scenario 2: A line chart shows a company s stock performance over only the three months when it performed best, without indicating that this is a selected portion of a longer time series.  What is the primary way this visualization might mislead viewers?    a . Problematic color scale    b . Cherry-picking data    c . Manipulated aspect ratio    d . Missing uncertainty information     Think about both what is shown in the visualization and how it is presented. Some visualization problems relate to selective inclusion of data, while others relate to visual perception and how data is represented.             Scenario 1: The primary issue is truncated axis.  Starting the y-axis above zero on a bar chart violates the principle that the length of bars should be proportional to the values they represent. This exaggerates the differences between values.  Scenario 2: The primary issue is cherry-picking data.  By selectively showing only the three best-performing months without proper context, the visualization presents an incomplete and potentially misleading picture of the company s overall performance.         Creating Ethical Alternatives   In this activity, you'll practice identifying and correcting misleading visualizations.     Working with a partner, create a deliberately misleading visualization using your dataset (or the Community Health dataset) in CODAP. Use at least one of the misleading techniques discussed.      Exchange your misleading visualization with another pair of students. For the visualization you receive:    Identify how the visualization might mislead viewers    Create an ethical alternative that presents the same data more accurately    Explain why your alternative is more ethical and effective        Discuss as a class: What responsibility do data scientists have to create ethical visualizations? How can we balance creating impactful visualizations with ensuring they're not misleading?     "
},
{
  "id": "example-ethical-viz-health",
  "level": "2",
  "url": "sec-ethics-misleading.html#example-ethical-viz-health",
  "type": "Example",
  "number": "94",
  "title": "Ethical Considerations in Community Health Visualization.",
  "body": " Ethical Considerations in Community Health Visualization   When visualizing our Community Health data, ethical considerations might include:    Ensuring bar charts comparing health outcomes across neighborhoods start at zero to avoid exaggerating differences    Including confidence intervals or other uncertainty indicators when showing health metrics based on small sample sizes    Using culturally sensitive color schemes when mapping data by neighborhood to avoid reinforcing stereotypes    Providing context about historical factors that might explain environmental disparities rather than just showing current differences    Being careful about implying causation when visualizing correlations between environmental factors and health outcomes    Including complete data rather than cherry-picking neighborhoods or time periods that support a particular narrative     "
},
{
  "id": "exercise-misleading-viz",
  "level": "2",
  "url": "sec-ethics-misleading.html#exercise-misleading-viz",
  "type": "Checkpoint",
  "number": "95",
  "title": "Identifying Misleading Visualizations.",
  "body": " Identifying Misleading Visualizations   For each visualization description, identify the primary way it might mislead viewers.     Scenario 1: A bar chart comparing company profits starts the y-axis at $50 million instead of zero, making a $5 million difference between competitors look very large.  What is the primary way this visualization might mislead viewers?    a . Truncated axis    b . Cherry-picking data    c . 3D effects    d . Inappropriate chart type    Scenario 2: A line chart shows a company s stock performance over only the three months when it performed best, without indicating that this is a selected portion of a longer time series.  What is the primary way this visualization might mislead viewers?    a . Problematic color scale    b . Cherry-picking data    c . Manipulated aspect ratio    d . Missing uncertainty information     Think about both what is shown in the visualization and how it is presented. Some visualization problems relate to selective inclusion of data, while others relate to visual perception and how data is represented.             Scenario 1: The primary issue is truncated axis.  Starting the y-axis above zero on a bar chart violates the principle that the length of bars should be proportional to the values they represent. This exaggerates the differences between values.  Scenario 2: The primary issue is cherry-picking data.  By selectively showing only the three best-performing months without proper context, the visualization presents an incomplete and potentially misleading picture of the company s overall performance.       "
},
{
  "id": "activity-ethical-viz",
  "level": "2",
  "url": "sec-ethics-misleading.html#activity-ethical-viz",
  "type": "Activity",
  "number": "28",
  "title": "Creating Ethical Alternatives.",
  "body": " Creating Ethical Alternatives   In this activity, you'll practice identifying and correcting misleading visualizations.     Working with a partner, create a deliberately misleading visualization using your dataset (or the Community Health dataset) in CODAP. Use at least one of the misleading techniques discussed.      Exchange your misleading visualization with another pair of students. For the visualization you receive:    Identify how the visualization might mislead viewers    Create an ethical alternative that presents the same data more accurately    Explain why your alternative is more ethical and effective        Discuss as a class: What responsibility do data scientists have to create ethical visualizations? How can we balance creating impactful visualizations with ensuring they're not misleading?    "
},
{
  "id": "sec-advanced-visualization",
  "level": "1",
  "url": "sec-advanced-visualization.html",
  "type": "Section",
  "number": "",
  "title": "Advanced Visualization and Analysis",
  "body": " Advanced Visualization and Analysis   Visualizing Multi-Variable Relationships  Real-world data often involves complex relationships between multiple variables. Advanced visualization techniques help us explore and communicate these multi-dimensional relationships.  Techniques for visualizing multi-variable relationships include:    Adding Dimensions with Visual Encodings    Color : Encoding categorical or numerical variables with color  Size : Encoding numerical variables with point or line size  Shape : Encoding categorical variables with different point shapes  Transparency : Using opacity to handle overplotting or indicate certainty      Small Multiples  Creating a series of similar charts for different categories or time periods, allowing for comparison across a third variable.    Faceting  Splitting a single visualization into multiple panels based on categories, creating a grid of related charts.    Layering  Overlaying multiple series or variables on the same visualization, using different colors or styles to distinguish them.    Interactive Techniques    Brushing and linking : Selections in one visualization highlight corresponding points in others  Filtering : Dynamically including or excluding data based on selection  Details on demand : Showing additional information when hovering over or selecting elements      The visual below from datascience.stackexchange.com employs several advanced visualization techniques to display four dimensions of data simultaneously. The x-axis plots GDP Per Capita while the y-axis shows Average Years Spent in Education, creating a spatial distribution of countries or regions. The color spectrum from red (low, 4.900) to green (high, 7.600) encodes Satisfaction levels, allowing viewers to quickly identify that higher GDP areas generally report higher satisfaction. Meanwhile, the size of each circle represents Feel Safe Scores, with larger bubbles indicating greater perceived safety (up to 89.60). This multidimensional approach creates visual patterns that reveal complex relationships between wealth, education, satisfaction, and safety that might be missed in simpler visualizations. The design leverages pre-attentive visual processing through position, color, and size to communicate relationships efficiently without overwhelming the viewer.   Multi-Variable Visualization Techniques   Examples of multi-variable visualizations: a scatter plot with color and size encoding, small multiples showing the same relationship across different categories, and a visualization with interactive elements.     Multi-Variable Community Health Visualizations   For our Community Health dataset, advanced multi-variable visualizations might include:    A scatter plot showing the relationship between green space access and asthma rates, with points colored by income level and sized by population density    Small multiples displaying the air quality-health relationship separately for each region of the city    A layered line chart showing trends in multiple health metrics over time, highlighting their relative changes    An interactive dashboard with linked visualizations where selecting high-pollution areas highlights corresponding neighborhoods in health outcome charts    A composite environmental quality score visualized as color on a map, with the ability to filter by different health outcome ranges      When creating multi-variable visualizations, be careful to:    Avoid overwhelming viewers with too much information at once    Ensure that each additional variable adds meaningful insight    Use visual encodings that are easy to distinguish and interpret    Provide clear legends and explanations for all encodings    Consider accessibility (e.g., colorblind-friendly palettes)     Multi-Variable Visualization Techniques   Which technique would be MOST appropriate for examining how the relationship between income and health outcomes varies across different regions of a city?      A pie chart showing the proportion of total health issues by region    A pie chart would only show the distribution of a single variable across regions, not the relationship between income and health outcomes.      A 3D scatter plot with x=income, y=health, z=region    Since region is a categorical variable, a 3D scatter plot with region as the z-axis would not be appropriate and would likely be difficult to interpret.      Small multiples showing income-health scatter plots separately for each region    Correct! Small multiples would create a separate scatter plot for each region, allowing direct comparison of how the income-health relationship varies across regions while maintaining the ability to see the full relationship within each region.      A stacked bar chart of health outcomes for each income bracket    A stacked bar chart would show composition but would make it difficult to clearly see the relationship between income and health outcomes across different regions.       Creating Multi-Variable Visualizations   In this activity, you'll create advanced visualizations that incorporate multiple variables from your dataset.     Create a scatter plot in CODAP that shows the relationship between two numerical variables in your dataset. Then enhance it by:    Adding color to represent a categorical variable    Using point size to represent a third numerical variable    Adding reference lines or other annotations to highlight patterns        Create small multiples for your data by:    Identifying a key categorical variable in your dataset    Creating separate but identical visualizations for each category    Arranging them in a grid for easy comparison        Explore the interactive capabilities of CODAP by:    Creating multiple linked visualizations of your data    Testing how selections in one visualization highlight corresponding points in others    Using this interactivity to identify patterns or relationships that weren't apparent in single visualizations         Statistical Thinking: Correlation and Relationships  As we create more complex visualizations, it's important to develop statistical thinking about the relationships we observe. Understanding correlation and other statistical relationships helps us interpret our visualizations more accurately.     Correlation is a statistical measure that expresses the extent to which two variables are linearly related. The correlation coefficient (r) ranges from -1 to +1, with values closer to +\/-1 indicating stronger relationships and 0 indicating no linear relationship.    Key concepts in understanding relationships:    Correlation vs. Causation  Correlation indicates that two variables change together but does not necessarily imply that one causes the other. Causal relationships require additional evidence beyond correlation.    Types of Relationships    Linear : Variables change at a constant rate relative to each other  Non-linear : The relationship follows a curve or more complex pattern  Monotonic : Variables change in the same direction but not necessarily at a constant rate  No relationship : Changes in one variable are not associated with changes in the other      Strength of Relationships    Strong : Points closely follow a pattern with little scatter  Moderate : Points generally follow a pattern but with noticeable scatter  Weak : Points loosely follow a pattern with substantial scatter      Direction of Relationships    Positive : Variables increase or decrease together  Negative : As one variable increases, the other decreases      Confounding Variables  Variables not included in the analysis that affect both variables being studied, potentially creating or masking relationships.    Simpson's Paradox  A phenomenon where a trend appears in several different groups of data but disappears or reverses when these groups are combined.     Types of Statistical Relationships from Online Math Learning   A grid of scatter plots showing different types of relationships: strong positive linear, weak positive linear, strong negative linear, no relationship, and various non-linear relationships.     Relationships in Community Health Data   In our Community Health dataset, we might observe various relationships:    A negative correlation between green space access and asthma rates, suggesting that neighborhoods with more green space tend to have lower asthma prevalence    A non-linear relationship between air pollution and distance from major highways, with pollution decreasing rapidly at first but then leveling off    No apparent relationship between neighborhood age and obesity rates, suggesting these variables aren't directly connected    A relationship between income and health outcomes that appears strong overall but weakens when examining specific regions separately (a potential Simpson's Paradox)    A correlation between air quality and asthma that might be confounded by income, as lower-income areas often have both worse air quality and less access to healthcare      When interpreting relationships in visualizations:    Look for patterns but be cautious about inferring causation    Consider potential confounding variables    Examine relationships within subgroups, not just overall    Be aware that correlation measures only capture linear relationships    Consider whether outliers are affecting the apparent relationship    Look for contextual factors that might explain observed relationships     Interpreting Correlations   A data scientist finds a strong positive correlation (r = 0.85) between ice cream sales and drowning incidents in a coastal city. Which of the following is the MOST appropriate interpretation?      Eating ice cream causes people to drown.    This incorrectly assumes causation from correlation. There's no logical mechanism by which ice cream consumption would directly cause drowning.      The correlation must be coincidental since these variables are unrelated.    This dismisses the strong correlation without considering possible explanations. A high correlation coefficient (0.85) suggests a relationship, even if indirect.      A third factor, such as hot weather or summer season, likely influences both variables.    Correct! This recognizes the correlation while identifying a plausible confounding variable. Hot weather\/summer likely increases both ice cream consumption and swimming activity (which increases drowning risk), creating an indirect relationship between the variables.      Drowning incidents cause increased ice cream sales.    This incorrectly assumes causation in the reverse direction, which is even less plausible than ice cream causing drowning.       Exploring Relationships in Your Dataset   In this activity, you'll explore and analyze relationships between variables in your dataset.     Create scatter plots for at least three different pairs of numerical variables in your dataset. For each pair:    Describe the pattern you observe (linear, non-linear, no relationship)    Estimate the strength (strong, moderate, weak) and direction (positive, negative) of any relationship    Calculate the correlation coefficient using CODAP's calculator        Select the strongest relationship you found and explore it further by:    Creating separate scatter plots for different subgroups (using a categorical variable)    Comparing the relationship across these subgroups    Looking for evidence of Simpson's Paradox or other subgroup differences        For the relationship you've been exploring:    Identify potential confounding variables that might influence both variables    Discuss whether the relationship might indicate causation or just correlation    Consider how you would communicate this relationship, including appropriate caveats, in your final presentation        "
},
{
  "id": "subsec-multi-variable-4-1-2",
  "level": "2",
  "url": "sec-advanced-visualization.html#subsec-multi-variable-4-1-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Color Size Shape Transparency "
},
{
  "id": "subsec-multi-variable-4-5-2",
  "level": "2",
  "url": "sec-advanced-visualization.html#subsec-multi-variable-4-5-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Brushing and linking Filtering Details on demand "
},
{
  "id": "fig-multi-variable",
  "level": "2",
  "url": "sec-advanced-visualization.html#fig-multi-variable",
  "type": "Figure",
  "number": "96",
  "title": "",
  "body": " Multi-Variable Visualization Techniques   Examples of multi-variable visualizations: a scatter plot with color and size encoding, small multiples showing the same relationship across different categories, and a visualization with interactive elements.   "
},
{
  "id": "example-multi-var-health",
  "level": "2",
  "url": "sec-advanced-visualization.html#example-multi-var-health",
  "type": "Example",
  "number": "97",
  "title": "Multi-Variable Community Health Visualizations.",
  "body": " Multi-Variable Community Health Visualizations   For our Community Health dataset, advanced multi-variable visualizations might include:    A scatter plot showing the relationship between green space access and asthma rates, with points colored by income level and sized by population density    Small multiples displaying the air quality-health relationship separately for each region of the city    A layered line chart showing trends in multiple health metrics over time, highlighting their relative changes    An interactive dashboard with linked visualizations where selecting high-pollution areas highlights corresponding neighborhoods in health outcome charts    A composite environmental quality score visualized as color on a map, with the ability to filter by different health outcome ranges     "
},
{
  "id": "mc-multi-var-techniques",
  "level": "2",
  "url": "sec-advanced-visualization.html#mc-multi-var-techniques",
  "type": "Checkpoint",
  "number": "98",
  "title": "Multi-Variable Visualization Techniques.",
  "body": " Multi-Variable Visualization Techniques   Which technique would be MOST appropriate for examining how the relationship between income and health outcomes varies across different regions of a city?      A pie chart showing the proportion of total health issues by region    A pie chart would only show the distribution of a single variable across regions, not the relationship between income and health outcomes.      A 3D scatter plot with x=income, y=health, z=region    Since region is a categorical variable, a 3D scatter plot with region as the z-axis would not be appropriate and would likely be difficult to interpret.      Small multiples showing income-health scatter plots separately for each region    Correct! Small multiples would create a separate scatter plot for each region, allowing direct comparison of how the income-health relationship varies across regions while maintaining the ability to see the full relationship within each region.      A stacked bar chart of health outcomes for each income bracket    A stacked bar chart would show composition but would make it difficult to clearly see the relationship between income and health outcomes across different regions.     "
},
{
  "id": "activity-multi-var",
  "level": "2",
  "url": "sec-advanced-visualization.html#activity-multi-var",
  "type": "Activity",
  "number": "29",
  "title": "Creating Multi-Variable Visualizations.",
  "body": " Creating Multi-Variable Visualizations   In this activity, you'll create advanced visualizations that incorporate multiple variables from your dataset.     Create a scatter plot in CODAP that shows the relationship between two numerical variables in your dataset. Then enhance it by:    Adding color to represent a categorical variable    Using point size to represent a third numerical variable    Adding reference lines or other annotations to highlight patterns        Create small multiples for your data by:    Identifying a key categorical variable in your dataset    Creating separate but identical visualizations for each category    Arranging them in a grid for easy comparison        Explore the interactive capabilities of CODAP by:    Creating multiple linked visualizations of your data    Testing how selections in one visualization highlight corresponding points in others    Using this interactivity to identify patterns or relationships that weren't apparent in single visualizations      "
},
{
  "id": "def-correlation",
  "level": "2",
  "url": "sec-advanced-visualization.html#def-correlation",
  "type": "Definition",
  "number": "99",
  "title": "",
  "body": "   Correlation is a statistical measure that expresses the extent to which two variables are linearly related. The correlation coefficient (r) ranges from -1 to +1, with values closer to +\/-1 indicating stronger relationships and 0 indicating no linear relationship.   "
},
{
  "id": "subsec-statistical-relationships-5-2-2",
  "level": "2",
  "url": "sec-advanced-visualization.html#subsec-statistical-relationships-5-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Linear Non-linear Monotonic No relationship "
},
{
  "id": "subsec-statistical-relationships-5-3-2",
  "level": "2",
  "url": "sec-advanced-visualization.html#subsec-statistical-relationships-5-3-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Strong Moderate Weak "
},
{
  "id": "subsec-statistical-relationships-5-4-2",
  "level": "2",
  "url": "sec-advanced-visualization.html#subsec-statistical-relationships-5-4-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Positive Negative "
},
{
  "id": "fig-correlation-types",
  "level": "2",
  "url": "sec-advanced-visualization.html#fig-correlation-types",
  "type": "Figure",
  "number": "100",
  "title": "",
  "body": " Types of Statistical Relationships from Online Math Learning   A grid of scatter plots showing different types of relationships: strong positive linear, weak positive linear, strong negative linear, no relationship, and various non-linear relationships.   "
},
{
  "id": "example-correlation-health",
  "level": "2",
  "url": "sec-advanced-visualization.html#example-correlation-health",
  "type": "Example",
  "number": "101",
  "title": "Relationships in Community Health Data.",
  "body": " Relationships in Community Health Data   In our Community Health dataset, we might observe various relationships:    A negative correlation between green space access and asthma rates, suggesting that neighborhoods with more green space tend to have lower asthma prevalence    A non-linear relationship between air pollution and distance from major highways, with pollution decreasing rapidly at first but then leveling off    No apparent relationship between neighborhood age and obesity rates, suggesting these variables aren't directly connected    A relationship between income and health outcomes that appears strong overall but weakens when examining specific regions separately (a potential Simpson's Paradox)    A correlation between air quality and asthma that might be confounded by income, as lower-income areas often have both worse air quality and less access to healthcare     "
},
{
  "id": "mc-correlation-interpretation",
  "level": "2",
  "url": "sec-advanced-visualization.html#mc-correlation-interpretation",
  "type": "Checkpoint",
  "number": "102",
  "title": "Interpreting Correlations.",
  "body": " Interpreting Correlations   A data scientist finds a strong positive correlation (r = 0.85) between ice cream sales and drowning incidents in a coastal city. Which of the following is the MOST appropriate interpretation?      Eating ice cream causes people to drown.    This incorrectly assumes causation from correlation. There's no logical mechanism by which ice cream consumption would directly cause drowning.      The correlation must be coincidental since these variables are unrelated.    This dismisses the strong correlation without considering possible explanations. A high correlation coefficient (0.85) suggests a relationship, even if indirect.      A third factor, such as hot weather or summer season, likely influences both variables.    Correct! This recognizes the correlation while identifying a plausible confounding variable. Hot weather\/summer likely increases both ice cream consumption and swimming activity (which increases drowning risk), creating an indirect relationship between the variables.      Drowning incidents cause increased ice cream sales.    This incorrectly assumes causation in the reverse direction, which is even less plausible than ice cream causing drowning.     "
},
{
  "id": "activity-relationships",
  "level": "2",
  "url": "sec-advanced-visualization.html#activity-relationships",
  "type": "Activity",
  "number": "30",
  "title": "Exploring Relationships in Your Dataset.",
  "body": " Exploring Relationships in Your Dataset   In this activity, you'll explore and analyze relationships between variables in your dataset.     Create scatter plots for at least three different pairs of numerical variables in your dataset. For each pair:    Describe the pattern you observe (linear, non-linear, no relationship)    Estimate the strength (strong, moderate, weak) and direction (positive, negative) of any relationship    Calculate the correlation coefficient using CODAP's calculator        Select the strongest relationship you found and explore it further by:    Creating separate scatter plots for different subgroups (using a categorical variable)    Comparing the relationship across these subgroups    Looking for evidence of Simpson's Paradox or other subgroup differences        For the relationship you've been exploring:    Identify potential confounding variables that might influence both variables    Discuss whether the relationship might indicate causation or just correlation    Consider how you would communicate this relationship, including appropriate caveats, in your final presentation      "
},
{
  "id": "sec-data-storytelling",
  "level": "1",
  "url": "sec-data-storytelling.html",
  "type": "Section",
  "number": "",
  "title": "Project Synthesis and Presentation",
  "body": " Project Synthesis and Presentation   Data Storytelling Principles  Data storytelling combines data analysis, visualization, and narrative to effectively communicate insights and inspire action. A good data story makes complex findings accessible, engaging, and memorable.     Data storytelling is the practice of building a narrative around data to help an audience understand the context, significance, and implications of the data. It combines analytical, visual, and narrative elements to transform data into insights that drive understanding and action.    Key elements of effective data storytelling:    Narrative Structure  A clear beginning, middle, and end that guides the audience through the data journey.  Setup : Introduce the context, question, or problem  Conflict\/Tension : Present the data, challenges, or unexpected findings  Resolution : Share insights, implications, and potential actions      Audience Focus  Tailoring the presentation to the specific needs, interests, and technical literacy of your audience.    Clear Message  A central insight or \"so what\" that the audience should remember.    Compelling Visuals  Well-designed visualizations that support and enhance the narrative.    Context and Relevance  Information that helps the audience understand why the data matters and how it connects to broader issues.    Human Element  Connecting data to human experiences, decisions, or impacts to increase engagement.     Data Story Structure (according to Oracle   A diagram showing the flow of a data story from context\/question through data presentation to insights and actions, with annotations for key elements at each stage.    Common data storytelling approaches:    Change over time : Showing evolution, trends, or transformations    Comparison : Highlighting similarities and differences between groups    Connection : Revealing relationships or networks    Outlier : Focusing on exceptional cases or anomalies    Zoom in\/out : Moving between big picture and specific details    Personal relevance : Connecting broad patterns to individual experiences     Community Health Data Story   A data story for our Community Health project might follow this structure:    Setup :   Introduce the context of environmental health disparities in the city  Establish the key questions about how environmental factors relate to health outcomes  Provide background on why this matters for public health and equity     Data Presentation :   Share a map visualizing health indicators across neighborhoods  Show key relationships between environmental factors and health outcomes  Highlight unexpected patterns or particularly affected areas     Insights :   Present the three most significant findings about environmental health relationships  Discuss how socioeconomic factors interact with these relationships  Address limitations and areas of uncertainty in the analysis     Resolution\/Call to Action :   Suggest potential interventions based on the findings  Identify neighborhoods most in need of environmental health improvements  Propose next steps for research or policy consideration        Data Storytelling Approaches   Which data storytelling approach would be MOST effective for communicating how unequal access to healthcare affects different demographic groups?      A technical analysis focusing on statistical significance and p-values    A highly technical approach focusing on statistical details would likely not be as effective for communicating inequities to a broad audience or driving understanding of human impact.      A comprehensive dashboard with all available metrics without narrative structure    While comprehensive data is valuable, presenting all metrics without a narrative structure or focus on human impact would make it difficult for the audience to identify key inequities or their implications.      A narrative that combines broad patterns of inequality with specific examples of how these affect individuals    Correct! This approach effectively combines data-driven patterns with human impact, making the inequities both statistically clear and emotionally resonant. Connecting aggregate data to individual experiences helps the audience understand both the scope and the human consequences of healthcare access disparities.      A presentation focused primarily on data collection methodology and limitations    While methodology and limitations are important to address, making them the primary focus would detract from communicating the actual inequities and their impact.       Planning Your Data Story   In this activity, you'll develop a structured data story for your project.     Define your data story by answering these questions:    Who is your primary audience? (e.g., classmates, general public, specific stakeholders)    What is the main message or insight you want to communicate?    Why should your audience care about this topic?    What action or response do you hope to inspire?        Create an outline for your data story with these components:    Introduction : Context, motivation, and key questions    Main sections : 2-4 key findings or insights, each supported by visualizations    Conclusion : Summary of main message, implications, and potential next steps        For each section of your story, identify:    The specific data or visualization that will support this part of the narrative    How you'll transition from one point to the next to create a coherent flow    Any potential questions or objections from your audience that you should address         Effective Presentation Techniques  Once you've developed your data story, you need to present it effectively to your audience. Good presentation techniques help ensure your insights are understood, remembered, and potentially acted upon.  Key aspects of effective data presentations:    Clear Structure  A logical flow that guides the audience through your analysis and findings.  Begin with a clear introduction of the topic and its importance  Present main findings in a logical sequence  End with conclusions, implications, and next steps      Visual Support  Well-designed slides or materials that enhance understanding.  Use consistent, clean design with minimal text  Ensure visualizations are large enough to be clearly visible  Highlight key points visually (through color, size, or position)      Engagement Techniques  Methods to maintain audience interest and involvement.  Start with a compelling hook or question  Use storytelling to create narrative flow  Include examples or scenarios that make data relevant      Clarity and Accessibility  Making your content understandable for your specific audience.  Define technical terms if necessary  Explain visualization types if they might be unfamiliar  Focus on insights rather than technical details (unless relevant for your audience)      Verbal Delivery  How you speak and present yourself.  Practice to ensure comfortable delivery and timing  Speak clearly and at an appropriate pace  Make eye contact with the audience      Tips for presenting data findings:    Start with the \"so what\" - the main insight or takeaway    Show the visualization, then explain what it shows (don't make the audience read and listen simultaneously)    Focus on the most important patterns or findings rather than describing every detail    Address limitations honestly but don't undermine your key findings    Be prepared for questions about methodology or alternative interpretations    End with clear implications or recommendations if appropriate     Organizing a Data Presentation   Arrange the following elements in a logical order for a data science presentation.     Introduction: Hook the audience with a compelling question or problem statement related to your data.    Context: Briefly explain the dataset, its sources, and why this analysis matters.     Technical details: Spend most of your time explaining data cleaning procedures and statistical methods.    Key findings: Present your most important insights, supported by clear visualizations.    Literature review: Extensively discuss how your work relates to previous research.     Implications: Discuss what your findings mean for understanding the issue or making decisions.    Limitations: Acknowledge constraints of your data or analysis to establish credibility.    Conclusion: Summarize key takeaways and suggest potential next steps or actions.    Detailed methodology appendix: Present all technical procedures in exhaustive detail.     Think about the logical flow of information that would help an audience understand and engage with your findings.     Preparing Your Presentation   In this activity, you'll prepare for your final project presentation.     Create an outline for your presentation, including:    Introduction: Hook, context, and main question(s)    Methods: Brief overview of your data sources and approach    Findings: 2-4 key insights from your analysis    Implications: What these findings mean and why they matter    Conclusion: Summary and potential next steps        Develop presentation materials:    Decide on presentation format (slides, live demo of CODAP dashboard, etc.)    Select key visualizations that best communicate your findings    Create any needed additional materials (handouts, reference sheets, etc.)        Practice your presentation:    Time yourself to ensure you stay within the allocated time    Practice explaining your visualizations clearly    Prepare for potential questions about your data or analysis        Peer review: Exchange presentation materials with a classmate and provide feedback on:    Clarity of main message    Effectiveness of visualizations    Flow and structure of the presentation    Any areas that might be confusing or need further explanation         Communicating Data Ethically and Effectively  The way we communicate data findings carries responsibility. Ethical and effective communication ensures that our analysis leads to understanding rather than misinterpretation.  Principles for ethical data communication:    Accuracy and Honesty  Present findings accurately without distortion, exaggeration, or omission of important context.    Transparency  Be open about data sources, methods, limitations, and uncertainties.    Respect for Audience  Avoid manipulation, oversimplification, or complexification that disrespects audience capabilities.    Cultural Sensitivity  Consider how findings might be interpreted by different groups and avoid reinforcing harmful stereotypes.    Privacy and Confidentiality  Protect individuals' privacy when communicating findings, especially with sensitive data.    Balanced Representation  Present multiple perspectives or interpretations when appropriate, rather than a single narrative.    Strategies for effective communication across different audiences:    For technical audiences : Include methodological details, statistical significance, and nuanced findings    For general audiences : Focus on clear insights, relatable examples, and visual explanation    For decision-makers : Emphasize implications, recommendations, and actionable insights    For diverse stakeholders : Consider multiple perspectives and potential impacts on different groups     Communicating Community Health Findings   When communicating findings from our Community Health project, we might:    Acknowledge limitations in our data, such as potential underreporting of health conditions in areas with less healthcare access    Present environmental disparities in historical and systemic context rather than implying they result from individual choices    Use neutral terminology when discussing neighborhood differences to avoid stigmatizing communities    Include perspectives from community members alongside statistical findings when possible    Be careful about how we present relationships between demographic factors and health outcomes to avoid reinforcing stereotypes    Clearly distinguish between correlation and causation in our environmental health findings       Ethical Data Communication   Which of the following represents the MOST ethical approach to communicating findings about educational achievement gaps between different demographic groups?      Avoid presenting the data entirely to prevent reinforcing stereotypes about any group.    While sensitivity is important, completely avoiding relevant data prevents understanding real disparities that might need addressing. Ethical communication involves presenting accurate information with appropriate context.      Present only the data that shows narrowing achievement gaps to focus on positive trends.    Selectively presenting only positive data creates an incomplete and potentially misleading picture. This approach lacks transparency and accuracy.      Present comprehensive data alongside contextual factors like historical inequities in school funding and resources.    Correct! This approach maintains accuracy by presenting the complete data while providing crucial context about systemic factors that influence educational outcomes. This helps audiences understand the complexities behind achievement gaps without reinforcing simplistic narratives about group differences.      Use dramatic visualizations to emphasize the gaps and create urgency for immediate action.    Using dramatic or exaggerated visualizations to evoke an emotional response can distort the data and manipulate the audience, which violates principles of accuracy and respect.       Communication Review   In this activity, you'll review and refine the communication aspects of your project.     Review your dashboard, presentation, or other communication materials with these questions:    Are there any ways your visualizations or narrative might inadvertently mislead viewers?    Have you adequately addressed limitations and uncertainty in your data and analysis?    Are there multiple perspectives or interpretations that should be acknowledged?    Does your communication respect the communities or populations represented in your data?        Based on your review, make at least three specific improvements to your communication materials to make them more ethical and effective.      Write a brief reflection (1-2 paragraphs) on the ethical considerations most relevant to your specific project and how you've addressed them in your communication.      "
},
{
  "id": "def-data-storytelling",
  "level": "2",
  "url": "sec-data-storytelling.html#def-data-storytelling",
  "type": "Definition",
  "number": "103",
  "title": "",
  "body": "   Data storytelling is the practice of building a narrative around data to help an audience understand the context, significance, and implications of the data. It combines analytical, visual, and narrative elements to transform data into insights that drive understanding and action.   "
},
{
  "id": "subsec-data-storytelling-5-1-2",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-5-1-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Setup Conflict\/Tension Resolution "
},
{
  "id": "fig-story-structure",
  "level": "2",
  "url": "sec-data-storytelling.html#fig-story-structure",
  "type": "Figure",
  "number": "104",
  "title": "",
  "body": " Data Story Structure (according to Oracle   A diagram showing the flow of a data story from context\/question through data presentation to insights and actions, with annotations for key elements at each stage.   "
},
{
  "id": "subsec-data-storytelling-8-1-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-8-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Change over time "
},
{
  "id": "subsec-data-storytelling-8-2-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-8-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Comparison "
},
{
  "id": "subsec-data-storytelling-8-3-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-8-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Connection "
},
{
  "id": "subsec-data-storytelling-8-4-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-8-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Outlier "
},
{
  "id": "subsec-data-storytelling-8-5-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-8-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Zoom in\/out "
},
{
  "id": "subsec-data-storytelling-8-6-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-data-storytelling-8-6-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Personal relevance "
},
{
  "id": "example-storytelling-health",
  "level": "2",
  "url": "sec-data-storytelling.html#example-storytelling-health",
  "type": "Example",
  "number": "105",
  "title": "Community Health Data Story.",
  "body": " Community Health Data Story   A data story for our Community Health project might follow this structure:    Setup :   Introduce the context of environmental health disparities in the city  Establish the key questions about how environmental factors relate to health outcomes  Provide background on why this matters for public health and equity     Data Presentation :   Share a map visualizing health indicators across neighborhoods  Show key relationships between environmental factors and health outcomes  Highlight unexpected patterns or particularly affected areas     Insights :   Present the three most significant findings about environmental health relationships  Discuss how socioeconomic factors interact with these relationships  Address limitations and areas of uncertainty in the analysis     Resolution\/Call to Action :   Suggest potential interventions based on the findings  Identify neighborhoods most in need of environmental health improvements  Propose next steps for research or policy consideration      "
},
{
  "id": "mc-storytelling",
  "level": "2",
  "url": "sec-data-storytelling.html#mc-storytelling",
  "type": "Checkpoint",
  "number": "106",
  "title": "Data Storytelling Approaches.",
  "body": " Data Storytelling Approaches   Which data storytelling approach would be MOST effective for communicating how unequal access to healthcare affects different demographic groups?      A technical analysis focusing on statistical significance and p-values    A highly technical approach focusing on statistical details would likely not be as effective for communicating inequities to a broad audience or driving understanding of human impact.      A comprehensive dashboard with all available metrics without narrative structure    While comprehensive data is valuable, presenting all metrics without a narrative structure or focus on human impact would make it difficult for the audience to identify key inequities or their implications.      A narrative that combines broad patterns of inequality with specific examples of how these affect individuals    Correct! This approach effectively combines data-driven patterns with human impact, making the inequities both statistically clear and emotionally resonant. Connecting aggregate data to individual experiences helps the audience understand both the scope and the human consequences of healthcare access disparities.      A presentation focused primarily on data collection methodology and limitations    While methodology and limitations are important to address, making them the primary focus would detract from communicating the actual inequities and their impact.     "
},
{
  "id": "activity-story-planning",
  "level": "2",
  "url": "sec-data-storytelling.html#activity-story-planning",
  "type": "Activity",
  "number": "31",
  "title": "Planning Your Data Story.",
  "body": " Planning Your Data Story   In this activity, you'll develop a structured data story for your project.     Define your data story by answering these questions:    Who is your primary audience? (e.g., classmates, general public, specific stakeholders)    What is the main message or insight you want to communicate?    Why should your audience care about this topic?    What action or response do you hope to inspire?        Create an outline for your data story with these components:    Introduction : Context, motivation, and key questions    Main sections : 2-4 key findings or insights, each supported by visualizations    Conclusion : Summary of main message, implications, and potential next steps        For each section of your story, identify:    The specific data or visualization that will support this part of the narrative    How you'll transition from one point to the next to create a coherent flow    Any potential questions or objections from your audience that you should address      "
},
{
  "id": "parsons-presentation",
  "level": "2",
  "url": "sec-data-storytelling.html#parsons-presentation",
  "type": "Checkpoint",
  "number": "107",
  "title": "Organizing a Data Presentation.",
  "body": " Organizing a Data Presentation   Arrange the following elements in a logical order for a data science presentation.     Introduction: Hook the audience with a compelling question or problem statement related to your data.    Context: Briefly explain the dataset, its sources, and why this analysis matters.     Technical details: Spend most of your time explaining data cleaning procedures and statistical methods.    Key findings: Present your most important insights, supported by clear visualizations.    Literature review: Extensively discuss how your work relates to previous research.     Implications: Discuss what your findings mean for understanding the issue or making decisions.    Limitations: Acknowledge constraints of your data or analysis to establish credibility.    Conclusion: Summarize key takeaways and suggest potential next steps or actions.    Detailed methodology appendix: Present all technical procedures in exhaustive detail.     Think about the logical flow of information that would help an audience understand and engage with your findings.   "
},
{
  "id": "activity-presentation-prep",
  "level": "2",
  "url": "sec-data-storytelling.html#activity-presentation-prep",
  "type": "Activity",
  "number": "32",
  "title": "Preparing Your Presentation.",
  "body": " Preparing Your Presentation   In this activity, you'll prepare for your final project presentation.     Create an outline for your presentation, including:    Introduction: Hook, context, and main question(s)    Methods: Brief overview of your data sources and approach    Findings: 2-4 key insights from your analysis    Implications: What these findings mean and why they matter    Conclusion: Summary and potential next steps        Develop presentation materials:    Decide on presentation format (slides, live demo of CODAP dashboard, etc.)    Select key visualizations that best communicate your findings    Create any needed additional materials (handouts, reference sheets, etc.)        Practice your presentation:    Time yourself to ensure you stay within the allocated time    Practice explaining your visualizations clearly    Prepare for potential questions about your data or analysis        Peer review: Exchange presentation materials with a classmate and provide feedback on:    Clarity of main message    Effectiveness of visualizations    Flow and structure of the presentation    Any areas that might be confusing or need further explanation      "
},
{
  "id": "subsec-effective-communication-6-1-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-effective-communication-6-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "For technical audiences "
},
{
  "id": "subsec-effective-communication-6-2-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-effective-communication-6-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "For general audiences "
},
{
  "id": "subsec-effective-communication-6-3-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-effective-communication-6-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "For decision-makers "
},
{
  "id": "subsec-effective-communication-6-4-1",
  "level": "2",
  "url": "sec-data-storytelling.html#subsec-effective-communication-6-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "For diverse stakeholders "
},
{
  "id": "example-communication-health",
  "level": "2",
  "url": "sec-data-storytelling.html#example-communication-health",
  "type": "Example",
  "number": "108",
  "title": "Communicating Community Health Findings.",
  "body": " Communicating Community Health Findings   When communicating findings from our Community Health project, we might:    Acknowledge limitations in our data, such as potential underreporting of health conditions in areas with less healthcare access    Present environmental disparities in historical and systemic context rather than implying they result from individual choices    Use neutral terminology when discussing neighborhood differences to avoid stigmatizing communities    Include perspectives from community members alongside statistical findings when possible    Be careful about how we present relationships between demographic factors and health outcomes to avoid reinforcing stereotypes    Clearly distinguish between correlation and causation in our environmental health findings     "
},
{
  "id": "mc-ethical-communication",
  "level": "2",
  "url": "sec-data-storytelling.html#mc-ethical-communication",
  "type": "Checkpoint",
  "number": "109",
  "title": "Ethical Data Communication.",
  "body": " Ethical Data Communication   Which of the following represents the MOST ethical approach to communicating findings about educational achievement gaps between different demographic groups?      Avoid presenting the data entirely to prevent reinforcing stereotypes about any group.    While sensitivity is important, completely avoiding relevant data prevents understanding real disparities that might need addressing. Ethical communication involves presenting accurate information with appropriate context.      Present only the data that shows narrowing achievement gaps to focus on positive trends.    Selectively presenting only positive data creates an incomplete and potentially misleading picture. This approach lacks transparency and accuracy.      Present comprehensive data alongside contextual factors like historical inequities in school funding and resources.    Correct! This approach maintains accuracy by presenting the complete data while providing crucial context about systemic factors that influence educational outcomes. This helps audiences understand the complexities behind achievement gaps without reinforcing simplistic narratives about group differences.      Use dramatic visualizations to emphasize the gaps and create urgency for immediate action.    Using dramatic or exaggerated visualizations to evoke an emotional response can distort the data and manipulate the audience, which violates principles of accuracy and respect.     "
},
{
  "id": "activity-communication-review",
  "level": "2",
  "url": "sec-data-storytelling.html#activity-communication-review",
  "type": "Activity",
  "number": "33",
  "title": "Communication Review.",
  "body": " Communication Review   In this activity, you'll review and refine the communication aspects of your project.     Review your dashboard, presentation, or other communication materials with these questions:    Are there any ways your visualizations or narrative might inadvertently mislead viewers?    Have you adequately addressed limitations and uncertainty in your data and analysis?    Are there multiple perspectives or interpretations that should be acknowledged?    Does your communication respect the communities or populations represented in your data?        Based on your review, make at least three specific improvements to your communication materials to make them more ethical and effective.      Write a brief reflection (1-2 paragraphs) on the ethical considerations most relevant to your specific project and how you've addressed them in your communication.    "
},
{
  "id": "sec-unit4-summary",
  "level": "1",
  "url": "sec-unit4-summary.html",
  "type": "Section",
  "number": "",
  "title": "Unit 4 Summary",
  "body": " Unit 4 Summary  In this unit, we've explored the art and science of data visualization and communication:    Visualization Fundamentals : We learned about the power of visualizations, principles for choosing the right chart types, and techniques for creating effective visual representations.    Ethics in Visualization : We examined how visualizations can mislead and how to create ethical representations that accurately convey data.    Advanced Visualization : We explored techniques for showing multi-variable relationships and building comprehensive dashboards to present our findings.    Statistical Thinking : We developed our understanding of correlation and other relationships, learning to interpret patterns with appropriate caution.    Data Storytelling : We discovered how to build compelling narratives around data that engage audiences and communicate insights effectively.    Presentation Techniques : We practiced methods for delivering our findings clearly and persuasively to different audiences.    Ethical Communication : We considered our responsibility to communicate findings accurately, transparently, and respectfully.    By applying these skills to both our Community Health dataset and your own chosen datasets, you've created visualizations, dashboards, and presentations that effectively communicate your findings and insights. These communication skills complement the technical data analysis abilities we've developed throughout the course, enabling you to not just analyze data but to share your discoveries in ways that inform, engage, and inspire action.   Unit 4 Reflection   Take some time to reflect on what you've learned in this unit and throughout the course:    What was the most valuable skill or concept you learned about data visualization and communication?    How has your understanding of effective data presentation changed during this unit?    What was the biggest challenge you faced in communicating your data findings, and how did you address it?    How might you apply the data science skills from this course in your future academic or professional work?       Unit 4 Review   Which of the following BEST describes the relationship between data analysis and data communication?      Data analysis is the only important aspect; communication is secondary and mainly for non-technical audiences.    This undervalues communication, which is essential for all audiences. Even the most sophisticated analysis has limited impact if not effectively communicated.      Data communication is about simplifying complex findings so non-experts can understand them.    While making findings accessible is important, effective data communication is not just about simplification; it's about conveying accurate insights appropriate to the audience and context.      Data visualization can make up for weaknesses in data analysis by making results look more impressive.    This approach would be misleading and unethical. Visualization should accurately represent analysis, not mask its weaknesses.      Data analysis and communication are equally essential parts of the data science process, with each informing and enhancing the other.    Correct! Analysis and communication are complementary, interdependent aspects of data science. Good analysis leads to meaningful insights, while effective communication ensures those insights are understood and can lead to action. The process is often iterative, with communication revealing needs for additional analysis.      "
},
{
  "id": "sec-unit4-summary-3-1-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Visualization Fundamentals "
},
{
  "id": "sec-unit4-summary-3-2-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Ethics in Visualization "
},
{
  "id": "sec-unit4-summary-3-3-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Advanced Visualization "
},
{
  "id": "sec-unit4-summary-3-4-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Statistical Thinking "
},
{
  "id": "sec-unit4-summary-3-5-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Data Storytelling "
},
{
  "id": "sec-unit4-summary-3-6-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-6-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Presentation Techniques "
},
{
  "id": "sec-unit4-summary-3-7-1",
  "level": "2",
  "url": "sec-unit4-summary.html#sec-unit4-summary-3-7-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Ethical Communication "
},
{
  "id": "exercise-unit4-reflection",
  "level": "2",
  "url": "sec-unit4-summary.html#exercise-unit4-reflection",
  "type": "Checkpoint",
  "number": "110",
  "title": "Unit 4 Reflection.",
  "body": " Unit 4 Reflection   Take some time to reflect on what you've learned in this unit and throughout the course:    What was the most valuable skill or concept you learned about data visualization and communication?    How has your understanding of effective data presentation changed during this unit?    What was the biggest challenge you faced in communicating your data findings, and how did you address it?    How might you apply the data science skills from this course in your future academic or professional work?     "
},
{
  "id": "mc-unit4-review",
  "level": "2",
  "url": "sec-unit4-summary.html#mc-unit4-review",
  "type": "Checkpoint",
  "number": "111",
  "title": "Unit 4 Review.",
  "body": " Unit 4 Review   Which of the following BEST describes the relationship between data analysis and data communication?      Data analysis is the only important aspect; communication is secondary and mainly for non-technical audiences.    This undervalues communication, which is essential for all audiences. Even the most sophisticated analysis has limited impact if not effectively communicated.      Data communication is about simplifying complex findings so non-experts can understand them.    While making findings accessible is important, effective data communication is not just about simplification; it's about conveying accurate insights appropriate to the audience and context.      Data visualization can make up for weaknesses in data analysis by making results look more impressive.    This approach would be misleading and unethical. Visualization should accurately represent analysis, not mask its weaknesses.      Data analysis and communication are equally essential parts of the data science process, with each informing and enhancing the other.    Correct! Analysis and communication are complementary, interdependent aspects of data science. Good analysis leads to meaningful insights, while effective communication ensures those insights are understood and can lead to action. The process is often iterative, with communication revealing needs for additional analysis.     "
},
{
  "id": "sec-project-overview",
  "level": "1",
  "url": "sec-project-overview.html",
  "type": "Section",
  "number": "",
  "title": "Project Overview",
  "body": " Project Overview  The course project is a semester-long data science investigation where you will:    Select a dataset aligned with your interests    Formulate meaningful statistical questions    Clean, organize, and transform the data    Create insightful visualizations    Build an interactive dashboard in CODAP    Present your findings in a clear, compelling manner    This project accounts for a large portion of your total grade in this class, but don't be overwhelmed! The project is designed to be completed incrementally throughout the semester, with specific milestones aligned to each unit of course content.   Learning Objectives  Through this project, you will demonstrate your ability to:    Apply data science concepts and techniques to real-world questions    Work effectively with data of varying quality and complexity    Create clear, accurate, and insightful data visualizations    Develop a coherent data narrative that communicates findings effectively    Critically evaluate data sources, limitations, and ethical considerations    Use CODAP to perform various data moves and create interactive visualizations      Dataset Selection Guidelines  Selecting an appropriate dataset is crucial for project success. Your dataset should:    Size and Complexity  Contain at least 100 records (rows) with at least 8 variables (columns). The dataset should be complex enough to support meaningful analysis but not so large that it becomes unmanageable in CODAP.    Variable Types  Include a mix of categorical and numerical variables to allow for diverse analysis and visualization techniques.    Quality and Completeness  Have reasonable completeness, but some missing values or quality issues are acceptable (and even educational to work with).    Interest and Relevance  Relate to a topic you find personally interesting or relevant, which will help sustain your engagement throughout the semester.    Accessibility  Be publicly available or properly licensed for educational use. You should be able to share the dataset with the instructor and classmates.    Recommended data repositories include:    Kaggle Datasets    Data.gov    Gapminder    Data.world    CDC Data & Statistics    World Bank Open Data     Dataset Evaluation Checklist    Use this checklist to evaluate potential datasets for your project. A suitable dataset should meet most of these criteria:    Contains at least 100 records (rows)    Includes at least 8 variables (columns)    Has a mix of categorical and numerical variables    Is on a topic that genuinely interests you    Has documentation about data collection methods and meanings of variables    Is reasonably clean but offers some opportunities for data cleaning practice    Can be easily imported into CODAP    Supports at least three meaningful statistical questions    Contains variables that might have interesting relationships    Is publicly available or properly licensed for educational use    Review the dataset you re considering and evaluate how many of these criteria it meets. A good dataset for your project should satisfy at least 7-8 of these items.   This checklist serves as a reference for dataset evaluation. There is no single correct answer, as the suitability of a dataset depends on your specific project needs. However, datasets meeting more criteria will generally provide better opportunities for meaningful analysis.         "
},
{
  "id": "exercise-dataset-evaluation",
  "level": "2",
  "url": "sec-project-overview.html#exercise-dataset-evaluation",
  "type": "Checkpoint",
  "number": "112",
  "title": "Dataset Evaluation Checklist.",
  "body": " Dataset Evaluation Checklist    Use this checklist to evaluate potential datasets for your project. A suitable dataset should meet most of these criteria:    Contains at least 100 records (rows)    Includes at least 8 variables (columns)    Has a mix of categorical and numerical variables    Is on a topic that genuinely interests you    Has documentation about data collection methods and meanings of variables    Is reasonably clean but offers some opportunities for data cleaning practice    Can be easily imported into CODAP    Supports at least three meaningful statistical questions    Contains variables that might have interesting relationships    Is publicly available or properly licensed for educational use    Review the dataset you re considering and evaluate how many of these criteria it meets. A good dataset for your project should satisfy at least 7-8 of these items.   This checklist serves as a reference for dataset evaluation. There is no single correct answer, as the suitability of a dataset depends on your specific project needs. However, datasets meeting more criteria will generally provide better opportunities for meaningful analysis.       "
},
{
  "id": "sec-project-workflow",
  "level": "1",
  "url": "sec-project-workflow.html",
  "type": "Section",
  "number": "",
  "title": "Project Workflow and Timeline",
  "body": " Project Workflow and Timeline  Your project will develop incrementally throughout the semester, with specific components aligned to the four main units of our course. Each phase builds on previous work, creating a coherent end-to-end data science project.   Recall the Data Science Investigation Process Framework developed by NCSU   A circular diagram showing the data science workflow: Ask Questions → Consider Data → Analyze Data → Interpret Results → Communicate Findings, with arrows showing the iterative nature of the process.     Phase 1: Dataset Selection + Exploration (Unit 1)  During this initial phase, you will:    Research and evaluate potential datasets based on the selection criteria    Select a dataset and document its source, contents, and relevance    Import your dataset into CODAP and perform initial exploration    Identify variable types and basic characteristics of your data    Consider potential ethical issues related to your dataset     Deliverable : Dataset Selection Report  A 1-2 page document that includes:    Dataset name, source, and link    Brief description of the dataset contents and context    Number of records and variables    List of key variables and their types    Why you selected this dataset and what interests you about it    Preliminary observations from initial exploration    Potential ethical considerations      Phase 2: Investigation Planning (Unit 2)  Building on your dataset exploration, you will:    Formulate 3-5 specific, meaningful statistical questions    Develop a comprehensive investigation plan    Identify data requirements for answering your questions    Assess data quality and potential limitations    Plan appropriate analysis approaches     Deliverable : Investigation Plan  A 2-3 page document that includes:    Refined statistical questions (clear, specific, answerable with data)    Required variables and data for each question    Assessment of data quality and completeness    Planned analysis methods and visualization approaches    Anticipated challenges and limitations    Expected outcomes or insights      Phase 3: Data Analysis and Processing (Unit 3)  In this phase, you will apply essential data moves to prepare your data for analysis:    Clean your dataset by handling missing values and outliers    Create derived variables as needed for your analysis    Filter and subset data to focus on relevant aspects    Calculate summary statistics and identify patterns    Group and aggregate data to gain higher-level insights    Document all transformations and decisions     Deliverable : Data Processing Documentation  A CODAP file and 2-3 page document that includes:    Summary of data quality issues encountered and how they were addressed    Description of derived variables created and their purpose    Documentation of filtering, grouping, and other data moves    Preliminary findings from summary statistics and grouping    Updated assessment of data limitations    CODAP file with processed data and basic visualizations      Phase 4: Visualization and Communication (Unit 4)  In the final phase, you will create effective visualizations and communicate your findings:    Design and create appropriate visualizations for your key findings    Build a comprehensive interactive dashboard in CODAP    Develop a clear data story based on your analysis    Prepare and deliver a final presentation    Document insights, implications, and limitations     Deliverable : Final Presentation    Final Presentation   5-7 minute presentation of your project  Clear communication of context, methods, and findings  Effective use of visualizations to support your narrative  Discussion of implications and limitations  Thoughtful responses to questions       Project Timeline   A timeline showing the four project phases aligned with the four course units, with key deliverables marked at the end of each phase.    "
},
{
  "id": "fig-project-workflow",
  "level": "2",
  "url": "sec-project-workflow.html#fig-project-workflow",
  "type": "Figure",
  "number": "113",
  "title": "",
  "body": " Recall the Data Science Investigation Process Framework developed by NCSU   A circular diagram showing the data science workflow: Ask Questions → Consider Data → Analyze Data → Interpret Results → Communicate Findings, with arrows showing the iterative nature of the process.   "
},
{
  "id": "subsec-phase1-4",
  "level": "2",
  "url": "sec-project-workflow.html#subsec-phase1-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Deliverable "
},
{
  "id": "subsec-phase2-4",
  "level": "2",
  "url": "sec-project-workflow.html#subsec-phase2-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Deliverable "
},
{
  "id": "subsec-phase3-4",
  "level": "2",
  "url": "sec-project-workflow.html#subsec-phase3-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Deliverable "
},
{
  "id": "subsec-phase4-4",
  "level": "2",
  "url": "sec-project-workflow.html#subsec-phase4-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Deliverable "
},
{
  "id": "fig-project-timeline",
  "level": "2",
  "url": "sec-project-workflow.html#fig-project-timeline",
  "type": "Figure",
  "number": "114",
  "title": "",
  "body": " Project Timeline   A timeline showing the four project phases aligned with the four course units, with key deliverables marked at the end of each phase.   "
},
{
  "id": "sec-project-assessment",
  "level": "1",
  "url": "sec-project-assessment.html",
  "type": "Section",
  "number": "",
  "title": "Assessment and Grading",
  "body": " Assessment and Grading  Your project will be assessed based on how well you demonstrate data science skills and concepts across all phases of the work. The grading emphasizes both technical proficiency and communication effectiveness.   Evaluation Rubrics  Each project component will be evaluated using the following rubrics:   Dataset Selection Report  For an A grade:    Dataset Suitability: Dataset perfectly meets all selection criteria; rich with potential for analysis    Documentation: Comprehensive documentation of source, contents, and context    Initial Exploration: Thorough initial exploration with insightful observations    Ethical Considerations: Thoughtful discussion of relevant ethical considerations    For a B-C grade:    Dataset Suitability: Dataset meets most criteria; adequate for project purposes    Documentation: Adequate documentation but missing some details    Initial Exploration: Basic exploration with some relevant observations    Ethical Considerations: Basic mention of ethical considerations    For a D-F grade:    Dataset Suitability: Dataset fails to meet multiple criteria; limited potential for analysis    Documentation: Minimal documentation; unclear source or context    Initial Exploration: Superficial exploration with few or no observations    Ethical Considerations: No consideration of ethical dimensions      Investigation Plan  For an A grade:    Statistical Questions: Clear, specific, meaningful questions that anticipate variability and are answerable with data    Data Assessment: Comprehensive assessment of data quality, completeness, and limitations    Analysis Approach: Well-reasoned approaches for each question, with clear justification    Plan Completeness: Thorough plan addressing all aspects of the investigation    For a B-C grade:    Statistical Questions: Mostly clear questions, but may lack specificity or clear connection to data    Data Assessment: Basic assessment of data with some gaps    Analysis Approach: Reasonable approaches but limited justification    Plan Completeness: Adequate plan but missing some elements    For a D-F grade:    Statistical Questions: Vague, overly broad, or unanswerable questions    Data Assessment: Minimal or unrealistic assessment of data    Analysis Approach: Inappropriate or vague analysis approaches    Plan Completeness: Incomplete or insufficient planning      Data Processing Documentation  For an A grade:    Data Cleaning: Appropriate handling of missing values, outliers, and other quality issues with clear rationale    Data Transformation: Creative and appropriate derived variables, filtering, and other transformations    Documentation: Clear, comprehensive documentation of all data moves and decisions    Preliminary Analysis: Insightful summary statistics and group comparisons    For a B-C grade:    Data Cleaning: Basic cleaning with some rationale, but may miss some issues    Data Transformation: Basic transformations that support analysis    Documentation: Adequate documentation but missing some details    Preliminary Analysis: Basic summary statistics with limited interpretation    For a D-F grade:    Data Cleaning: Inadequate cleaning or inappropriate handling of data issues    Data Transformation: Few or inappropriate transformations    Documentation: Poor or insufficient documentation    Preliminary Analysis: Minimal or incorrect statistical analysis      Final Presentation  For an A grade:    Content: Comprehensive coverage of context, methods, findings, and implications    Data Story: Compelling narrative that effectively communicates insights    Visual Support: Excellent use of visualizations to support and enhance presentation    Delivery: Clear, engaging delivery with strong command of material    Q&A Response: Thoughtful, knowledgeable responses to questions    For a B-C grade:    Content: Adequate coverage of key elements but lacking some depth    Data Story: Clear narrative but lacking some engagement or coherence    Visual Support: Adequate visual support with minor issues    Delivery: Competent delivery with some room for improvement    Q&A Response: Adequate responses to most questions    For a D-F grade:    Content: Incomplete or superficial treatment of the project    Data Story: Disjointed or unclear narrative    Visual Support: Poor or distracting visual elements    Delivery: Unclear, disorganized, or difficult to follow    Q&A Response: Unable to address questions effectively      "
},
{
  "id": "sec-project-tips",
  "level": "1",
  "url": "sec-project-tips.html",
  "type": "Section",
  "number": "",
  "title": "Tips for Success",
  "body": " Tips for Success  Based on experiences of previous students, here are some tips to help you succeed in your data science project:    Start with a Great Dataset  Invest time in finding a dataset that genuinely interests you and meets the selection criteria. Your enthusiasm for the topic will sustain you through challenges.    Work Incrementally  Don't wait until the last minute for each deliverable. The project is designed to be developed continuously throughout the semester.    Document as You Go  Keep detailed notes on your data moves, decisions, and observations. This will make writing the documentation much easier.    Seek Feedback Early  Share your work with classmates and the instructor to get feedback at each stage, not just when deliverables are due.    Focus on Quality over Quantity  It's better to thoroughly explore a few meaningful questions than to superficially address many questions.    Embrace the Iterative Process  Be prepared to revisit and revise earlier work as you gain new insights. Data science is rarely a linear process.    Practice Your Presentation  Rehearse your final presentation multiple times to ensure clear communication and appropriate timing.    Remember that data science is both an art and a science. Technical skills matter, but so does the ability to ask good questions, find meaningful patterns, and communicate insights effectively.   Common Challenges and Solutions  Here are some common challenges students face in their projects and strategies to address them:    Dataset Too Large for CODAP  Solution: Consider using a relevant subset of the data, or aggregate the data at a higher level (e.g., monthly instead of daily).    Too Many Missing Values  Solution: Determine if the missing values follow a pattern. You might focus on a subset with more complete data or use the missing data pattern itself as an insight.    Not Finding Clear Patterns  Solution: Try different groupings, transformations, or visualization approaches. Sometimes, finding that expected relationships don't exist is itself an important finding.    Questions Too Broad or Narrow  Solution: Refine your questions based on initial data exploration. Iteratively adjust the scope to match what your data can reasonably answer.    Difficulty Telling a Coherent Story  Solution: Start with your most interesting finding and build your narrative around it. Consider how different insights relate to each other and to your central question.      Project Planning Reflection   Take some time to reflect on your approach to the project:    What topics or datasets are you most interested in exploring?    What specific skills from the course do you most want to develop through this project?    What do you anticipate being the most challenging aspect of the project for you?    What strategies will you use to stay on track throughout the semester?    How will you ensure that your final project effectively communicates your findings?      "
},
{
  "id": "exercise-project-reflection",
  "level": "2",
  "url": "sec-project-tips.html#exercise-project-reflection",
  "type": "Checkpoint",
  "number": "115",
  "title": "Project Planning Reflection.",
  "body": " Project Planning Reflection   Take some time to reflect on your approach to the project:    What topics or datasets are you most interested in exploring?    What specific skills from the course do you most want to develop through this project?    What do you anticipate being the most challenging aspect of the project for you?    What strategies will you use to stay on track throughout the semester?    How will you ensure that your final project effectively communicates your findings?     "
},
{
  "id": "sec-codap-basics",
  "level": "1",
  "url": "sec-codap-basics.html",
  "type": "Section",
  "number": "",
  "title": "Getting Started with CODAP",
  "body": " Getting Started with CODAP   Accessing CODAP  CODAP is a free, web-based application that runs in your browser. There's no need to download or install anything.    Access CODAP at codap.concord.org    No account is required to use CODAP, though creating an account allows you to save your work to the cloud    Documents can be saved locally to your computer as .codap files even without an account    CODAP works in all modern browsers (Chrome, Firefox, Safari, Edge)     CODAP Homepage   Screenshot of the CODAP homepage showing the welcome screen with options to create a new document, open examples, or open a local file.      Interface Overview  When you first open CODAP, you'll see a blank document with a menu bar at the top. The main workspace is where you'll create and arrange data views.  The primary components of the CODAP interface include:    Main Menu  Located at the top, providing access to file operations, examples, help, and tools.    Document Toolbar  Contains buttons for adding tables, graphs, text objects, maps, and other components.    Workspace  The main area where tables, graphs, and other components are displayed and arranged.    Component Windows  Individual windows for tables, graphs, etc., which can be moved, resized, minimized, or closed.     CODAP Interface Elements   Labeled screenshot showing the main elements of the CODAP interface including the menu bar, toolbar, workspace, and component windows.    Key features of the CODAP interface:    All components (tables, graphs, etc.) can be freely arranged in the workspace    Components can be resized by dragging their edges    Multiple components can be open simultaneously and interact with each other    Selected elements in one component are automatically highlighted in others      Importing Data  There are several ways to get data into CODAP:    Opening Example Documents  From the main menu, select \"Example Documents\" to explore pre-made CODAP files with data.    Importing from CSV or other file formats  From the main menu, select \"Import...\" to bring data from a local file.    Copy and Paste  Copy data from a spreadsheet and paste it directly into a CODAP table.    Manual Entry  Create a new table and enter data manually.    Using Plugins  Some plugins allow importing data from specific sources like Google Sheets.    To create a new table:    Click the \"Table\" button in the toolbar    Name your table when prompted    Click \"+\" to add attributes (columns)    Enter data or use the import options described above     "
},
{
  "id": "fig-codap-homepage",
  "level": "2",
  "url": "sec-codap-basics.html#fig-codap-homepage",
  "type": "Figure",
  "number": "116",
  "title": "",
  "body": " CODAP Homepage   Screenshot of the CODAP homepage showing the welcome screen with options to create a new document, open examples, or open a local file.   "
},
{
  "id": "fig-codap-interface2",
  "level": "2",
  "url": "sec-codap-basics.html#fig-codap-interface2",
  "type": "Figure",
  "number": "117",
  "title": "",
  "body": " CODAP Interface Elements   Labeled screenshot showing the main elements of the CODAP interface including the menu bar, toolbar, workspace, and component windows.   "
},
{
  "id": "sec-core-features",
  "level": "1",
  "url": "sec-core-features.html",
  "type": "Section",
  "number": "",
  "title": "Core CODAP Features",
  "body": " Core CODAP Features   Working with Tables  Tables are the primary way to view and edit data in CODAP. Key operations include:    Adding and Renaming Attributes    Click \"+\" in the table header to add a new attribute (column)  Double-click an attribute name to rename it  Right-click an attribute for more options      Sorting Data    Click on an attribute name to sort ascending  Click again to sort descending  Click a third time to return to original order      Editing Values    Click directly on a cell to edit its value  Press Tab to move to the next cell  Press Enter to confirm an edit      Adding Cases (Rows)    Click \"+\" below the last row to add a new case  Right-click in the row area for options to insert or delete cases      Selecting Cases    Click on a row to select a single case  Shift+click to select a range of cases  Ctrl\/Cmd+click to select multiple non-adjacent cases       Tips for working with tables:     Use consistent naming conventions for attributes (e.g., lowercase with underscores, or camelCase)    Right-click on attribute names to access additional options like hiding or deleting    Resize columns by dragging the dividers between attribute names    Hold Shift while resizing to maintain proportions of all columns    Use the ruler tool (available in the attribute menu) to create groups within a column      Creating and Customizing Graphs  CODAP's graphing capabilities are powerful yet easy to use. To create a graph:    Click the \"Graph\" button in the toolbar    Drag an attribute from the table to the horizontal (x) axis    Drag another attribute to the vertical (y) axis    Optionally, drag attributes to the legend area to encode with color, size, or shape    Graph types available in CODAP include:    Scatter Plots  Shows the relationship between two numerical attributes.    Dot Plots  Displays distributions of single attributes, with one axis showing values and the other showing counts.    Box Plots  Shows distributions with median, quartiles, and outliers.    Histograms  Displays frequency distributions with bins.    Bar Charts  Shows counts or other metrics for categorical data.    To customize a graph:    Click the graph type icon to switch between plot types    Click on axis labels to adjust scales, titles, and other properties    Use the ruler tool to add reference lines or divide data into groups    Click on the palette icon to customize colors, point sizes, or other visual properties    Click \"Plot Options\" for additional settings specific to the current plot type     Tips for effective graphs:     Choose the appropriate graph type for your data and question    Use color, size, or shape to add additional dimensions to your visualization    Add meaningful axis labels by clicking on the default labels    Adjust axis scales if the default doesn't show your data effectively    For histograms, experiment with different bin widths to find meaningful patterns    Remember that selections in graphs automatically highlight corresponding data in tables and other graphs      Creating Calculated Attributes  One of CODAP's most powerful features is the ability to create new attributes based on calculations using existing data. To create a calculated attribute:    Click \"+\" in the table header to add a new attribute    Name your new attribute    Click the \"calculator\" icon that appears in the attribute header    Enter a formula in the formula editor    Click \"Apply\" to create the calculated attribute    Common operators and functions available in the formula editor:   CODAP Formula Elements    Category  Examples  Description    Basic Operators  +, -, *, \/, ^  Addition, subtraction, multiplication, division, exponentiation    Comparison Operators  <, >, =, <=, >=, !=  Less than, greater than, equal to, etc.    Logical Operators  and, or, not  Combine conditions    Math Functions  sqrt(), abs(), round(), log()  Square root, absolute value, rounding, logarithm    Text Functions  concat(), length(), upper()  Combine text, get length, convert to uppercase    Conditional Functions  if(condition, trueValue, falseValue)  Return different values based on a condition      Example Calculations in CODAP   Here are some useful calculations you might create:    Convert units: temperature_c * 9\/5 + 32 (Celsius to Fahrenheit)    Calculate a ratio: weight \/ height^2 (Body Mass Index)    Create a category: if(score >= 90, \"A\", if(score >= 80, \"B\", if(score >= 70, \"C\", \"D\")))    Calculate percent change: (new_value - old_value) \/ old_value * 100    Combine text: concat(first_name, \" \", last_name)       Tips for calculated attributes:     Use descriptive names for calculated attributes    Formulas automatically update if the source attributes change    You can reference other calculated attributes in your formulas    For complex calculations, consider breaking them into multiple attributes    Use the formula history to retrieve previous calculations    Right-click on attribute names to edit existing formulas      Geographic Mapping  CODAP includes basic mapping capabilities for visualizing geographic data:    Click the \"Map\" button in the toolbar to create a map    Drag attributes containing latitude and longitude to the appropriate fields    Optionally, drag another attribute to the legend to color points by category or value    Map features include:    Pan by dragging the map background    Zoom using the + and - buttons or scroll wheel    Change the base map using the layers icon    Select points on the map to highlight corresponding data in tables and graphs    Adjust point appearance using the point style controls     Requirements for mapping:     Data must include latitude and longitude coordinates in decimal degrees    Latitude ranges from -90° (South) to 90° (North)    Longitude ranges from -180° (West) to 180° (East)    For data with location names but no coordinates, you may need to add coordinate attributes     "
},
{
  "id": "subsec-working-with-tables-4",
  "level": "2",
  "url": "sec-core-features.html#subsec-working-with-tables-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Tips for working with tables: "
},
{
  "id": "subsec-creating-graphs-8",
  "level": "2",
  "url": "sec-core-features.html#subsec-creating-graphs-8",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Tips for effective graphs: "
},
{
  "id": "subsec-calculated-attributes-5",
  "level": "2",
  "url": "sec-core-features.html#subsec-calculated-attributes-5",
  "type": "Table",
  "number": "118",
  "title": "CODAP Formula Elements",
  "body": " CODAP Formula Elements    Category  Examples  Description    Basic Operators  +, -, *, \/, ^  Addition, subtraction, multiplication, division, exponentiation    Comparison Operators  <, >, =, <=, >=, !=  Less than, greater than, equal to, etc.    Logical Operators  and, or, not  Combine conditions    Math Functions  sqrt(), abs(), round(), log()  Square root, absolute value, rounding, logarithm    Text Functions  concat(), length(), upper()  Combine text, get length, convert to uppercase    Conditional Functions  if(condition, trueValue, falseValue)  Return different values based on a condition    "
},
{
  "id": "example-calculations",
  "level": "2",
  "url": "sec-core-features.html#example-calculations",
  "type": "Example",
  "number": "119",
  "title": "Example Calculations in CODAP.",
  "body": " Example Calculations in CODAP   Here are some useful calculations you might create:    Convert units: temperature_c * 9\/5 + 32 (Celsius to Fahrenheit)    Calculate a ratio: weight \/ height^2 (Body Mass Index)    Create a category: if(score >= 90, \"A\", if(score >= 80, \"B\", if(score >= 70, \"C\", \"D\")))    Calculate percent change: (new_value - old_value) \/ old_value * 100    Combine text: concat(first_name, \" \", last_name)     "
},
{
  "id": "subsec-calculated-attributes-7",
  "level": "2",
  "url": "sec-core-features.html#subsec-calculated-attributes-7",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Tips for calculated attributes: "
},
{
  "id": "subsec-mapping-6",
  "level": "2",
  "url": "sec-core-features.html#subsec-mapping-6",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Requirements for mapping: "
},
{
  "id": "sec-advanced-techniques",
  "level": "1",
  "url": "sec-advanced-techniques.html",
  "type": "Section",
  "number": "",
  "title": "Advanced CODAP Techniques",
  "body": " Advanced CODAP Techniques   Working with Hierarchical Data  CODAP supports hierarchical data structures, where cases at one level contain cases at another level. Examples include:    Schools containing students    Countries containing cities    Experiments containing trials    To create hierarchical data:    Create a new collection (table) using the \"New Collection...\" option in the table menu    Specify the parent-child relationship between collections    Add attributes to each collection as needed    Benefits of hierarchical data:    Organize data at different levels of granularity    Analyze aggregated data (e.g., average test scores per school)    Easily filter across related collections    Maintain relationships between different units of analysis      Advanced Filtering Techniques  CODAP offers several ways to filter your data:    Selection Filtering    Select cases in any view (table, graph, map)  Use the \"eyeball\" icon in the table to show only selected cases  Click again to show all cases      Formula-Based Filtering    Click the filter icon in the table header  Enter a formula that evaluates to true or false (e.g., price < 100 )  Only cases where the formula is true will be shown      Creating Subsets    Select cases of interest  Use \"New Collection From Selection\" from the table menu  This creates a new collection containing only the selected cases      Using Categorical Attributes    Create a categorical attribute using a formula (e.g., if(score > 70, \"Pass\", \"Fail\") )  Use this attribute in graphs to separate data into groups  Select specific categories to filter the data      Complex filtering examples:    Multiple conditions: (price < 100) and (rating >= 4)    Either\/or conditions: (category = \"Electronics\") or (category = \"Appliances\")    Exclusion: not(state = \"California\")    Range filtering: (age >= 18) and (age <= 65)    Text contains: contains(name, \"Smith\")      Advanced Data Import and Export  Beyond basic CSV importing, CODAP provides several advanced data handling options:    Importing from Plugins    Click the \"Plugins\" button in the toolbar  Select data connectors like \"Google Sheets\" or \"Data Interactives\"  Follow the plugin-specific instructions to import data      Importing Multiple Tables    Import each table separately  Use \"Relate Collections...\" to establish relationships between tables      Exporting Data    Use \"Export Case Data...\" from the table menu  Choose CSV or tab-delimited format  Select which attributes to include      Saving and Sharing CODAP Documents    Use \"Save\" to download as a .codap file  Use \"Share\" to generate a shareable link (requires account)  Use \"Create Poster\" to create a static view for presentation       Tips for data handling:     Keep original data intact by working with copies when making significant changes    Save your work frequently as CODAP files    When importing CSV files, check that numeric data is recognized correctly (not imported as text)    Use text attributes for identification codes, even if they contain numbers    Export your processed data if you need to use it in other applications      Building Interactive Dashboards  CODAP's flexible interface allows you to create interactive dashboards by combining multiple components:    Create tables, graphs, maps, and text objects that provide different views of your data    Arrange these components in a logical layout by dragging and resizing    Use text objects to add titles, explanations, or context    Take advantage of CODAP's automatic linking between components    Dashboard features to utilize:    Linked selection : Selecting items in one view highlights them in all views    Show\/hide components : Minimize components temporarily using the minimize button    Text objects : Add context with the \"Text\" button in the toolbar    Colored backgrounds : Use the gear icon in component windows to change background colors    Multiple representations : Show the same data in different ways (e.g., table, graph, map)     Dashboard design tips:     Place the most important visualizations prominently    Organize components in a logical flow (e.g., overview to detail)    Use consistent colors and styles across components    Include brief text explanations to guide users    Test the dashboard by selecting different data points to ensure linking works correctly    Resize the browser window to check how your dashboard adapts to different screen sizes     "
},
{
  "id": "subsec-data-import-export-4",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-data-import-export-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Tips for data handling: "
},
{
  "id": "subsec-building-dashboards-5-1-1",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-building-dashboards-5-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Linked selection "
},
{
  "id": "subsec-building-dashboards-5-2-1",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-building-dashboards-5-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Show\/hide components "
},
{
  "id": "subsec-building-dashboards-5-3-1",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-building-dashboards-5-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Text objects "
},
{
  "id": "subsec-building-dashboards-5-4-1",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-building-dashboards-5-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Colored backgrounds "
},
{
  "id": "subsec-building-dashboards-5-5-1",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-building-dashboards-5-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Multiple representations "
},
{
  "id": "subsec-building-dashboards-6",
  "level": "2",
  "url": "sec-advanced-techniques.html#subsec-building-dashboards-6",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Dashboard design tips: "
},
{
  "id": "sec-tips-tricks",
  "level": "1",
  "url": "sec-tips-tricks.html",
  "type": "Section",
  "number": "",
  "title": "CODAP Tips, Tricks, and Troubleshooting",
  "body": " CODAP Tips, Tricks, and Troubleshooting   Keyboard Shortcuts and Efficiency Tips  Use these keyboard shortcuts and techniques to work more efficiently in CODAP:   Useful CODAP Shortcuts    Action  Windows\/Linux  Mac    Copy selected cells  Ctrl+C  Cmd+C    Paste into table  Ctrl+V  Cmd+V    Cut selection  Ctrl+X  Cmd+X    Select all cases  Ctrl+A  Cmd+A    Undo  Ctrl+Z  Cmd+Z    Redo  Ctrl+Y or Ctrl+Shift+Z  Cmd+Y or Cmd+Shift+Z    Save document  Ctrl+S  Cmd+S     Efficiency tips:    Duplicating Components  Right-click on a component's title bar and select \"Duplicate\" to create a copy.    Quick Graph Creation  Select attributes in the table by Ctrl\/Cmd+clicking their headers, then click the graph button.    Batch Editing  Select multiple cells in a column, right-click, and choose \"Edit Values\" to change them all at once.    Rearranging Components  Hold Shift while moving components to maintain their alignment with other components.    Quick Selections in Graphs  Click and drag to select multiple points in a graph; double-click background to select all points.      Common Issues and Solutions  If you encounter problems in CODAP, try these solutions for common issues:    Data Not Importing Correctly    Check that your CSV file uses consistent delimiters (commas or tabs)  Ensure text with commas is properly quoted in CSV files  Try opening the CSV in a text editor to check for formatting issues  For large files, try importing in smaller chunks      Formulas Not Working    Check for typos in attribute names (they are case-sensitive)  Verify parentheses are balanced  Make sure you're using the correct operators (e.g., = for equality, not ==)  Confirm that referenced attributes contain appropriate data types      Performance Issues    Close unnecessary components to reduce memory usage  Work with a subset of data if the full dataset is very large  Limit the number of simultaneously open graphs and tables  Save your work frequently to prevent loss from browser crashes      Display Issues    Try refreshing the browser if components aren't displaying correctly  Use a different browser if persistent display problems occur  Check that your browser is updated to the latest version  Adjust browser zoom level if components appear too large or small      Data Not Linking Between Components    Verify that all components are using the same data context (collection)  Check if any filters are applied that might be hiding selected data  Ensure that the components were created within the same document      If problems persist:    Try the \"Help\" menu for documentation and resources    Check the CODAP User Community at codap.concord.org\/help    Save your work and refresh the browser    Try a different browser (Chrome and Firefox work best with CODAP)      Advanced CODAP Tricks  These advanced techniques can help you get the most out of CODAP:    Using the Ruler Tool  The ruler tool allows you to create reference lines, divide data into segments, and more:  Click the ruler icon in graph axes or attribute headers  Click on the axis\/column to place dividers  Drag dividers to adjust their position  Use for creating bins, thresholds, or reference points      Creating Aggregate Functions  Calculate summaries across groups:  Create a graph with the grouping variable on one axis  Drag the variable to summarize to the other axis  Click the axis to change from \"Count\" to other aggregates (mean, median, sum)  Add these summaries back to your data using the \"Edit...\" menu option      Custom Color Palettes  Create custom color schemes for your data:  Drag an attribute to the legend area of a graph  Click on individual colors to change them  Use the color palette button to select from preset schemes  Choose colors that are colorblind-friendly for accessibility      Data Transformations  Transform data for better visualization:  Use log() for skewed distributions  Use (value - min) \/ (max - min) for normalization  Use (value - mean) \/ standardDeviation for standardization  Create binned categories with nested if() statements      Creating Custom Interactive Controls  Use formula-based approaches to create interactive controls:  Create a new collection with control parameters (e.g., threshold values)  Reference these values in formulas in your main dataset  Adjust the controls to see immediate effects on visualizations        CODAP Best Practices  Follow these best practices for effective and efficient work in CODAP:    Document Organization    Use descriptive titles for all components  Group related components together in the workspace  Add text objects to provide context and explanations  Organize your workflow from data import to final visualization      Data Management    Keep original data intact and use derived attributes for transformations  Use consistent naming conventions for attributes  Document the meaning of derived attributes and formulas  Save your work frequently and create backups      Visualization Practices    Choose appropriate visualization types for your data and questions  Use clear titles and labels for all visualizations  Apply consistent color schemes across related visualizations  Ensure visualizations are accessible (adequate contrast, colorblind-friendly)      Analysis Workflow    Start with exploratory visualizations to understand your data  Progress to focused visualizations that address specific questions  Create calculations to quantify relationships and patterns  Develop a comprehensive dashboard to communicate findings      By following these best practices, you'll create more effective, efficient, and communicative CODAP documents.   "
},
{
  "id": "subsec-keyboard-shortcuts-3",
  "level": "2",
  "url": "sec-tips-tricks.html#subsec-keyboard-shortcuts-3",
  "type": "Table",
  "number": "120",
  "title": "Useful CODAP Shortcuts",
  "body": " Useful CODAP Shortcuts    Action  Windows\/Linux  Mac    Copy selected cells  Ctrl+C  Cmd+C    Paste into table  Ctrl+V  Cmd+V    Cut selection  Ctrl+X  Cmd+X    Select all cases  Ctrl+A  Cmd+A    Undo  Ctrl+Z  Cmd+Z    Redo  Ctrl+Y or Ctrl+Shift+Z  Cmd+Y or Cmd+Shift+Z    Save document  Ctrl+S  Cmd+S    "
},
{
  "id": "sec-codap-resources",
  "level": "1",
  "url": "sec-codap-resources.html",
  "type": "Section",
  "number": "",
  "title": "Additional CODAP Resources",
  "body": " Additional CODAP Resources  To continue developing your CODAP skills, explore these additional resources:    Official CODAP Documentation   codap.concord.org\/help - Comprehensive documentation, tutorials, and examples.    CODAP Sample Documents  Accessible from the CODAP homepage under \"Example Documents\" - Explore these to see diverse applications of CODAP.    Video Tutorials   YouTube: CODAP Tutorials - Step-by-step video guides for various CODAP features.    CODAP User Forum   codap.concord.org\/forums - Community discussions, questions, and answers.    Data Science Education Resources   HI-RiSE: Data Science Education Resources - Teaching materials using CODAP from Hollylynne Lee and colleagues.    Remember that the best way to learn CODAP is through practice. Experiment with different features, try new approaches, and don't be afraid to explore. The more you use CODAP, the more comfortable and proficient you'll become.   CODAP Exploration Challenge   To practice your CODAP skills, try this challenge:    Open the \"Mammals\" example document in CODAP    Create at least three different visualizations of the data (e.g., scatter plot, box plot, dot plot)    Create a calculated attribute that represents the brain weight as a percentage of body weight    Use the ruler tool to divide mammals into categories based on the new brain-to-body ratio    Create a dashboard that includes your visualizations, the data table, and a text object explaining what you've found    Save your CODAP document    This challenge will help you practice many of the skills described in this guide while exploring an interesting dataset.    "
},
{
  "id": "exercise-codap-exploration",
  "level": "2",
  "url": "sec-codap-resources.html#exercise-codap-exploration",
  "type": "Checkpoint",
  "number": "121",
  "title": "CODAP Exploration Challenge.",
  "body": " CODAP Exploration Challenge   To practice your CODAP skills, try this challenge:    Open the \"Mammals\" example document in CODAP    Create at least three different visualizations of the data (e.g., scatter plot, box plot, dot plot)    Create a calculated attribute that represents the brain weight as a percentage of body weight    Use the ruler tool to divide mammals into categories based on the new brain-to-body ratio    Create a dashboard that includes your visualizations, the data table, and a text object explaining what you've found    Save your CODAP document    This challenge will help you practice many of the skills described in this guide while exploring an interesting dataset.   "
},
{
  "id": "backmatter-2",
  "level": "1",
  "url": "backmatter-2.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " This book was authored in PreTeXt .  "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')
  this.metadataWhitelist = ['position']

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
